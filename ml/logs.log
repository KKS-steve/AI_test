2023-09-05 12:07:55,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:07:55,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:07:55,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:07:55,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:07:57,978:INFO:PyCaret ClassificationExperiment
2023-09-05 12:07:57,978:INFO:Logging name: clf-default-name
2023-09-05 12:07:57,978:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-05 12:07:57,978:INFO:version 3.0.4
2023-09-05 12:07:57,978:INFO:Initializing setup()
2023-09-05 12:07:57,978:INFO:self.USI: e2be
2023-09-05 12:07:57,978:INFO:self._variable_keys: {'gpu_n_jobs_param', 'exp_name_log', 'is_multiclass', 'y_test', 'X_test', 'USI', 'n_jobs_param', 'gpu_param', 'y_train', 'exp_id', 'X_train', 'fold_generator', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', 'fix_imbalance', 'X', 'target_param', 'log_plots_param', 'y', 'pipeline', 'data', 'html_param', 'idx', '_available_plots', '_ml_usecase', 'memory', 'seed'}
2023-09-05 12:07:57,978:INFO:Checking environment
2023-09-05 12:07:57,978:INFO:python_version: 3.8.8
2023-09-05 12:07:57,978:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 12:07:57,978:INFO:machine: AMD64
2023-09-05 12:07:57,978:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 12:07:57,978:INFO:Memory: svmem(total=16822788096, available=9206628352, percent=45.3, used=7616159744, free=9206628352)
2023-09-05 12:07:57,978:INFO:Physical Core: 8
2023-09-05 12:07:57,978:INFO:Logical Core: 16
2023-09-05 12:07:57,978:INFO:Checking libraries
2023-09-05 12:07:57,978:INFO:System:
2023-09-05 12:07:57,978:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 12:07:57,978:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 12:07:57,978:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 12:07:57,978:INFO:PyCaret required dependencies:
2023-09-05 12:07:57,978:INFO:                 pip: 23.2.1
2023-09-05 12:07:57,978:INFO:          setuptools: 65.5.1
2023-09-05 12:07:57,978:INFO:             pycaret: 3.0.4
2023-09-05 12:07:57,978:INFO:             IPython: 8.12.2
2023-09-05 12:07:57,978:INFO:          ipywidgets: 8.0.7
2023-09-05 12:07:57,978:INFO:                tqdm: 4.66.1
2023-09-05 12:07:57,978:INFO:               numpy: 1.23.5
2023-09-05 12:07:57,978:INFO:              pandas: 1.5.3
2023-09-05 12:07:57,978:INFO:              jinja2: 3.1.2
2023-09-05 12:07:57,978:INFO:               scipy: 1.10.1
2023-09-05 12:07:57,978:INFO:              joblib: 1.3.2
2023-09-05 12:07:57,978:INFO:             sklearn: 1.2.2
2023-09-05 12:07:57,978:INFO:                pyod: 1.1.0
2023-09-05 12:07:57,978:INFO:            imblearn: 0.11.0
2023-09-05 12:07:57,978:INFO:   category_encoders: 2.6.2
2023-09-05 12:07:57,978:INFO:            lightgbm: 4.0.0
2023-09-05 12:07:57,978:INFO:               numba: 0.57.1
2023-09-05 12:07:57,978:INFO:            requests: 2.31.0
2023-09-05 12:07:57,978:INFO:          matplotlib: 3.7.2
2023-09-05 12:07:57,978:INFO:          scikitplot: 0.3.7
2023-09-05 12:07:57,978:INFO:         yellowbrick: 1.5
2023-09-05 12:07:57,978:INFO:              plotly: 5.15.0
2023-09-05 12:07:57,978:INFO:    plotly-resampler: Not installed
2023-09-05 12:07:57,978:INFO:             kaleido: 0.2.1
2023-09-05 12:07:57,978:INFO:           schemdraw: 0.15
2023-09-05 12:07:57,978:INFO:         statsmodels: 0.14.0
2023-09-05 12:07:57,978:INFO:              sktime: 0.22.0
2023-09-05 12:07:57,978:INFO:               tbats: 1.1.3
2023-09-05 12:07:57,978:INFO:            pmdarima: 2.0.3
2023-09-05 12:07:57,978:INFO:              psutil: 5.9.5
2023-09-05 12:07:57,978:INFO:          markupsafe: 2.1.3
2023-09-05 12:07:57,978:INFO:             pickle5: Not installed
2023-09-05 12:07:57,978:INFO:         cloudpickle: 2.2.1
2023-09-05 12:07:57,978:INFO:         deprecation: 2.1.0
2023-09-05 12:07:57,978:INFO:              xxhash: 3.3.0
2023-09-05 12:07:57,978:INFO:           wurlitzer: Not installed
2023-09-05 12:07:57,978:INFO:PyCaret optional dependencies:
2023-09-05 12:07:57,978:INFO:                shap: Not installed
2023-09-05 12:07:57,978:INFO:           interpret: Not installed
2023-09-05 12:07:57,978:INFO:                umap: Not installed
2023-09-05 12:07:57,978:INFO:    pandas_profiling: 4.5.1
2023-09-05 12:07:57,978:INFO:  explainerdashboard: Not installed
2023-09-05 12:07:57,978:INFO:             autoviz: Not installed
2023-09-05 12:07:57,978:INFO:           fairlearn: Not installed
2023-09-05 12:07:57,978:INFO:          deepchecks: Not installed
2023-09-05 12:07:57,978:INFO:             xgboost: 1.7.6
2023-09-05 12:07:57,978:INFO:            catboost: 1.2.1
2023-09-05 12:07:57,978:INFO:              kmodes: Not installed
2023-09-05 12:07:57,978:INFO:             mlxtend: Not installed
2023-09-05 12:07:57,978:INFO:       statsforecast: Not installed
2023-09-05 12:07:57,978:INFO:        tune_sklearn: Not installed
2023-09-05 12:07:57,978:INFO:                 ray: Not installed
2023-09-05 12:07:57,978:INFO:            hyperopt: Not installed
2023-09-05 12:07:57,978:INFO:              optuna: 3.3.0
2023-09-05 12:07:57,978:INFO:               skopt: 0.9.0
2023-09-05 12:07:57,978:INFO:              mlflow: Not installed
2023-09-05 12:07:57,978:INFO:              gradio: Not installed
2023-09-05 12:07:57,978:INFO:             fastapi: Not installed
2023-09-05 12:07:57,978:INFO:             uvicorn: Not installed
2023-09-05 12:07:57,978:INFO:              m2cgen: Not installed
2023-09-05 12:07:57,978:INFO:           evidently: Not installed
2023-09-05 12:07:57,978:INFO:               fugue: Not installed
2023-09-05 12:07:57,978:INFO:           streamlit: Not installed
2023-09-05 12:07:57,978:INFO:             prophet: Not installed
2023-09-05 12:07:57,978:INFO:None
2023-09-05 12:07:57,978:INFO:Set up data.
2023-09-05 12:07:57,978:INFO:Set up train/test split.
2023-09-05 12:07:57,993:INFO:Set up index.
2023-09-05 12:07:57,993:INFO:Set up folding strategy.
2023-09-05 12:07:57,993:INFO:Assigning column types.
2023-09-05 12:07:57,993:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 12:07:58,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:07:58,024:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:07:58,040:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:58,040:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:58,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:07:58,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:07:58,103:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:58,103:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:58,103:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 12:07:58,134:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:07:58,149:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:58,149:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:58,181:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:07:58,196:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:58,196:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:58,196:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-05 12:07:58,243:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:58,243:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:58,290:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:58,306:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:58,306:INFO:Preparing preprocessing pipeline...
2023-09-05 12:07:58,306:INFO:Set up simple imputation.
2023-09-05 12:07:58,306:INFO:Finished creating preprocessing pipeline.
2023-09-05 12:07:58,321:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-05 12:07:58,321:INFO:Creating final display dataframe.
2023-09-05 12:07:58,353:INFO:Setup _display_container:                     Description             Value
0                    Session id              2867
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e2be
2023-09-05 12:07:58,408:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:58,410:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:58,442:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:58,458:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:58,458:INFO:setup() successfully completed in 0.48s...............
2023-09-05 12:08:29,181:INFO:PyCaret ClassificationExperiment
2023-09-05 12:08:29,181:INFO:Logging name: clf-default-name
2023-09-05 12:08:29,181:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-05 12:08:29,181:INFO:version 3.0.4
2023-09-05 12:08:29,181:INFO:Initializing setup()
2023-09-05 12:08:29,181:INFO:self.USI: 5d8d
2023-09-05 12:08:29,181:INFO:self._variable_keys: {'gpu_n_jobs_param', 'exp_name_log', 'is_multiclass', 'y_test', 'X_test', 'USI', 'n_jobs_param', 'gpu_param', 'y_train', 'exp_id', 'X_train', 'fold_generator', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', 'fix_imbalance', 'X', 'target_param', 'log_plots_param', 'y', 'pipeline', 'data', 'html_param', 'idx', '_available_plots', '_ml_usecase', 'memory', 'seed'}
2023-09-05 12:08:29,181:INFO:Checking environment
2023-09-05 12:08:29,181:INFO:python_version: 3.8.8
2023-09-05 12:08:29,181:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 12:08:29,181:INFO:machine: AMD64
2023-09-05 12:08:29,181:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 12:08:29,183:INFO:Memory: svmem(total=16822788096, available=9199333376, percent=45.3, used=7623454720, free=9199333376)
2023-09-05 12:08:29,183:INFO:Physical Core: 8
2023-09-05 12:08:29,183:INFO:Logical Core: 16
2023-09-05 12:08:29,183:INFO:Checking libraries
2023-09-05 12:08:29,183:INFO:System:
2023-09-05 12:08:29,183:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 12:08:29,183:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 12:08:29,183:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 12:08:29,183:INFO:PyCaret required dependencies:
2023-09-05 12:08:29,183:INFO:                 pip: 23.2.1
2023-09-05 12:08:29,183:INFO:          setuptools: 65.5.1
2023-09-05 12:08:29,183:INFO:             pycaret: 3.0.4
2023-09-05 12:08:29,183:INFO:             IPython: 8.12.2
2023-09-05 12:08:29,183:INFO:          ipywidgets: 8.0.7
2023-09-05 12:08:29,183:INFO:                tqdm: 4.66.1
2023-09-05 12:08:29,183:INFO:               numpy: 1.23.5
2023-09-05 12:08:29,183:INFO:              pandas: 1.5.3
2023-09-05 12:08:29,183:INFO:              jinja2: 3.1.2
2023-09-05 12:08:29,183:INFO:               scipy: 1.10.1
2023-09-05 12:08:29,183:INFO:              joblib: 1.3.2
2023-09-05 12:08:29,183:INFO:             sklearn: 1.2.2
2023-09-05 12:08:29,183:INFO:                pyod: 1.1.0
2023-09-05 12:08:29,183:INFO:            imblearn: 0.11.0
2023-09-05 12:08:29,183:INFO:   category_encoders: 2.6.2
2023-09-05 12:08:29,183:INFO:            lightgbm: 4.0.0
2023-09-05 12:08:29,183:INFO:               numba: 0.57.1
2023-09-05 12:08:29,183:INFO:            requests: 2.31.0
2023-09-05 12:08:29,183:INFO:          matplotlib: 3.7.2
2023-09-05 12:08:29,183:INFO:          scikitplot: 0.3.7
2023-09-05 12:08:29,183:INFO:         yellowbrick: 1.5
2023-09-05 12:08:29,183:INFO:              plotly: 5.15.0
2023-09-05 12:08:29,183:INFO:    plotly-resampler: Not installed
2023-09-05 12:08:29,183:INFO:             kaleido: 0.2.1
2023-09-05 12:08:29,183:INFO:           schemdraw: 0.15
2023-09-05 12:08:29,183:INFO:         statsmodels: 0.14.0
2023-09-05 12:08:29,183:INFO:              sktime: 0.22.0
2023-09-05 12:08:29,183:INFO:               tbats: 1.1.3
2023-09-05 12:08:29,183:INFO:            pmdarima: 2.0.3
2023-09-05 12:08:29,183:INFO:              psutil: 5.9.5
2023-09-05 12:08:29,183:INFO:          markupsafe: 2.1.3
2023-09-05 12:08:29,183:INFO:             pickle5: Not installed
2023-09-05 12:08:29,183:INFO:         cloudpickle: 2.2.1
2023-09-05 12:08:29,183:INFO:         deprecation: 2.1.0
2023-09-05 12:08:29,183:INFO:              xxhash: 3.3.0
2023-09-05 12:08:29,183:INFO:           wurlitzer: Not installed
2023-09-05 12:08:29,183:INFO:PyCaret optional dependencies:
2023-09-05 12:08:29,183:INFO:                shap: Not installed
2023-09-05 12:08:29,183:INFO:           interpret: Not installed
2023-09-05 12:08:29,183:INFO:                umap: Not installed
2023-09-05 12:08:29,183:INFO:    pandas_profiling: 4.5.1
2023-09-05 12:08:29,183:INFO:  explainerdashboard: Not installed
2023-09-05 12:08:29,183:INFO:             autoviz: Not installed
2023-09-05 12:08:29,183:INFO:           fairlearn: Not installed
2023-09-05 12:08:29,183:INFO:          deepchecks: Not installed
2023-09-05 12:08:29,183:INFO:             xgboost: 1.7.6
2023-09-05 12:08:29,183:INFO:            catboost: 1.2.1
2023-09-05 12:08:29,183:INFO:              kmodes: Not installed
2023-09-05 12:08:29,183:INFO:             mlxtend: Not installed
2023-09-05 12:08:29,183:INFO:       statsforecast: Not installed
2023-09-05 12:08:29,183:INFO:        tune_sklearn: Not installed
2023-09-05 12:08:29,183:INFO:                 ray: Not installed
2023-09-05 12:08:29,183:INFO:            hyperopt: Not installed
2023-09-05 12:08:29,183:INFO:              optuna: 3.3.0
2023-09-05 12:08:29,183:INFO:               skopt: 0.9.0
2023-09-05 12:08:29,183:INFO:              mlflow: Not installed
2023-09-05 12:08:29,183:INFO:              gradio: Not installed
2023-09-05 12:08:29,183:INFO:             fastapi: Not installed
2023-09-05 12:08:29,183:INFO:             uvicorn: Not installed
2023-09-05 12:08:29,183:INFO:              m2cgen: Not installed
2023-09-05 12:08:29,183:INFO:           evidently: Not installed
2023-09-05 12:08:29,183:INFO:               fugue: Not installed
2023-09-05 12:08:29,183:INFO:           streamlit: Not installed
2023-09-05 12:08:29,183:INFO:             prophet: Not installed
2023-09-05 12:08:29,183:INFO:None
2023-09-05 12:08:29,183:INFO:Set up data.
2023-09-05 12:08:29,183:INFO:Set up train/test split.
2023-09-05 12:08:29,183:INFO:Set up index.
2023-09-05 12:08:29,183:INFO:Set up folding strategy.
2023-09-05 12:08:29,183:INFO:Assigning column types.
2023-09-05 12:08:29,193:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 12:08:29,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:08:29,224:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:08:29,243:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:29,293:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:29,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:08:29,324:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:08:29,340:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:29,340:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:29,340:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 12:08:29,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:08:29,393:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:29,394:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:29,424:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:08:29,443:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:29,443:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:29,443:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-05 12:08:29,490:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:29,490:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:29,536:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:29,536:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:29,536:INFO:Preparing preprocessing pipeline...
2023-09-05 12:08:29,536:INFO:Set up simple imputation.
2023-09-05 12:08:29,552:INFO:Finished creating preprocessing pipeline.
2023-09-05 12:08:29,552:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-05 12:08:29,552:INFO:Creating final display dataframe.
2023-09-05 12:08:29,583:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5d8d
2023-09-05 12:08:29,641:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:29,643:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:29,676:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:29,692:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:29,692:INFO:setup() successfully completed in 0.51s...............
2023-09-05 12:12:01,806:INFO:gpu_param set to False
2023-09-05 12:12:01,881:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:12:01,883:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:12:01,929:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:12:01,929:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:12:47,146:INFO:gpu_param set to False
2023-09-05 12:12:47,202:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:12:47,204:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:12:47,241:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:12:47,241:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:15:22,034:INFO:Initializing compare_models()
2023-09-05 12:15:22,034:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-05 12:15:22,034:INFO:Checking exceptions
2023-09-05 12:15:22,039:INFO:Preparing display monitor
2023-09-05 12:15:22,064:INFO:Initializing Logistic Regression
2023-09-05 12:15:22,064:INFO:Total runtime is 0.0 minutes
2023-09-05 12:15:22,065:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:22,065:INFO:Initializing create_model()
2023-09-05 12:15:22,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:22,065:INFO:Checking exceptions
2023-09-05 12:15:22,065:INFO:Importing libraries
2023-09-05 12:15:22,065:INFO:Copying training dataset
2023-09-05 12:15:22,065:INFO:Defining folds
2023-09-05 12:15:22,065:INFO:Declaring metric variables
2023-09-05 12:15:22,065:INFO:Importing untrained model
2023-09-05 12:15:22,075:INFO:Logistic Regression Imported successfully
2023-09-05 12:15:22,080:INFO:Starting cross validation
2023-09-05 12:15:22,081:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:23,663:INFO:Calculating mean and std
2023-09-05 12:15:23,663:INFO:Creating metrics dataframe
2023-09-05 12:15:23,663:INFO:Uploading results into container
2023-09-05 12:15:23,669:INFO:Uploading model into container now
2023-09-05 12:15:23,669:INFO:_master_model_container: 1
2023-09-05 12:15:23,669:INFO:_display_container: 2
2023-09-05 12:15:23,670:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-05 12:15:23,670:INFO:create_model() successfully completed......................................
2023-09-05 12:15:23,803:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:23,803:INFO:Creating metrics dataframe
2023-09-05 12:15:23,803:INFO:Initializing K Neighbors Classifier
2023-09-05 12:15:23,803:INFO:Total runtime is 0.02899259328842163 minutes
2023-09-05 12:15:23,803:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:23,803:INFO:Initializing create_model()
2023-09-05 12:15:23,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:23,803:INFO:Checking exceptions
2023-09-05 12:15:23,803:INFO:Importing libraries
2023-09-05 12:15:23,803:INFO:Copying training dataset
2023-09-05 12:15:23,818:INFO:Defining folds
2023-09-05 12:15:23,818:INFO:Declaring metric variables
2023-09-05 12:15:23,822:INFO:Importing untrained model
2023-09-05 12:15:23,826:INFO:K Neighbors Classifier Imported successfully
2023-09-05 12:15:23,832:INFO:Starting cross validation
2023-09-05 12:15:23,832:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:25,090:INFO:Calculating mean and std
2023-09-05 12:15:25,090:INFO:Creating metrics dataframe
2023-09-05 12:15:25,090:INFO:Uploading results into container
2023-09-05 12:15:25,090:INFO:Uploading model into container now
2023-09-05 12:15:25,090:INFO:_master_model_container: 2
2023-09-05 12:15:25,097:INFO:_display_container: 2
2023-09-05 12:15:25,097:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-05 12:15:25,097:INFO:create_model() successfully completed......................................
2023-09-05 12:15:25,206:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:25,206:INFO:Creating metrics dataframe
2023-09-05 12:15:25,222:INFO:Initializing Naive Bayes
2023-09-05 12:15:25,222:INFO:Total runtime is 0.05263752937316894 minutes
2023-09-05 12:15:25,222:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:25,222:INFO:Initializing create_model()
2023-09-05 12:15:25,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:25,222:INFO:Checking exceptions
2023-09-05 12:15:25,222:INFO:Importing libraries
2023-09-05 12:15:25,222:INFO:Copying training dataset
2023-09-05 12:15:25,228:INFO:Defining folds
2023-09-05 12:15:25,229:INFO:Declaring metric variables
2023-09-05 12:15:25,232:INFO:Importing untrained model
2023-09-05 12:15:25,234:INFO:Naive Bayes Imported successfully
2023-09-05 12:15:25,241:INFO:Starting cross validation
2023-09-05 12:15:25,242:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:26,460:INFO:Calculating mean and std
2023-09-05 12:15:26,460:INFO:Creating metrics dataframe
2023-09-05 12:15:26,460:INFO:Uploading results into container
2023-09-05 12:15:26,466:INFO:Uploading model into container now
2023-09-05 12:15:26,466:INFO:_master_model_container: 3
2023-09-05 12:15:26,466:INFO:_display_container: 2
2023-09-05 12:15:26,466:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-05 12:15:26,466:INFO:create_model() successfully completed......................................
2023-09-05 12:15:26,573:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:26,573:INFO:Creating metrics dataframe
2023-09-05 12:15:26,573:INFO:Initializing Decision Tree Classifier
2023-09-05 12:15:26,573:INFO:Total runtime is 0.07515607674916586 minutes
2023-09-05 12:15:26,589:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:26,590:INFO:Initializing create_model()
2023-09-05 12:15:26,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:26,590:INFO:Checking exceptions
2023-09-05 12:15:26,590:INFO:Importing libraries
2023-09-05 12:15:26,590:INFO:Copying training dataset
2023-09-05 12:15:26,593:INFO:Defining folds
2023-09-05 12:15:26,593:INFO:Declaring metric variables
2023-09-05 12:15:26,595:INFO:Importing untrained model
2023-09-05 12:15:26,598:INFO:Decision Tree Classifier Imported successfully
2023-09-05 12:15:26,602:INFO:Starting cross validation
2023-09-05 12:15:26,603:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:27,796:INFO:Calculating mean and std
2023-09-05 12:15:27,796:INFO:Creating metrics dataframe
2023-09-05 12:15:27,796:INFO:Uploading results into container
2023-09-05 12:15:27,796:INFO:Uploading model into container now
2023-09-05 12:15:27,803:INFO:_master_model_container: 4
2023-09-05 12:15:27,803:INFO:_display_container: 2
2023-09-05 12:15:27,803:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 12:15:27,803:INFO:create_model() successfully completed......................................
2023-09-05 12:15:27,921:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:27,921:INFO:Creating metrics dataframe
2023-09-05 12:15:27,921:INFO:Initializing SVM - Linear Kernel
2023-09-05 12:15:27,921:INFO:Total runtime is 0.09762059450149536 minutes
2023-09-05 12:15:27,921:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:27,921:INFO:Initializing create_model()
2023-09-05 12:15:27,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:27,921:INFO:Checking exceptions
2023-09-05 12:15:27,921:INFO:Importing libraries
2023-09-05 12:15:27,921:INFO:Copying training dataset
2023-09-05 12:15:27,932:INFO:Defining folds
2023-09-05 12:15:27,932:INFO:Declaring metric variables
2023-09-05 12:15:27,934:INFO:Importing untrained model
2023-09-05 12:15:27,936:INFO:SVM - Linear Kernel Imported successfully
2023-09-05 12:15:27,942:INFO:Starting cross validation
2023-09-05 12:15:27,943:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:29,085:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:15:29,101:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:15:29,117:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:15:29,132:INFO:Calculating mean and std
2023-09-05 12:15:29,132:INFO:Creating metrics dataframe
2023-09-05 12:15:29,132:INFO:Uploading results into container
2023-09-05 12:15:29,132:INFO:Uploading model into container now
2023-09-05 12:15:29,139:INFO:_master_model_container: 5
2023-09-05 12:15:29,139:INFO:_display_container: 2
2023-09-05 12:15:29,139:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-05 12:15:29,139:INFO:create_model() successfully completed......................................
2023-09-05 12:15:29,255:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:29,255:INFO:Creating metrics dataframe
2023-09-05 12:15:29,255:INFO:Initializing Ridge Classifier
2023-09-05 12:15:29,255:INFO:Total runtime is 0.11986161470413209 minutes
2023-09-05 12:15:29,255:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:29,255:INFO:Initializing create_model()
2023-09-05 12:15:29,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:29,255:INFO:Checking exceptions
2023-09-05 12:15:29,255:INFO:Importing libraries
2023-09-05 12:15:29,255:INFO:Copying training dataset
2023-09-05 12:15:29,269:INFO:Defining folds
2023-09-05 12:15:29,269:INFO:Declaring metric variables
2023-09-05 12:15:29,272:INFO:Importing untrained model
2023-09-05 12:15:29,274:INFO:Ridge Classifier Imported successfully
2023-09-05 12:15:29,280:INFO:Starting cross validation
2023-09-05 12:15:29,280:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:29,328:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 12:15:29,328:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 12:15:30,293:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 12:15:30,324:INFO:Calculating mean and std
2023-09-05 12:15:30,324:INFO:Creating metrics dataframe
2023-09-05 12:15:30,329:INFO:Uploading results into container
2023-09-05 12:15:30,330:INFO:Uploading model into container now
2023-09-05 12:15:30,330:INFO:_master_model_container: 6
2023-09-05 12:15:30,330:INFO:_display_container: 2
2023-09-05 12:15:30,330:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-05 12:15:30,330:INFO:create_model() successfully completed......................................
2023-09-05 12:15:30,439:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:30,439:INFO:Creating metrics dataframe
2023-09-05 12:15:30,454:INFO:Initializing Random Forest Classifier
2023-09-05 12:15:30,454:INFO:Total runtime is 0.13984461625417074 minutes
2023-09-05 12:15:30,454:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:30,454:INFO:Initializing create_model()
2023-09-05 12:15:30,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:30,454:INFO:Checking exceptions
2023-09-05 12:15:30,454:INFO:Importing libraries
2023-09-05 12:15:30,454:INFO:Copying training dataset
2023-09-05 12:15:30,463:INFO:Defining folds
2023-09-05 12:15:30,463:INFO:Declaring metric variables
2023-09-05 12:15:30,466:INFO:Importing untrained model
2023-09-05 12:15:30,468:INFO:Random Forest Classifier Imported successfully
2023-09-05 12:15:30,468:INFO:Starting cross validation
2023-09-05 12:15:30,468:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:30,834:INFO:Calculating mean and std
2023-09-05 12:15:30,834:INFO:Creating metrics dataframe
2023-09-05 12:15:30,838:INFO:Uploading results into container
2023-09-05 12:15:30,839:INFO:Uploading model into container now
2023-09-05 12:15:30,839:INFO:_master_model_container: 7
2023-09-05 12:15:30,839:INFO:_display_container: 2
2023-09-05 12:15:30,839:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 12:15:30,839:INFO:create_model() successfully completed......................................
2023-09-05 12:15:30,956:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:30,956:INFO:Creating metrics dataframe
2023-09-05 12:15:30,964:INFO:Initializing Quadratic Discriminant Analysis
2023-09-05 12:15:30,964:INFO:Total runtime is 0.14834203720092776 minutes
2023-09-05 12:15:30,966:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:30,966:INFO:Initializing create_model()
2023-09-05 12:15:30,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:30,966:INFO:Checking exceptions
2023-09-05 12:15:30,966:INFO:Importing libraries
2023-09-05 12:15:30,966:INFO:Copying training dataset
2023-09-05 12:15:30,970:INFO:Defining folds
2023-09-05 12:15:30,970:INFO:Declaring metric variables
2023-09-05 12:15:30,973:INFO:Importing untrained model
2023-09-05 12:15:30,976:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-05 12:15:30,981:INFO:Starting cross validation
2023-09-05 12:15:30,982:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:31,057:INFO:Calculating mean and std
2023-09-05 12:15:31,057:INFO:Creating metrics dataframe
2023-09-05 12:15:31,060:INFO:Uploading results into container
2023-09-05 12:15:31,060:INFO:Uploading model into container now
2023-09-05 12:15:31,060:INFO:_master_model_container: 8
2023-09-05 12:15:31,060:INFO:_display_container: 2
2023-09-05 12:15:31,060:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-05 12:15:31,060:INFO:create_model() successfully completed......................................
2023-09-05 12:15:31,169:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:31,169:INFO:Creating metrics dataframe
2023-09-05 12:15:31,169:INFO:Initializing Ada Boost Classifier
2023-09-05 12:15:31,169:INFO:Total runtime is 0.15176258484522503 minutes
2023-09-05 12:15:31,185:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:31,185:INFO:Initializing create_model()
2023-09-05 12:15:31,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:31,185:INFO:Checking exceptions
2023-09-05 12:15:31,187:INFO:Importing libraries
2023-09-05 12:15:31,187:INFO:Copying training dataset
2023-09-05 12:15:31,189:INFO:Defining folds
2023-09-05 12:15:31,189:INFO:Declaring metric variables
2023-09-05 12:15:31,192:INFO:Importing untrained model
2023-09-05 12:15:31,193:INFO:Ada Boost Classifier Imported successfully
2023-09-05 12:15:31,193:INFO:Starting cross validation
2023-09-05 12:15:31,193:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:31,354:INFO:Calculating mean and std
2023-09-05 12:15:31,354:INFO:Creating metrics dataframe
2023-09-05 12:15:31,359:INFO:Uploading results into container
2023-09-05 12:15:31,359:INFO:Uploading model into container now
2023-09-05 12:15:31,360:INFO:_master_model_container: 9
2023-09-05 12:15:31,360:INFO:_display_container: 2
2023-09-05 12:15:31,360:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-05 12:15:31,360:INFO:create_model() successfully completed......................................
2023-09-05 12:15:31,464:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:31,464:INFO:Creating metrics dataframe
2023-09-05 12:15:31,464:INFO:Initializing Gradient Boosting Classifier
2023-09-05 12:15:31,464:INFO:Total runtime is 0.1566732128461202 minutes
2023-09-05 12:15:31,481:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:31,481:INFO:Initializing create_model()
2023-09-05 12:15:31,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:31,481:INFO:Checking exceptions
2023-09-05 12:15:31,481:INFO:Importing libraries
2023-09-05 12:15:31,481:INFO:Copying training dataset
2023-09-05 12:15:31,484:INFO:Defining folds
2023-09-05 12:15:31,484:INFO:Declaring metric variables
2023-09-05 12:15:31,487:INFO:Importing untrained model
2023-09-05 12:15:31,492:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 12:15:31,496:INFO:Starting cross validation
2023-09-05 12:15:31,496:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:31,653:INFO:Calculating mean and std
2023-09-05 12:15:31,653:INFO:Creating metrics dataframe
2023-09-05 12:15:31,658:INFO:Uploading results into container
2023-09-05 12:15:31,658:INFO:Uploading model into container now
2023-09-05 12:15:31,659:INFO:_master_model_container: 10
2023-09-05 12:15:31,659:INFO:_display_container: 2
2023-09-05 12:15:31,659:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 12:15:31,659:INFO:create_model() successfully completed......................................
2023-09-05 12:15:31,755:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:31,755:INFO:Creating metrics dataframe
2023-09-05 12:15:31,770:INFO:Initializing Linear Discriminant Analysis
2023-09-05 12:15:31,770:INFO:Total runtime is 0.16177898645401 minutes
2023-09-05 12:15:31,770:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:31,770:INFO:Initializing create_model()
2023-09-05 12:15:31,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:31,770:INFO:Checking exceptions
2023-09-05 12:15:31,770:INFO:Importing libraries
2023-09-05 12:15:31,770:INFO:Copying training dataset
2023-09-05 12:15:31,782:INFO:Defining folds
2023-09-05 12:15:31,782:INFO:Declaring metric variables
2023-09-05 12:15:31,784:INFO:Importing untrained model
2023-09-05 12:15:31,787:INFO:Linear Discriminant Analysis Imported successfully
2023-09-05 12:15:31,792:INFO:Starting cross validation
2023-09-05 12:15:31,792:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:31,859:INFO:Calculating mean and std
2023-09-05 12:15:31,859:INFO:Creating metrics dataframe
2023-09-05 12:15:31,859:INFO:Uploading results into container
2023-09-05 12:15:31,859:INFO:Uploading model into container now
2023-09-05 12:15:31,859:INFO:_master_model_container: 11
2023-09-05 12:15:31,859:INFO:_display_container: 2
2023-09-05 12:15:31,859:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-05 12:15:31,859:INFO:create_model() successfully completed......................................
2023-09-05 12:15:31,968:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:31,968:INFO:Creating metrics dataframe
2023-09-05 12:15:31,968:INFO:Initializing Extra Trees Classifier
2023-09-05 12:15:31,968:INFO:Total runtime is 0.16507187287012737 minutes
2023-09-05 12:15:31,968:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:31,968:INFO:Initializing create_model()
2023-09-05 12:15:31,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:31,968:INFO:Checking exceptions
2023-09-05 12:15:31,968:INFO:Importing libraries
2023-09-05 12:15:31,968:INFO:Copying training dataset
2023-09-05 12:15:31,985:INFO:Defining folds
2023-09-05 12:15:31,986:INFO:Declaring metric variables
2023-09-05 12:15:31,988:INFO:Importing untrained model
2023-09-05 12:15:31,991:INFO:Extra Trees Classifier Imported successfully
2023-09-05 12:15:31,997:INFO:Starting cross validation
2023-09-05 12:15:31,998:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:32,247:INFO:Calculating mean and std
2023-09-05 12:15:32,247:INFO:Creating metrics dataframe
2023-09-05 12:15:32,251:INFO:Uploading results into container
2023-09-05 12:15:32,251:INFO:Uploading model into container now
2023-09-05 12:15:32,252:INFO:_master_model_container: 12
2023-09-05 12:15:32,252:INFO:_display_container: 2
2023-09-05 12:15:32,252:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-05 12:15:32,252:INFO:create_model() successfully completed......................................
2023-09-05 12:15:32,347:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:32,347:INFO:Creating metrics dataframe
2023-09-05 12:15:32,363:INFO:Initializing Extreme Gradient Boosting
2023-09-05 12:15:32,363:INFO:Total runtime is 0.17165624698003135 minutes
2023-09-05 12:15:32,363:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:32,363:INFO:Initializing create_model()
2023-09-05 12:15:32,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:32,363:INFO:Checking exceptions
2023-09-05 12:15:32,363:INFO:Importing libraries
2023-09-05 12:15:32,363:INFO:Copying training dataset
2023-09-05 12:15:32,374:INFO:Defining folds
2023-09-05 12:15:32,374:INFO:Declaring metric variables
2023-09-05 12:15:32,377:INFO:Importing untrained model
2023-09-05 12:15:32,379:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 12:15:32,380:INFO:Starting cross validation
2023-09-05 12:15:32,380:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:32,490:INFO:Calculating mean and std
2023-09-05 12:15:32,490:INFO:Creating metrics dataframe
2023-09-05 12:15:32,494:INFO:Uploading results into container
2023-09-05 12:15:32,494:INFO:Uploading model into container now
2023-09-05 12:15:32,494:INFO:_master_model_container: 13
2023-09-05 12:15:32,494:INFO:_display_container: 2
2023-09-05 12:15:32,495:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 12:15:32,495:INFO:create_model() successfully completed......................................
2023-09-05 12:15:32,604:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:32,604:INFO:Creating metrics dataframe
2023-09-05 12:15:32,604:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 12:15:32,604:INFO:Total runtime is 0.1756674647331238 minutes
2023-09-05 12:15:32,604:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:32,604:INFO:Initializing create_model()
2023-09-05 12:15:32,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:32,604:INFO:Checking exceptions
2023-09-05 12:15:32,604:INFO:Importing libraries
2023-09-05 12:15:32,604:INFO:Copying training dataset
2023-09-05 12:15:32,619:INFO:Defining folds
2023-09-05 12:15:32,619:INFO:Declaring metric variables
2023-09-05 12:15:32,621:INFO:Importing untrained model
2023-09-05 12:15:32,624:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 12:15:32,631:INFO:Starting cross validation
2023-09-05 12:15:32,631:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:32,818:INFO:Calculating mean and std
2023-09-05 12:15:32,818:INFO:Creating metrics dataframe
2023-09-05 12:15:32,825:INFO:Uploading results into container
2023-09-05 12:15:32,826:INFO:Uploading model into container now
2023-09-05 12:15:32,826:INFO:_master_model_container: 14
2023-09-05 12:15:32,826:INFO:_display_container: 2
2023-09-05 12:15:32,826:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 12:15:32,826:INFO:create_model() successfully completed......................................
2023-09-05 12:15:32,952:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:32,952:INFO:Creating metrics dataframe
2023-09-05 12:15:32,967:INFO:Initializing Dummy Classifier
2023-09-05 12:15:32,967:INFO:Total runtime is 0.1817231098810832 minutes
2023-09-05 12:15:32,967:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:32,967:INFO:Initializing create_model()
2023-09-05 12:15:32,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5EA26820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:32,967:INFO:Checking exceptions
2023-09-05 12:15:32,967:INFO:Importing libraries
2023-09-05 12:15:32,967:INFO:Copying training dataset
2023-09-05 12:15:32,974:INFO:Defining folds
2023-09-05 12:15:32,974:INFO:Declaring metric variables
2023-09-05 12:15:32,976:INFO:Importing untrained model
2023-09-05 12:15:32,979:INFO:Dummy Classifier Imported successfully
2023-09-05 12:15:32,979:INFO:Starting cross validation
2023-09-05 12:15:32,979:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:33,032:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:15:33,032:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:15:33,032:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:15:33,039:INFO:Calculating mean and std
2023-09-05 12:15:33,039:INFO:Creating metrics dataframe
2023-09-05 12:15:33,043:INFO:Uploading results into container
2023-09-05 12:15:33,044:INFO:Uploading model into container now
2023-09-05 12:15:33,044:INFO:_master_model_container: 15
2023-09-05 12:15:33,044:INFO:_display_container: 2
2023-09-05 12:15:33,044:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-05 12:15:33,044:INFO:create_model() successfully completed......................................
2023-09-05 12:15:33,152:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:33,152:INFO:Creating metrics dataframe
2023-09-05 12:15:33,166:INFO:Initializing create_model()
2023-09-05 12:15:33,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:33,166:INFO:Checking exceptions
2023-09-05 12:15:33,167:INFO:Importing libraries
2023-09-05 12:15:33,167:INFO:Copying training dataset
2023-09-05 12:15:33,170:INFO:Defining folds
2023-09-05 12:15:33,170:INFO:Declaring metric variables
2023-09-05 12:15:33,170:INFO:Importing untrained model
2023-09-05 12:15:33,170:INFO:Declaring custom model
2023-09-05 12:15:33,170:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 12:15:33,171:INFO:Cross validation set to False
2023-09-05 12:15:33,171:INFO:Fitting Model
2023-09-05 12:15:33,256:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 12:15:33,256:INFO:create_model() successfully completed......................................
2023-09-05 12:15:33,378:INFO:_master_model_container: 15
2023-09-05 12:15:33,378:INFO:_display_container: 2
2023-09-05 12:15:33,378:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 12:15:33,378:INFO:compare_models() successfully completed......................................
2023-09-05 16:01:06,646:INFO:Initializing compare_models()
2023-09-05 16:01:06,646:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-05 16:01:06,646:INFO:Checking exceptions
2023-09-05 16:01:06,648:INFO:Preparing display monitor
2023-09-05 16:01:06,667:INFO:Initializing Logistic Regression
2023-09-05 16:01:06,667:INFO:Total runtime is 0.0 minutes
2023-09-05 16:01:06,669:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:06,670:INFO:Initializing create_model()
2023-09-05 16:01:06,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:06,670:INFO:Checking exceptions
2023-09-05 16:01:06,670:INFO:Importing libraries
2023-09-05 16:01:06,670:INFO:Copying training dataset
2023-09-05 16:01:06,672:INFO:Defining folds
2023-09-05 16:01:06,672:INFO:Declaring metric variables
2023-09-05 16:01:06,672:INFO:Importing untrained model
2023-09-05 16:01:06,679:INFO:Logistic Regression Imported successfully
2023-09-05 16:01:06,684:INFO:Starting cross validation
2023-09-05 16:01:06,684:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:08,256:INFO:Calculating mean and std
2023-09-05 16:01:08,256:INFO:Creating metrics dataframe
2023-09-05 16:01:08,262:INFO:Uploading results into container
2023-09-05 16:01:08,263:INFO:Uploading model into container now
2023-09-05 16:01:08,263:INFO:_master_model_container: 16
2023-09-05 16:01:08,263:INFO:_display_container: 3
2023-09-05 16:01:08,264:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-05 16:01:08,264:INFO:create_model() successfully completed......................................
2023-09-05 16:01:08,438:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:08,438:INFO:Creating metrics dataframe
2023-09-05 16:01:08,454:INFO:Initializing K Neighbors Classifier
2023-09-05 16:01:08,454:INFO:Total runtime is 0.02977370818456014 minutes
2023-09-05 16:01:08,454:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:08,454:INFO:Initializing create_model()
2023-09-05 16:01:08,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:08,454:INFO:Checking exceptions
2023-09-05 16:01:08,454:INFO:Importing libraries
2023-09-05 16:01:08,454:INFO:Copying training dataset
2023-09-05 16:01:08,461:INFO:Defining folds
2023-09-05 16:01:08,461:INFO:Declaring metric variables
2023-09-05 16:01:08,463:INFO:Importing untrained model
2023-09-05 16:01:08,465:INFO:K Neighbors Classifier Imported successfully
2023-09-05 16:01:08,471:INFO:Starting cross validation
2023-09-05 16:01:08,472:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:09,740:INFO:Calculating mean and std
2023-09-05 16:01:09,740:INFO:Creating metrics dataframe
2023-09-05 16:01:09,746:INFO:Uploading results into container
2023-09-05 16:01:09,746:INFO:Uploading model into container now
2023-09-05 16:01:09,747:INFO:_master_model_container: 17
2023-09-05 16:01:09,747:INFO:_display_container: 3
2023-09-05 16:01:09,747:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-05 16:01:09,747:INFO:create_model() successfully completed......................................
2023-09-05 16:01:09,920:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:09,920:INFO:Creating metrics dataframe
2023-09-05 16:01:09,920:INFO:Initializing Naive Bayes
2023-09-05 16:01:09,920:INFO:Total runtime is 0.054219023386637366 minutes
2023-09-05 16:01:09,920:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:09,920:INFO:Initializing create_model()
2023-09-05 16:01:09,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:09,920:INFO:Checking exceptions
2023-09-05 16:01:09,920:INFO:Importing libraries
2023-09-05 16:01:09,920:INFO:Copying training dataset
2023-09-05 16:01:09,932:INFO:Defining folds
2023-09-05 16:01:09,932:INFO:Declaring metric variables
2023-09-05 16:01:09,934:INFO:Importing untrained model
2023-09-05 16:01:09,937:INFO:Naive Bayes Imported successfully
2023-09-05 16:01:09,940:INFO:Starting cross validation
2023-09-05 16:01:09,943:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:11,141:INFO:Calculating mean and std
2023-09-05 16:01:11,141:INFO:Creating metrics dataframe
2023-09-05 16:01:11,150:INFO:Uploading results into container
2023-09-05 16:01:11,151:INFO:Uploading model into container now
2023-09-05 16:01:11,151:INFO:_master_model_container: 18
2023-09-05 16:01:11,151:INFO:_display_container: 3
2023-09-05 16:01:11,151:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-05 16:01:11,151:INFO:create_model() successfully completed......................................
2023-09-05 16:01:11,320:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:11,320:INFO:Creating metrics dataframe
2023-09-05 16:01:11,336:INFO:Initializing Decision Tree Classifier
2023-09-05 16:01:11,336:INFO:Total runtime is 0.0778118371963501 minutes
2023-09-05 16:01:11,336:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:11,336:INFO:Initializing create_model()
2023-09-05 16:01:11,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:11,336:INFO:Checking exceptions
2023-09-05 16:01:11,336:INFO:Importing libraries
2023-09-05 16:01:11,336:INFO:Copying training dataset
2023-09-05 16:01:11,342:INFO:Defining folds
2023-09-05 16:01:11,342:INFO:Declaring metric variables
2023-09-05 16:01:11,345:INFO:Importing untrained model
2023-09-05 16:01:11,347:INFO:Decision Tree Classifier Imported successfully
2023-09-05 16:01:11,350:INFO:Starting cross validation
2023-09-05 16:01:11,350:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:12,536:INFO:Calculating mean and std
2023-09-05 16:01:12,536:INFO:Creating metrics dataframe
2023-09-05 16:01:12,543:INFO:Uploading results into container
2023-09-05 16:01:12,544:INFO:Uploading model into container now
2023-09-05 16:01:12,544:INFO:_master_model_container: 19
2023-09-05 16:01:12,544:INFO:_display_container: 3
2023-09-05 16:01:12,545:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 16:01:12,545:INFO:create_model() successfully completed......................................
2023-09-05 16:01:12,710:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:12,710:INFO:Creating metrics dataframe
2023-09-05 16:01:12,726:INFO:Initializing SVM - Linear Kernel
2023-09-05 16:01:12,726:INFO:Total runtime is 0.10098056793212891 minutes
2023-09-05 16:01:12,726:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:12,726:INFO:Initializing create_model()
2023-09-05 16:01:12,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:12,726:INFO:Checking exceptions
2023-09-05 16:01:12,726:INFO:Importing libraries
2023-09-05 16:01:12,726:INFO:Copying training dataset
2023-09-05 16:01:12,739:INFO:Defining folds
2023-09-05 16:01:12,739:INFO:Declaring metric variables
2023-09-05 16:01:12,741:INFO:Importing untrained model
2023-09-05 16:01:12,744:INFO:SVM - Linear Kernel Imported successfully
2023-09-05 16:01:12,746:INFO:Starting cross validation
2023-09-05 16:01:12,746:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:13,881:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 16:01:13,897:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 16:01:13,897:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 16:01:13,912:INFO:Calculating mean and std
2023-09-05 16:01:13,912:INFO:Creating metrics dataframe
2023-09-05 16:01:13,920:INFO:Uploading results into container
2023-09-05 16:01:13,920:INFO:Uploading model into container now
2023-09-05 16:01:13,921:INFO:_master_model_container: 20
2023-09-05 16:01:13,921:INFO:_display_container: 3
2023-09-05 16:01:13,921:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-05 16:01:13,921:INFO:create_model() successfully completed......................................
2023-09-05 16:01:14,088:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:14,088:INFO:Creating metrics dataframe
2023-09-05 16:01:14,103:INFO:Initializing Ridge Classifier
2023-09-05 16:01:14,103:INFO:Total runtime is 0.12393848896026612 minutes
2023-09-05 16:01:14,103:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:14,103:INFO:Initializing create_model()
2023-09-05 16:01:14,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:14,103:INFO:Checking exceptions
2023-09-05 16:01:14,103:INFO:Importing libraries
2023-09-05 16:01:14,103:INFO:Copying training dataset
2023-09-05 16:01:14,111:INFO:Defining folds
2023-09-05 16:01:14,111:INFO:Declaring metric variables
2023-09-05 16:01:14,111:INFO:Importing untrained model
2023-09-05 16:01:14,111:INFO:Ridge Classifier Imported successfully
2023-09-05 16:01:14,111:INFO:Starting cross validation
2023-09-05 16:01:14,111:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:14,145:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 16:01:14,145:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 16:01:15,135:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 16:01:15,167:INFO:Calculating mean and std
2023-09-05 16:01:15,167:INFO:Creating metrics dataframe
2023-09-05 16:01:15,172:INFO:Uploading results into container
2023-09-05 16:01:15,172:INFO:Uploading model into container now
2023-09-05 16:01:15,173:INFO:_master_model_container: 21
2023-09-05 16:01:15,173:INFO:_display_container: 3
2023-09-05 16:01:15,173:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-05 16:01:15,173:INFO:create_model() successfully completed......................................
2023-09-05 16:01:15,337:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:15,337:INFO:Creating metrics dataframe
2023-09-05 16:01:15,352:INFO:Initializing Random Forest Classifier
2023-09-05 16:01:15,352:INFO:Total runtime is 0.14475505352020263 minutes
2023-09-05 16:01:15,354:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:15,354:INFO:Initializing create_model()
2023-09-05 16:01:15,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:15,354:INFO:Checking exceptions
2023-09-05 16:01:15,354:INFO:Importing libraries
2023-09-05 16:01:15,354:INFO:Copying training dataset
2023-09-05 16:01:15,357:INFO:Defining folds
2023-09-05 16:01:15,357:INFO:Declaring metric variables
2023-09-05 16:01:15,360:INFO:Importing untrained model
2023-09-05 16:01:15,362:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:01:15,364:INFO:Starting cross validation
2023-09-05 16:01:15,364:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:15,554:INFO:Calculating mean and std
2023-09-05 16:01:15,554:INFO:Creating metrics dataframe
2023-09-05 16:01:15,559:INFO:Uploading results into container
2023-09-05 16:01:15,560:INFO:Uploading model into container now
2023-09-05 16:01:15,560:INFO:_master_model_container: 22
2023-09-05 16:01:15,560:INFO:_display_container: 3
2023-09-05 16:01:15,560:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:01:15,560:INFO:create_model() successfully completed......................................
2023-09-05 16:01:15,726:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:15,726:INFO:Creating metrics dataframe
2023-09-05 16:01:15,726:INFO:Initializing Quadratic Discriminant Analysis
2023-09-05 16:01:15,726:INFO:Total runtime is 0.1509807785352071 minutes
2023-09-05 16:01:15,742:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:15,742:INFO:Initializing create_model()
2023-09-05 16:01:15,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:15,742:INFO:Checking exceptions
2023-09-05 16:01:15,742:INFO:Importing libraries
2023-09-05 16:01:15,742:INFO:Copying training dataset
2023-09-05 16:01:15,745:INFO:Defining folds
2023-09-05 16:01:15,745:INFO:Declaring metric variables
2023-09-05 16:01:15,747:INFO:Importing untrained model
2023-09-05 16:01:15,749:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-05 16:01:15,754:INFO:Starting cross validation
2023-09-05 16:01:15,754:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:15,810:INFO:Calculating mean and std
2023-09-05 16:01:15,810:INFO:Creating metrics dataframe
2023-09-05 16:01:15,814:INFO:Uploading results into container
2023-09-05 16:01:15,814:INFO:Uploading model into container now
2023-09-05 16:01:15,815:INFO:_master_model_container: 23
2023-09-05 16:01:15,815:INFO:_display_container: 3
2023-09-05 16:01:15,815:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-05 16:01:15,815:INFO:create_model() successfully completed......................................
2023-09-05 16:01:15,976:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:15,976:INFO:Creating metrics dataframe
2023-09-05 16:01:15,976:INFO:Initializing Ada Boost Classifier
2023-09-05 16:01:15,976:INFO:Total runtime is 0.15515221357345582 minutes
2023-09-05 16:01:15,992:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:15,992:INFO:Initializing create_model()
2023-09-05 16:01:15,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:15,992:INFO:Checking exceptions
2023-09-05 16:01:15,992:INFO:Importing libraries
2023-09-05 16:01:15,992:INFO:Copying training dataset
2023-09-05 16:01:15,997:INFO:Defining folds
2023-09-05 16:01:15,997:INFO:Declaring metric variables
2023-09-05 16:01:15,999:INFO:Importing untrained model
2023-09-05 16:01:16,002:INFO:Ada Boost Classifier Imported successfully
2023-09-05 16:01:16,006:INFO:Starting cross validation
2023-09-05 16:01:16,007:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:16,141:INFO:Calculating mean and std
2023-09-05 16:01:16,141:INFO:Creating metrics dataframe
2023-09-05 16:01:16,146:INFO:Uploading results into container
2023-09-05 16:01:16,146:INFO:Uploading model into container now
2023-09-05 16:01:16,146:INFO:_master_model_container: 24
2023-09-05 16:01:16,146:INFO:_display_container: 3
2023-09-05 16:01:16,147:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-05 16:01:16,147:INFO:create_model() successfully completed......................................
2023-09-05 16:01:16,305:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:16,305:INFO:Creating metrics dataframe
2023-09-05 16:01:16,320:INFO:Initializing Gradient Boosting Classifier
2023-09-05 16:01:16,320:INFO:Total runtime is 0.16088492075602215 minutes
2023-09-05 16:01:16,320:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:16,320:INFO:Initializing create_model()
2023-09-05 16:01:16,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:16,320:INFO:Checking exceptions
2023-09-05 16:01:16,320:INFO:Importing libraries
2023-09-05 16:01:16,320:INFO:Copying training dataset
2023-09-05 16:01:16,331:INFO:Defining folds
2023-09-05 16:01:16,331:INFO:Declaring metric variables
2023-09-05 16:01:16,333:INFO:Importing untrained model
2023-09-05 16:01:16,336:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 16:01:16,340:INFO:Starting cross validation
2023-09-05 16:01:16,340:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:16,489:INFO:Calculating mean and std
2023-09-05 16:01:16,489:INFO:Creating metrics dataframe
2023-09-05 16:01:16,494:INFO:Uploading results into container
2023-09-05 16:01:16,494:INFO:Uploading model into container now
2023-09-05 16:01:16,495:INFO:_master_model_container: 25
2023-09-05 16:01:16,495:INFO:_display_container: 3
2023-09-05 16:01:16,495:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 16:01:16,495:INFO:create_model() successfully completed......................................
2023-09-05 16:01:16,664:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:16,664:INFO:Creating metrics dataframe
2023-09-05 16:01:16,664:INFO:Initializing Linear Discriminant Analysis
2023-09-05 16:01:16,664:INFO:Total runtime is 0.16661912600199383 minutes
2023-09-05 16:01:16,664:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:16,664:INFO:Initializing create_model()
2023-09-05 16:01:16,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:16,664:INFO:Checking exceptions
2023-09-05 16:01:16,664:INFO:Importing libraries
2023-09-05 16:01:16,664:INFO:Copying training dataset
2023-09-05 16:01:16,677:INFO:Defining folds
2023-09-05 16:01:16,677:INFO:Declaring metric variables
2023-09-05 16:01:16,679:INFO:Importing untrained model
2023-09-05 16:01:16,681:INFO:Linear Discriminant Analysis Imported successfully
2023-09-05 16:01:16,685:INFO:Starting cross validation
2023-09-05 16:01:16,685:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:16,747:INFO:Calculating mean and std
2023-09-05 16:01:16,747:INFO:Creating metrics dataframe
2023-09-05 16:01:16,750:INFO:Uploading results into container
2023-09-05 16:01:16,751:INFO:Uploading model into container now
2023-09-05 16:01:16,751:INFO:_master_model_container: 26
2023-09-05 16:01:16,751:INFO:_display_container: 3
2023-09-05 16:01:16,751:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-05 16:01:16,751:INFO:create_model() successfully completed......................................
2023-09-05 16:01:16,918:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:16,918:INFO:Creating metrics dataframe
2023-09-05 16:01:16,918:INFO:Initializing Extra Trees Classifier
2023-09-05 16:01:16,918:INFO:Total runtime is 0.17084158658981324 minutes
2023-09-05 16:01:16,918:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:16,918:INFO:Initializing create_model()
2023-09-05 16:01:16,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:16,918:INFO:Checking exceptions
2023-09-05 16:01:16,918:INFO:Importing libraries
2023-09-05 16:01:16,918:INFO:Copying training dataset
2023-09-05 16:01:16,931:INFO:Defining folds
2023-09-05 16:01:16,931:INFO:Declaring metric variables
2023-09-05 16:01:16,933:INFO:Importing untrained model
2023-09-05 16:01:16,937:INFO:Extra Trees Classifier Imported successfully
2023-09-05 16:01:16,941:INFO:Starting cross validation
2023-09-05 16:01:16,943:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:17,198:INFO:Calculating mean and std
2023-09-05 16:01:17,199:INFO:Creating metrics dataframe
2023-09-05 16:01:17,203:INFO:Uploading results into container
2023-09-05 16:01:17,203:INFO:Uploading model into container now
2023-09-05 16:01:17,203:INFO:_master_model_container: 27
2023-09-05 16:01:17,203:INFO:_display_container: 3
2023-09-05 16:01:17,204:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:01:17,204:INFO:create_model() successfully completed......................................
2023-09-05 16:01:17,370:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:17,370:INFO:Creating metrics dataframe
2023-09-05 16:01:17,370:INFO:Initializing Extreme Gradient Boosting
2023-09-05 16:01:17,370:INFO:Total runtime is 0.17838665246963503 minutes
2023-09-05 16:01:17,370:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:17,370:INFO:Initializing create_model()
2023-09-05 16:01:17,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:17,370:INFO:Checking exceptions
2023-09-05 16:01:17,370:INFO:Importing libraries
2023-09-05 16:01:17,370:INFO:Copying training dataset
2023-09-05 16:01:17,388:INFO:Defining folds
2023-09-05 16:01:17,388:INFO:Declaring metric variables
2023-09-05 16:01:17,390:INFO:Importing untrained model
2023-09-05 16:01:17,393:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 16:01:17,397:INFO:Starting cross validation
2023-09-05 16:01:17,397:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:17,525:INFO:Calculating mean and std
2023-09-05 16:01:17,525:INFO:Creating metrics dataframe
2023-09-05 16:01:17,531:INFO:Uploading results into container
2023-09-05 16:01:17,531:INFO:Uploading model into container now
2023-09-05 16:01:17,531:INFO:_master_model_container: 28
2023-09-05 16:01:17,532:INFO:_display_container: 3
2023-09-05 16:01:17,532:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 16:01:17,532:INFO:create_model() successfully completed......................................
2023-09-05 16:01:17,694:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:17,694:INFO:Creating metrics dataframe
2023-09-05 16:01:17,709:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 16:01:17,709:INFO:Total runtime is 0.18403608401616417 minutes
2023-09-05 16:01:17,711:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:17,712:INFO:Initializing create_model()
2023-09-05 16:01:17,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:17,712:INFO:Checking exceptions
2023-09-05 16:01:17,712:INFO:Importing libraries
2023-09-05 16:01:17,712:INFO:Copying training dataset
2023-09-05 16:01:17,714:INFO:Defining folds
2023-09-05 16:01:17,715:INFO:Declaring metric variables
2023-09-05 16:01:17,717:INFO:Importing untrained model
2023-09-05 16:01:17,720:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 16:01:17,727:INFO:Starting cross validation
2023-09-05 16:01:17,728:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:17,944:INFO:Calculating mean and std
2023-09-05 16:01:17,944:INFO:Creating metrics dataframe
2023-09-05 16:01:17,950:INFO:Uploading results into container
2023-09-05 16:01:17,950:INFO:Uploading model into container now
2023-09-05 16:01:17,950:INFO:_master_model_container: 29
2023-09-05 16:01:17,950:INFO:_display_container: 3
2023-09-05 16:01:17,950:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 16:01:17,950:INFO:create_model() successfully completed......................................
2023-09-05 16:01:18,136:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:18,136:INFO:Creating metrics dataframe
2023-09-05 16:01:18,151:INFO:Initializing Dummy Classifier
2023-09-05 16:01:18,151:INFO:Total runtime is 0.19140220483144127 minutes
2023-09-05 16:01:18,151:INFO:SubProcess create_model() called ==================================
2023-09-05 16:01:18,151:INFO:Initializing create_model()
2023-09-05 16:01:18,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5E95CF40>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:18,151:INFO:Checking exceptions
2023-09-05 16:01:18,151:INFO:Importing libraries
2023-09-05 16:01:18,151:INFO:Copying training dataset
2023-09-05 16:01:18,159:INFO:Defining folds
2023-09-05 16:01:18,160:INFO:Declaring metric variables
2023-09-05 16:01:18,162:INFO:Importing untrained model
2023-09-05 16:01:18,164:INFO:Dummy Classifier Imported successfully
2023-09-05 16:01:18,171:INFO:Starting cross validation
2023-09-05 16:01:18,171:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:01:18,201:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 16:01:18,201:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 16:01:18,212:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 16:01:18,216:INFO:Calculating mean and std
2023-09-05 16:01:18,216:INFO:Creating metrics dataframe
2023-09-05 16:01:18,220:INFO:Uploading results into container
2023-09-05 16:01:18,220:INFO:Uploading model into container now
2023-09-05 16:01:18,221:INFO:_master_model_container: 30
2023-09-05 16:01:18,221:INFO:_display_container: 3
2023-09-05 16:01:18,221:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-05 16:01:18,221:INFO:create_model() successfully completed......................................
2023-09-05 16:01:18,385:INFO:SubProcess create_model() end ==================================
2023-09-05 16:01:18,385:INFO:Creating metrics dataframe
2023-09-05 16:01:18,401:INFO:Initializing create_model()
2023-09-05 16:01:18,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:18,401:INFO:Checking exceptions
2023-09-05 16:01:18,403:INFO:Importing libraries
2023-09-05 16:01:18,403:INFO:Copying training dataset
2023-09-05 16:01:18,405:INFO:Defining folds
2023-09-05 16:01:18,405:INFO:Declaring metric variables
2023-09-05 16:01:18,405:INFO:Importing untrained model
2023-09-05 16:01:18,406:INFO:Declaring custom model
2023-09-05 16:01:18,406:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 16:01:18,406:INFO:Cross validation set to False
2023-09-05 16:01:18,406:INFO:Fitting Model
2023-09-05 16:01:18,478:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 16:01:18,478:INFO:create_model() successfully completed......................................
2023-09-05 16:01:18,661:INFO:Initializing create_model()
2023-09-05 16:01:18,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:18,661:INFO:Checking exceptions
2023-09-05 16:01:18,662:INFO:Importing libraries
2023-09-05 16:01:18,662:INFO:Copying training dataset
2023-09-05 16:01:18,664:INFO:Defining folds
2023-09-05 16:01:18,664:INFO:Declaring metric variables
2023-09-05 16:01:18,665:INFO:Importing untrained model
2023-09-05 16:01:18,665:INFO:Declaring custom model
2023-09-05 16:01:18,665:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 16:01:18,666:INFO:Cross validation set to False
2023-09-05 16:01:18,666:INFO:Fitting Model
2023-09-05 16:01:18,678:INFO:[LightGBM] [Info] Number of positive: 273, number of negative: 439
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.
2023-09-05 16:01:18,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-09-05 16:01:18,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-09-05 16:01:18,678:INFO:[LightGBM] [Info] Total Bins 274
2023-09-05 16:01:18,678:INFO:[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9
2023-09-05 16:01:18,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028
2023-09-05 16:01:18,678:INFO:[LightGBM] [Info] Start training from score -0.475028
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 16:01:18,714:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 16:01:18,714:INFO:create_model() successfully completed......................................
2023-09-05 16:01:18,916:INFO:Initializing create_model()
2023-09-05 16:01:18,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:01:18,916:INFO:Checking exceptions
2023-09-05 16:01:18,916:INFO:Importing libraries
2023-09-05 16:01:18,916:INFO:Copying training dataset
2023-09-05 16:01:18,916:INFO:Defining folds
2023-09-05 16:01:18,916:INFO:Declaring metric variables
2023-09-05 16:01:18,916:INFO:Importing untrained model
2023-09-05 16:01:18,916:INFO:Declaring custom model
2023-09-05 16:01:18,923:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 16:01:18,923:INFO:Cross validation set to False
2023-09-05 16:01:18,923:INFO:Fitting Model
2023-09-05 16:01:18,972:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 16:01:18,972:INFO:create_model() successfully completed......................................
2023-09-05 16:01:19,180:INFO:_master_model_container: 30
2023-09-05 16:01:19,180:INFO:_display_container: 3
2023-09-05 16:01:19,180:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)]
2023-09-05 16:01:19,180:INFO:compare_models() successfully completed......................................
2023-09-05 16:09:33,704:INFO:Initializing create_model()
2023-09-05 16:09:33,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 16:09:33,704:INFO:Checking exceptions
2023-09-05 16:09:33,714:INFO:Importing libraries
2023-09-05 16:09:33,715:INFO:Copying training dataset
2023-09-05 16:09:33,718:INFO:Defining folds
2023-09-05 16:09:33,718:INFO:Declaring metric variables
2023-09-05 16:09:33,720:INFO:Importing untrained model
2023-09-05 16:09:33,720:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:09:33,729:INFO:Starting cross validation
2023-09-05 16:09:33,730:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:09:35,498:INFO:Calculating mean and std
2023-09-05 16:09:35,498:INFO:Creating metrics dataframe
2023-09-05 16:09:35,498:INFO:Finalizing model
2023-09-05 16:09:35,695:INFO:Uploading results into container
2023-09-05 16:09:35,696:INFO:Uploading model into container now
2023-09-05 16:09:35,698:INFO:_master_model_container: 31
2023-09-05 16:09:35,698:INFO:_display_container: 4
2023-09-05 16:09:35,698:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:09:35,698:INFO:create_model() successfully completed......................................
2023-09-05 16:21:47,149:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
81 fits failed out of a total of 243.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
81 fits failed with the following error:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-05 16:21:47,165:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.82640781 0.82446119 0.82910863
 0.82198674 0.82339939 0.82716743        nan        nan        nan
 0.81679283 0.81597282 0.81943746 0.81679283 0.81597282 0.81943746
        nan        nan        nan 0.81233521 0.81839286 0.82008449
 0.81233521 0.81839286 0.82008449        nan        nan        nan
 0.81663056 0.82017159 0.82347408 0.81699778 0.82166718 0.82805769
        nan        nan        nan 0.81902096 0.82323328 0.8171695
 0.81902096 0.82323328 0.8171695         nan        nan        nan
 0.81606809 0.81418775 0.82010011 0.81606809 0.81418775 0.82010011
        nan        nan        nan 0.8155491  0.82476856 0.82477001
 0.81833536 0.82407055 0.82824495        nan        nan        nan
 0.81902096 0.82431304 0.8160722  0.81902096 0.82431304 0.8160722
        nan        nan        nan 0.81606809 0.81418775 0.82010011
 0.81606809 0.81418775 0.82010011]
  warnings.warn(

2023-09-05 16:44:18,952:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
54 fits failed out of a total of 162.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
54 fits failed with the following error:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-05 16:44:18,952:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.8269024  0.82910863 0.82776029
 0.82842971 0.82716743 0.82716939        nan        nan        nan
 0.81913674 0.81943746 0.81668302 0.81913674 0.81943746 0.81668302
        nan        nan        nan 0.82008449 0.82008449 0.81761532
 0.82008449 0.82008449 0.81761532        nan        nan        nan
 0.82237992 0.82347408 0.82607924 0.82805769 0.82805769 0.82408002
        nan        nan        nan 0.81491809 0.8171695  0.81795215
 0.81491809 0.8171695  0.81795215        nan        nan        nan
 0.81662607 0.82010011 0.82007409 0.81662607 0.82010011 0.82007409]
  warnings.warn(

2023-09-05 16:45:58,197:INFO:Initializing create_model()
2023-09-05 16:45:58,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 16:45:58,198:INFO:Checking exceptions
2023-09-05 16:45:58,207:INFO:Importing libraries
2023-09-05 16:45:58,207:INFO:Copying training dataset
2023-09-05 16:45:58,210:INFO:Defining folds
2023-09-05 16:45:58,210:INFO:Declaring metric variables
2023-09-05 16:45:58,214:INFO:Importing untrained model
2023-09-05 16:45:58,216:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:45:58,223:INFO:Starting cross validation
2023-09-05 16:45:58,224:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:45:59,890:INFO:Calculating mean and std
2023-09-05 16:45:59,890:INFO:Creating metrics dataframe
2023-09-05 16:45:59,890:INFO:Finalizing model
2023-09-05 16:45:59,933:INFO:Uploading results into container
2023-09-05 16:45:59,934:INFO:Uploading model into container now
2023-09-05 16:45:59,939:INFO:_master_model_container: 32
2023-09-05 16:45:59,939:INFO:_display_container: 5
2023-09-05 16:45:59,940:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:45:59,940:INFO:create_model() successfully completed......................................
2023-09-05 16:46:10,560:INFO:Initializing create_model()
2023-09-05 16:46:10,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 16:46:10,560:INFO:Checking exceptions
2023-09-05 16:46:10,575:INFO:Importing libraries
2023-09-05 16:46:10,575:INFO:Copying training dataset
2023-09-05 16:46:10,578:INFO:Defining folds
2023-09-05 16:46:10,579:INFO:Declaring metric variables
2023-09-05 16:46:10,580:INFO:Importing untrained model
2023-09-05 16:46:10,580:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:46:10,591:INFO:Starting cross validation
2023-09-05 16:46:10,591:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:46:12,591:INFO:Calculating mean and std
2023-09-05 16:46:12,592:INFO:Creating metrics dataframe
2023-09-05 16:46:12,595:INFO:Finalizing model
2023-09-05 16:46:13,045:INFO:Uploading results into container
2023-09-05 16:46:13,045:INFO:Uploading model into container now
2023-09-05 16:46:13,049:INFO:_master_model_container: 33
2023-09-05 16:46:13,049:INFO:_display_container: 6
2023-09-05 16:46:13,054:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:46:13,054:INFO:create_model() successfully completed......................................
2023-09-05 16:47:00,909:INFO:Initializing create_model()
2023-09-05 16:47:00,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 16:47:00,910:INFO:Checking exceptions
2023-09-05 16:47:00,919:INFO:Importing libraries
2023-09-05 16:47:00,919:INFO:Copying training dataset
2023-09-05 16:47:00,923:INFO:Defining folds
2023-09-05 16:47:00,923:INFO:Declaring metric variables
2023-09-05 16:47:00,926:INFO:Importing untrained model
2023-09-05 16:47:00,929:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:47:00,933:INFO:Starting cross validation
2023-09-05 16:47:00,934:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:47:02,656:INFO:Calculating mean and std
2023-09-05 16:47:02,656:INFO:Creating metrics dataframe
2023-09-05 16:47:02,663:INFO:Finalizing model
2023-09-05 16:47:03,011:INFO:Uploading results into container
2023-09-05 16:47:03,012:INFO:Uploading model into container now
2023-09-05 16:47:03,014:INFO:_master_model_container: 34
2023-09-05 16:47:03,014:INFO:_display_container: 7
2023-09-05 16:47:03,014:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:47:03,014:INFO:create_model() successfully completed......................................
2023-09-05 16:49:14,228:INFO:Initializing tune_model()
2023-09-05 16:49:14,228:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [150, 200, 250], 'max_depth': [10, 20], 'min_samples_split': [1, 2, 3], 'min_samples_leaf': [1, 2, 3]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>)
2023-09-05 16:49:14,228:INFO:Checking exceptions
2023-09-05 16:49:14,238:INFO:Copying training dataset
2023-09-05 16:49:14,240:INFO:Checking base model
2023-09-05 16:49:14,241:INFO:Base model : Random Forest Classifier
2023-09-05 16:49:14,243:INFO:Declaring metric variables
2023-09-05 16:49:14,245:INFO:Defining Hyperparameters
2023-09-05 16:49:14,430:INFO:custom_grid: {'actual_estimator__n_estimators': [150, 200, 250], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2, 3], 'actual_estimator__min_samples_leaf': [1, 2, 3]}
2023-09-05 16:49:14,430:INFO:Tuning with n_jobs=-1
2023-09-05 16:49:14,430:INFO:Initializing RandomizedSearchCV
2023-09-05 16:49:17,178:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
12 fits failed out of a total of 30.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
12 fits failed with the following error:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\AI\pythonProject\venv\lib\site-packages\joblib\memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-05 16:49:17,178:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8033838         nan        nan 0.82725242 0.81741895 0.81881951
 0.81881951        nan 0.80899195        nan]
  warnings.warn(

2023-09-05 16:49:17,178:INFO:best_params: {'actual_estimator__n_estimators': 250, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-05 16:49:17,178:INFO:Hyperparameter search completed
2023-09-05 16:49:17,178:INFO:SubProcess create_model() called ==================================
2023-09-05 16:49:17,178:INFO:Initializing create_model()
2023-09-05 16:49:17,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A641FFC70>, model_only=True, return_train_score=False, kwargs={'n_estimators': 250, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-05 16:49:17,178:INFO:Checking exceptions
2023-09-05 16:49:17,178:INFO:Importing libraries
2023-09-05 16:49:17,178:INFO:Copying training dataset
2023-09-05 16:49:17,194:INFO:Defining folds
2023-09-05 16:49:17,194:INFO:Declaring metric variables
2023-09-05 16:49:17,196:INFO:Importing untrained model
2023-09-05 16:49:17,196:INFO:Declaring custom model
2023-09-05 16:49:17,196:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:49:17,205:INFO:Starting cross validation
2023-09-05 16:49:17,206:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:49:17,520:INFO:Calculating mean and std
2023-09-05 16:49:17,520:INFO:Creating metrics dataframe
2023-09-05 16:49:17,520:INFO:Finalizing model
2023-09-05 16:49:17,924:INFO:Uploading results into container
2023-09-05 16:49:17,924:INFO:Uploading model into container now
2023-09-05 16:49:17,925:INFO:_master_model_container: 35
2023-09-05 16:49:17,925:INFO:_display_container: 8
2023-09-05 16:49:17,925:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:49:17,925:INFO:create_model() successfully completed......................................
2023-09-05 16:49:18,107:INFO:SubProcess create_model() end ==================================
2023-09-05 16:49:18,107:INFO:choose_better activated
2023-09-05 16:49:18,107:INFO:SubProcess create_model() called ==================================
2023-09-05 16:49:18,107:INFO:Initializing create_model()
2023-09-05 16:49:18,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:49:18,107:INFO:Checking exceptions
2023-09-05 16:49:18,119:INFO:Importing libraries
2023-09-05 16:49:18,119:INFO:Copying training dataset
2023-09-05 16:49:18,121:INFO:Defining folds
2023-09-05 16:49:18,121:INFO:Declaring metric variables
2023-09-05 16:49:18,121:INFO:Importing untrained model
2023-09-05 16:49:18,121:INFO:Declaring custom model
2023-09-05 16:49:18,122:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:49:18,122:INFO:Starting cross validation
2023-09-05 16:49:18,122:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:49:18,394:INFO:Calculating mean and std
2023-09-05 16:49:18,394:INFO:Creating metrics dataframe
2023-09-05 16:49:18,394:INFO:Finalizing model
2023-09-05 16:49:18,441:INFO:Uploading results into container
2023-09-05 16:49:18,441:INFO:Uploading model into container now
2023-09-05 16:49:18,441:INFO:_master_model_container: 36
2023-09-05 16:49:18,441:INFO:_display_container: 9
2023-09-05 16:49:18,441:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:49:18,441:INFO:create_model() successfully completed......................................
2023-09-05 16:49:18,629:INFO:SubProcess create_model() end ==================================
2023-09-05 16:49:18,629:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 16:49:18,629:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8273
2023-09-05 16:49:18,629:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 16:49:18,629:INFO:choose_better completed
2023-09-05 16:49:18,639:INFO:_master_model_container: 36
2023-09-05 16:49:18,639:INFO:_display_container: 8
2023-09-05 16:49:18,640:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:49:18,640:INFO:tune_model() successfully completed......................................
2023-09-05 16:53:14,595:INFO:Initializing tune_model()
2023-09-05 16:53:14,595:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [150, 200, 250], 'max_depth': [10, 20], 'min_samples_split': [1, 2, 3], 'min_samples_leaf': [1, 2, 3]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>)
2023-09-05 16:53:14,595:INFO:Checking exceptions
2023-09-05 16:53:14,606:INFO:Copying training dataset
2023-09-05 16:53:14,608:INFO:Checking base model
2023-09-05 16:53:14,608:INFO:Base model : Random Forest Classifier
2023-09-05 16:53:14,611:INFO:Declaring metric variables
2023-09-05 16:53:14,613:INFO:Defining Hyperparameters
2023-09-05 16:53:14,811:INFO:custom_grid: {'actual_estimator__n_estimators': [150, 200, 250], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2, 3], 'actual_estimator__min_samples_leaf': [1, 2, 3]}
2023-09-05 16:53:14,811:INFO:Tuning with n_jobs=-1
2023-09-05 16:53:14,811:INFO:Initializing RandomizedSearchCV
2023-09-05 16:53:15,409:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
12 fits failed out of a total of 30.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
12 fits failed with the following error:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\AI\pythonProject\venv\lib\site-packages\joblib\memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-05 16:53:15,409:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8033838         nan        nan 0.82725242 0.81741895 0.81881951
 0.81881951        nan 0.80899195        nan]
  warnings.warn(

2023-09-05 16:53:15,409:INFO:best_params: {'actual_estimator__n_estimators': 250, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-05 16:53:15,409:INFO:Hyperparameter search completed
2023-09-05 16:53:15,409:INFO:SubProcess create_model() called ==================================
2023-09-05 16:53:15,409:INFO:Initializing create_model()
2023-09-05 16:53:15,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A624C7790>, model_only=True, return_train_score=False, kwargs={'n_estimators': 250, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-05 16:53:15,409:INFO:Checking exceptions
2023-09-05 16:53:15,409:INFO:Importing libraries
2023-09-05 16:53:15,409:INFO:Copying training dataset
2023-09-05 16:53:15,425:INFO:Defining folds
2023-09-05 16:53:15,425:INFO:Declaring metric variables
2023-09-05 16:53:15,425:INFO:Importing untrained model
2023-09-05 16:53:15,425:INFO:Declaring custom model
2023-09-05 16:53:15,425:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:53:15,434:INFO:Starting cross validation
2023-09-05 16:53:15,434:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:53:15,792:INFO:Calculating mean and std
2023-09-05 16:53:15,792:INFO:Creating metrics dataframe
2023-09-05 16:53:15,792:INFO:Finalizing model
2023-09-05 16:53:15,858:INFO:Uploading results into container
2023-09-05 16:53:15,859:INFO:Uploading model into container now
2023-09-05 16:53:15,859:INFO:_master_model_container: 37
2023-09-05 16:53:15,859:INFO:_display_container: 9
2023-09-05 16:53:15,860:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:53:15,860:INFO:create_model() successfully completed......................................
2023-09-05 16:53:16,044:INFO:SubProcess create_model() end ==================================
2023-09-05 16:53:16,044:INFO:choose_better activated
2023-09-05 16:53:16,044:INFO:SubProcess create_model() called ==================================
2023-09-05 16:53:16,048:INFO:Initializing create_model()
2023-09-05 16:53:16,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:53:16,048:INFO:Checking exceptions
2023-09-05 16:53:16,050:INFO:Importing libraries
2023-09-05 16:53:16,050:INFO:Copying training dataset
2023-09-05 16:53:16,053:INFO:Defining folds
2023-09-05 16:53:16,053:INFO:Declaring metric variables
2023-09-05 16:53:16,053:INFO:Importing untrained model
2023-09-05 16:53:16,053:INFO:Declaring custom model
2023-09-05 16:53:16,053:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:53:16,053:INFO:Starting cross validation
2023-09-05 16:53:16,053:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:53:16,339:INFO:Calculating mean and std
2023-09-05 16:53:16,339:INFO:Creating metrics dataframe
2023-09-05 16:53:16,339:INFO:Finalizing model
2023-09-05 16:53:16,386:INFO:Uploading results into container
2023-09-05 16:53:16,386:INFO:Uploading model into container now
2023-09-05 16:53:16,386:INFO:_master_model_container: 38
2023-09-05 16:53:16,386:INFO:_display_container: 10
2023-09-05 16:53:16,386:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:53:16,386:INFO:create_model() successfully completed......................................
2023-09-05 16:53:16,558:INFO:SubProcess create_model() end ==================================
2023-09-05 16:53:16,558:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 16:53:16,558:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8273
2023-09-05 16:53:16,558:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 16:53:16,558:INFO:choose_better completed
2023-09-05 16:53:16,575:INFO:_master_model_container: 38
2023-09-05 16:53:16,575:INFO:_display_container: 9
2023-09-05 16:53:16,575:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:53:16,575:INFO:tune_model() successfully completed......................................
2023-09-05 16:53:37,325:INFO:Initializing tune_model()
2023-09-05 16:53:37,325:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>)
2023-09-05 16:53:37,325:INFO:Checking exceptions
2023-09-05 16:53:37,338:INFO:Copying training dataset
2023-09-05 16:53:37,339:INFO:Checking base model
2023-09-05 16:53:37,340:INFO:Base model : Random Forest Classifier
2023-09-05 16:53:37,342:INFO:Declaring metric variables
2023-09-05 16:53:37,345:INFO:Defining Hyperparameters
2023-09-05 16:53:37,529:INFO:Tuning with n_jobs=-1
2023-09-05 16:53:37,529:INFO:Initializing RandomizedSearchCV
2023-09-05 16:53:39,432:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-09-05 16:53:39,432:INFO:Hyperparameter search completed
2023-09-05 16:53:39,432:INFO:SubProcess create_model() called ==================================
2023-09-05 16:53:39,432:INFO:Initializing create_model()
2023-09-05 16:53:39,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A642C0430>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2023-09-05 16:53:39,432:INFO:Checking exceptions
2023-09-05 16:53:39,432:INFO:Importing libraries
2023-09-05 16:53:39,432:INFO:Copying training dataset
2023-09-05 16:53:39,438:INFO:Defining folds
2023-09-05 16:53:39,438:INFO:Declaring metric variables
2023-09-05 16:53:39,440:INFO:Importing untrained model
2023-09-05 16:53:39,440:INFO:Declaring custom model
2023-09-05 16:53:39,440:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:53:39,440:INFO:Starting cross validation
2023-09-05 16:53:39,440:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:53:39,691:INFO:Calculating mean and std
2023-09-05 16:53:39,691:INFO:Creating metrics dataframe
2023-09-05 16:53:39,691:INFO:Finalizing model
2023-09-05 16:53:39,990:INFO:Uploading results into container
2023-09-05 16:53:39,991:INFO:Uploading model into container now
2023-09-05 16:53:39,991:INFO:_master_model_container: 39
2023-09-05 16:53:39,991:INFO:_display_container: 10
2023-09-05 16:53:39,991:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:53:39,991:INFO:create_model() successfully completed......................................
2023-09-05 16:53:40,164:INFO:SubProcess create_model() end ==================================
2023-09-05 16:53:40,164:INFO:choose_better activated
2023-09-05 16:53:40,164:INFO:SubProcess create_model() called ==================================
2023-09-05 16:53:40,164:INFO:Initializing create_model()
2023-09-05 16:53:40,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:53:40,164:INFO:Checking exceptions
2023-09-05 16:53:40,164:INFO:Importing libraries
2023-09-05 16:53:40,164:INFO:Copying training dataset
2023-09-05 16:53:40,179:INFO:Defining folds
2023-09-05 16:53:40,179:INFO:Declaring metric variables
2023-09-05 16:53:40,179:INFO:Importing untrained model
2023-09-05 16:53:40,179:INFO:Declaring custom model
2023-09-05 16:53:40,182:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:53:40,182:INFO:Starting cross validation
2023-09-05 16:53:40,182:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:53:40,479:INFO:Calculating mean and std
2023-09-05 16:53:40,479:INFO:Creating metrics dataframe
2023-09-05 16:53:40,479:INFO:Finalizing model
2023-09-05 16:53:40,542:INFO:Uploading results into container
2023-09-05 16:53:40,542:INFO:Uploading model into container now
2023-09-05 16:53:40,542:INFO:_master_model_container: 40
2023-09-05 16:53:40,542:INFO:_display_container: 11
2023-09-05 16:53:40,542:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:53:40,542:INFO:create_model() successfully completed......................................
2023-09-05 16:53:40,729:INFO:SubProcess create_model() end ==================================
2023-09-05 16:53:40,729:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 16:53:40,729:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8244
2023-09-05 16:53:40,729:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 16:53:40,729:INFO:choose_better completed
2023-09-05 16:53:40,736:INFO:_master_model_container: 40
2023-09-05 16:53:40,736:INFO:_display_container: 10
2023-09-05 16:53:40,737:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:53:40,737:INFO:tune_model() successfully completed......................................
2023-09-05 16:54:02,709:INFO:Initializing tune_model()
2023-09-05 16:54:02,709:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>)
2023-09-05 16:54:02,709:INFO:Checking exceptions
2023-09-05 16:54:02,709:INFO:Soft dependency imported: optuna: 3.3.0
2023-09-05 16:54:02,995:INFO:Copying training dataset
2023-09-05 16:54:02,997:INFO:Checking base model
2023-09-05 16:54:02,997:INFO:Base model : Random Forest Classifier
2023-09-05 16:54:02,999:INFO:Declaring metric variables
2023-09-05 16:54:03,001:INFO:Defining Hyperparameters
2023-09-05 16:54:03,200:INFO:Tuning with n_jobs=-1
2023-09-05 16:54:03,215:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\samplers\_tpe\sampler.py:277: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-09-05 16:54:03,215:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\samplers\_tpe\sampler.py:296: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-09-05 16:54:03,215:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-09-05 16:54:03,215:INFO:Initializing optuna.integration.OptunaSearchCV
2023-09-05 16:54:03,230:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2441: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-09-05 16:54:13,090:INFO:best_params: {'actual_estimator__n_estimators': 278, 'actual_estimator__max_depth': 8, 'actual_estimator__min_impurity_decrease': 1.3345667696592218e-06, 'actual_estimator__max_features': 0.7051011324758149, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__bootstrap': True, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}}
2023-09-05 16:54:13,099:INFO:Hyperparameter search completed
2023-09-05 16:54:13,099:INFO:SubProcess create_model() called ==================================
2023-09-05 16:54:13,099:INFO:Initializing create_model()
2023-09-05 16:54:13,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A5F1A9160>, model_only=True, return_train_score=False, kwargs={'n_estimators': 278, 'max_depth': 8, 'min_impurity_decrease': 1.3345667696592218e-06, 'max_features': 0.7051011324758149, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True, 'criterion': 'entropy', 'class_weight': {}})
2023-09-05 16:54:13,099:INFO:Checking exceptions
2023-09-05 16:54:13,100:INFO:Importing libraries
2023-09-05 16:54:13,100:INFO:Copying training dataset
2023-09-05 16:54:13,102:INFO:Defining folds
2023-09-05 16:54:13,102:INFO:Declaring metric variables
2023-09-05 16:54:13,105:INFO:Importing untrained model
2023-09-05 16:54:13,105:INFO:Declaring custom model
2023-09-05 16:54:13,107:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:54:13,107:INFO:Starting cross validation
2023-09-05 16:54:13,107:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:54:13,485:INFO:Calculating mean and std
2023-09-05 16:54:13,485:INFO:Creating metrics dataframe
2023-09-05 16:54:13,485:INFO:Finalizing model
2023-09-05 16:54:13,956:INFO:Uploading results into container
2023-09-05 16:54:13,956:INFO:Uploading model into container now
2023-09-05 16:54:13,957:INFO:_master_model_container: 41
2023-09-05 16:54:13,957:INFO:_display_container: 11
2023-09-05 16:54:13,957:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=8,
                       max_features=0.7051011324758149, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.3345667696592218e-06,
                       min_samples_leaf=2, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=278,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 16:54:13,957:INFO:create_model() successfully completed......................................
2023-09-05 16:54:14,150:INFO:SubProcess create_model() end ==================================
2023-09-05 16:54:14,150:INFO:choose_better activated
2023-09-05 16:54:14,153:INFO:SubProcess create_model() called ==================================
2023-09-05 16:54:14,153:INFO:Initializing create_model()
2023-09-05 16:54:14,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:54:14,153:INFO:Checking exceptions
2023-09-05 16:54:14,154:INFO:Importing libraries
2023-09-05 16:54:14,154:INFO:Copying training dataset
2023-09-05 16:54:14,155:INFO:Defining folds
2023-09-05 16:54:14,155:INFO:Declaring metric variables
2023-09-05 16:54:14,155:INFO:Importing untrained model
2023-09-05 16:54:14,155:INFO:Declaring custom model
2023-09-05 16:54:14,155:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:54:14,157:INFO:Starting cross validation
2023-09-05 16:54:14,157:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:54:14,470:INFO:Calculating mean and std
2023-09-05 16:54:14,470:INFO:Creating metrics dataframe
2023-09-05 16:54:14,470:INFO:Finalizing model
2023-09-05 16:54:14,533:INFO:Uploading results into container
2023-09-05 16:54:14,533:INFO:Uploading model into container now
2023-09-05 16:54:14,533:INFO:_master_model_container: 42
2023-09-05 16:54:14,533:INFO:_display_container: 12
2023-09-05 16:54:14,533:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:54:14,533:INFO:create_model() successfully completed......................................
2023-09-05 16:54:14,723:INFO:SubProcess create_model() end ==================================
2023-09-05 16:54:14,723:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 16:54:14,723:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=8,
                       max_features=0.7051011324758149, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.3345667696592218e-06,
                       min_samples_leaf=2, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=278,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8258
2023-09-05 16:54:14,723:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=8,
                       max_features=0.7051011324758149, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.3345667696592218e-06,
                       min_samples_leaf=2, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=278,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) is best model
2023-09-05 16:54:14,723:INFO:choose_better completed
2023-09-05 16:54:14,740:INFO:_master_model_container: 42
2023-09-05 16:54:14,740:INFO:_display_container: 11
2023-09-05 16:54:14,740:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=8,
                       max_features=0.7051011324758149, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.3345667696592218e-06,
                       min_samples_leaf=2, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=278,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 16:54:14,740:INFO:tune_model() successfully completed......................................
2023-09-05 16:58:04,140:INFO:Initializing tune_model()
2023-09-05 16:58:04,140:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>)
2023-09-05 16:58:04,140:INFO:Checking exceptions
2023-09-05 16:58:04,140:INFO:Soft dependency imported: skopt: 0.9.0
2023-09-05 16:58:04,202:INFO:Copying training dataset
2023-09-05 16:58:04,204:INFO:Checking base model
2023-09-05 16:58:04,204:INFO:Base model : Random Forest Classifier
2023-09-05 16:58:04,207:INFO:Declaring metric variables
2023-09-05 16:58:04,209:INFO:Defining Hyperparameters
2023-09-05 16:58:04,403:INFO:Tuning with n_jobs=-1
2023-09-05 16:58:04,403:INFO:Initializing skopt.BayesSearchCV
2023-09-05 16:58:09,656:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', True), ('actual_estimator__class_weight', 'balanced_subsample'), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 7), ('actual_estimator__max_features', 0.8224534830390922), ('actual_estimator__min_impurity_decrease', 3.902034183027504e-07), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 6), ('actual_estimator__n_estimators', 244)])
2023-09-05 16:58:09,656:INFO:Hyperparameter search completed
2023-09-05 16:58:09,656:INFO:SubProcess create_model() called ==================================
2023-09-05 16:58:09,656:INFO:Initializing create_model()
2023-09-05 16:58:09,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A64985250>, model_only=True, return_train_score=False, kwargs={'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_depth': 7, 'max_features': 0.8224534830390922, 'min_impurity_decrease': 3.902034183027504e-07, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 244})
2023-09-05 16:58:09,656:INFO:Checking exceptions
2023-09-05 16:58:09,656:INFO:Importing libraries
2023-09-05 16:58:09,656:INFO:Copying training dataset
2023-09-05 16:58:09,656:INFO:Defining folds
2023-09-05 16:58:09,656:INFO:Declaring metric variables
2023-09-05 16:58:09,668:INFO:Importing untrained model
2023-09-05 16:58:09,668:INFO:Declaring custom model
2023-09-05 16:58:09,669:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:58:09,669:INFO:Starting cross validation
2023-09-05 16:58:09,669:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:58:10,012:INFO:Calculating mean and std
2023-09-05 16:58:10,012:INFO:Creating metrics dataframe
2023-09-05 16:58:10,012:INFO:Finalizing model
2023-09-05 16:58:10,529:INFO:Uploading results into container
2023-09-05 16:58:10,530:INFO:Uploading model into container now
2023-09-05 16:58:10,530:INFO:_master_model_container: 43
2023-09-05 16:58:10,530:INFO:_display_container: 12
2023-09-05 16:58:10,530:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 16:58:10,530:INFO:create_model() successfully completed......................................
2023-09-05 16:58:10,712:INFO:SubProcess create_model() end ==================================
2023-09-05 16:58:10,712:INFO:choose_better activated
2023-09-05 16:58:10,725:INFO:SubProcess create_model() called ==================================
2023-09-05 16:58:10,726:INFO:Initializing create_model()
2023-09-05 16:58:10,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:58:10,727:INFO:Checking exceptions
2023-09-05 16:58:10,729:INFO:Importing libraries
2023-09-05 16:58:10,730:INFO:Copying training dataset
2023-09-05 16:58:10,734:INFO:Defining folds
2023-09-05 16:58:10,734:INFO:Declaring metric variables
2023-09-05 16:58:10,735:INFO:Importing untrained model
2023-09-05 16:58:10,735:INFO:Declaring custom model
2023-09-05 16:58:10,735:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:58:10,736:INFO:Starting cross validation
2023-09-05 16:58:10,736:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:58:11,052:INFO:Calculating mean and std
2023-09-05 16:58:11,052:INFO:Creating metrics dataframe
2023-09-05 16:58:11,052:INFO:Finalizing model
2023-09-05 16:58:11,130:INFO:Uploading results into container
2023-09-05 16:58:11,130:INFO:Uploading model into container now
2023-09-05 16:58:11,130:INFO:_master_model_container: 44
2023-09-05 16:58:11,130:INFO:_display_container: 13
2023-09-05 16:58:11,130:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:58:11,130:INFO:create_model() successfully completed......................................
2023-09-05 16:58:11,311:INFO:SubProcess create_model() end ==================================
2023-09-05 16:58:11,311:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 16:58:11,311:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8244
2023-09-05 16:58:11,311:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) is best model
2023-09-05 16:58:11,311:INFO:choose_better completed
2023-09-05 16:58:11,325:INFO:_master_model_container: 44
2023-09-05 16:58:11,325:INFO:_display_container: 12
2023-09-05 16:58:11,325:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 16:58:11,325:INFO:tune_model() successfully completed......................................
2023-09-05 17:02:43,059:INFO:Initializing tune_model()
2023-09-05 17:02:43,059:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [150, 200, 250], 'max_depth': [10, 20], 'min_samples_split': [1, 2, 3], 'min_samples_leaf': [1, 2, 3]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>)
2023-09-05 17:02:43,059:INFO:Checking exceptions
2023-09-05 17:02:43,081:INFO:Copying training dataset
2023-09-05 17:02:43,081:INFO:Checking base model
2023-09-05 17:02:43,081:INFO:Base model : Random Forest Classifier
2023-09-05 17:02:43,086:INFO:Declaring metric variables
2023-09-05 17:02:43,089:INFO:Defining Hyperparameters
2023-09-05 17:02:43,294:INFO:custom_grid: {'actual_estimator__n_estimators': [150, 200, 250], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2, 3], 'actual_estimator__min_samples_leaf': [1, 2, 3]}
2023-09-05 17:02:43,294:INFO:Tuning with n_jobs=-1
2023-09-05 17:02:43,294:INFO:Initializing RandomizedSearchCV
2023-09-05 17:02:44,465:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
12 fits failed out of a total of 30.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
12 fits failed with the following error:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\AI\pythonProject\venv\lib\site-packages\joblib\memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-05 17:02:44,465:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8033838         nan        nan 0.82725242 0.81741895 0.81881951
 0.81881951        nan 0.80899195        nan]
  warnings.warn(

2023-09-05 17:02:44,497:INFO:best_params: {'actual_estimator__n_estimators': 250, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-05 17:02:44,497:INFO:Hyperparameter search completed
2023-09-05 17:02:44,497:INFO:SubProcess create_model() called ==================================
2023-09-05 17:02:44,497:INFO:Initializing create_model()
2023-09-05 17:02:44,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012A632562E0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 250, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-05 17:02:44,497:INFO:Checking exceptions
2023-09-05 17:02:44,497:INFO:Importing libraries
2023-09-05 17:02:44,497:INFO:Copying training dataset
2023-09-05 17:02:44,497:INFO:Defining folds
2023-09-05 17:02:44,497:INFO:Declaring metric variables
2023-09-05 17:02:44,507:INFO:Importing untrained model
2023-09-05 17:02:44,507:INFO:Declaring custom model
2023-09-05 17:02:44,509:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:02:44,509:INFO:Starting cross validation
2023-09-05 17:02:44,509:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:02:44,910:INFO:Calculating mean and std
2023-09-05 17:02:44,910:INFO:Creating metrics dataframe
2023-09-05 17:02:44,915:INFO:Finalizing model
2023-09-05 17:02:45,007:INFO:Uploading results into container
2023-09-05 17:02:45,008:INFO:Uploading model into container now
2023-09-05 17:02:45,008:INFO:_master_model_container: 45
2023-09-05 17:02:45,008:INFO:_display_container: 13
2023-09-05 17:02:45,008:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:02:45,008:INFO:create_model() successfully completed......................................
2023-09-05 17:02:45,222:INFO:SubProcess create_model() end ==================================
2023-09-05 17:02:45,222:INFO:choose_better activated
2023-09-05 17:02:45,222:INFO:SubProcess create_model() called ==================================
2023-09-05 17:02:45,222:INFO:Initializing create_model()
2023-09-05 17:02:45,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012A5EA268B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:02:45,222:INFO:Checking exceptions
2023-09-05 17:02:45,222:INFO:Importing libraries
2023-09-05 17:02:45,222:INFO:Copying training dataset
2023-09-05 17:02:45,222:INFO:Defining folds
2023-09-05 17:02:45,222:INFO:Declaring metric variables
2023-09-05 17:02:45,222:INFO:Importing untrained model
2023-09-05 17:02:45,222:INFO:Declaring custom model
2023-09-05 17:02:45,235:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:02:45,235:INFO:Starting cross validation
2023-09-05 17:02:45,235:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:02:45,569:INFO:Calculating mean and std
2023-09-05 17:02:45,569:INFO:Creating metrics dataframe
2023-09-05 17:02:45,571:INFO:Finalizing model
2023-09-05 17:02:45,653:INFO:Uploading results into container
2023-09-05 17:02:45,653:INFO:Uploading model into container now
2023-09-05 17:02:45,654:INFO:_master_model_container: 46
2023-09-05 17:02:45,654:INFO:_display_container: 14
2023-09-05 17:02:45,654:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:02:45,654:INFO:create_model() successfully completed......................................
2023-09-05 17:02:45,857:INFO:SubProcess create_model() end ==================================
2023-09-05 17:02:45,857:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 17:02:45,857:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8273
2023-09-05 17:02:45,857:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 17:02:45,857:INFO:choose_better completed
2023-09-05 17:02:45,857:INFO:_master_model_container: 46
2023-09-05 17:02:45,857:INFO:_display_container: 13
2023-09-05 17:02:45,857:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:02:45,857:INFO:tune_model() successfully completed......................................
2023-09-05 17:37:34,071:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_bad01608efac4c8db13ed4548cefa926_86460698ece3481999f73196122b6c87
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_fe93ed018f4146dea311fc37dd8b6192
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_763316c2137c41d99d6767987423972d_5573f2bd519f4d60af380d56d10c9039
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_08a49ffdba7e47be83c41b04fe2d3342
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_20d590f815e94df1a593be045fe36ff6_2c8c431cefc4498aa4ccea376f925ac3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_0877f11dc77145258df4304d0b5ffcd7
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_062e0ee9d8544bdcb1e9c4fb3b2d106e_5c43aba8f9da408e9d32ea91abcaba39
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_8eb19f50d277413aa6666b59a064158e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_5f264bf71cc24034b97522c2da055e68_8416ff262a4d4ab6bffc7998a8d57cc3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_af4a2827df3c4c56a33b9847738ab46c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_9d80d80854ab4ed4842216063664dad2_9f919095da9042a49f8234c65accc198
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_255f59f5a8394056b3a46a8c7acae7fe
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_87c2147da804409baafcb557ddd62ee4_2e7fae3ce0574bd6ac8fd5419a1a2d48
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_885b2e88b64d467bbaff514e9e0d660a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_e6baefca29de449094aba363b7760981_2ff03acf273c48809aae4d03f88035bb
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_4b062cb522aa453c9312d3ebaacc8215
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_cadf65830d28409fa8cb8222086671d3_0127d5823aa24d25924eb8943dbf0a98
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_2c04af373714474ab688097363369a93
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_0acdccf28bbc45ed9ba8d0270cd18f27_b551f4d04ddf4adc8bbbe9d859ce068e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_474bb6afca194765b280f301c22587d0
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_1f2714b802154250ac499a788c34cd4a_16376e347ae74b48bf971406ff1cb77f
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_bd314962996d475e929b3384a4ab2977
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_63ef85fce1e74249b0c5c14091fd7d8d_615063a473cd49ee84909ad3d336df66
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_8baaf42318884b5fb1b2aad2dc1d5921
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_86b1dc239cee4953a8b97915ac7f2aba_5f2c73163260463e8527ca030930e445
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_9a3bd00c9a8c4580914c907eeaec876b
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_59ded867cd5f482ba2a1a22c3ad6a814_89cc9ccea57243c889f37f1137b2a98d
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_3cebe7d77ca645828795ea5691010014
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_2d903bc4858f4c018e805dc917315569_4c0048660a0b40b9ae3a5f59b2de7ad6
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_8bf239611d55459aa81b4cb7c307716f
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4ef37f374c4b4097a4752a504e32f291_36af08095347483484d8f9a88087c253
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_0bda860f46c643c39d8068916eaf82b6
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_2ae788b3f1ce49aab46d84534ac5fbbe_7e63edf62a9b492ebfad959ab95a6c00
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_c70231ab41bb4a98a541bb193a60c991
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_1e16c9eec59e446caf96f02b7f9767d5_1488337b3e0a47df96b0f9b19382a662
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_4238ffc149be4157a98c91545604ce1f
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_810c573e173440b9abf44f5332efaff2_0e63c4a9947843f481ea287205048fd6
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_ca44c3970ed1409a9850b025d28fb66c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_c96a3a4ee1054622b189b88f4c97ee70_c5804f2d9a5c4c15a2188a79aff0a602
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_c1514a3641f74a1e9605fa0adb427e91
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_f53058f581f043f28139ea7db8f26ab0_5c0b89ada20445ee84d1c4eadff4740f
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_d40c5b507bbb4523937ff37c94df4cd8
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,074:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_a0d6df3ea9f24b009dff7a24eddab08a_aee9727c5fd443a49fe6f785dfd191f4
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_b3a9258c386c42f18d821e71edba3fa3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_ea070028eac7473e8ca051e3b21424cd_7d9717eb47ab4e9a86dbaac2701c1b5b
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_5c78820340614d5fa90f425476a38d56
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_53e3d8e41864464da534c33559e4d830_ca1fe5bd02e045b5b613e4479431909d
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_27f8a6327074490bbc15fe8a04483bb6
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_7aeabee875654e2db0af2e76236f4f19_605df1540896441a8b5b3c0815c87984
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_7c385e2efec6468c8fa90c37f08178f8
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_34298793d1514911922d12ad6b5ea46e_52232a0badcf41d287c5b479f4f97d5e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_5bb3c856e7f9494a9c4874e6462d544e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_fb83d25f42cb4242b29095ea51fe17de_da7a058437cb4ec09e05bfe23b4caba3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_f3709c25081b48659ba3db58e64e73c0
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_1dd4d4e58f044e3090aeaefde9c39ea6_5f6ab9b6458a4f1b80d82eea217cd755
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_9a6f2213658c459a92e0cc18d49a850b
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_cf6d0f8ae3ce4751a2db1403504981ae_43fd90c21b1f443ebde36d1fb909bf4c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_60607899191e4b90a472bdfc196ffd37
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_95dab5912e7346268ae231e00bee4ad4_b665d36cbcbc47c5999cb835f70f18da
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_9d27f3dd92b8459f9cbbe9b1e83922f5
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_035de68df67d4c96b1a7736c72684751_c78333c8818e47c18236f0c7a4d5adcb
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_bad4bc3a21b24216ab9c044167fd7364
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_a4905189e0a642bbbb85290e764ec7db_c2dfaf662fd44a66ba813db6dfadbc9e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_c4ce0751d1cd4d608bdf526751386bfc
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_899d5a860ba74dc496e272b893e078f0_0fd5f09db74c410c9126d75745e756b3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_8ac573e2462742f2885c59fd9a54e8c4
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4b02ffabcd4548888f093d3eee9a9271_7c0815c988384fc29b728c705f2c987a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_0627cf154c294d91934a9eef64e27c86
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_5202d8a5e3dc4b968e92e6ccaaee2bdb_d023c42038b04a68b14b6dada41e301c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_26ea09cb0e5a4faea79b99d1d48502d5
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_f9da9389fe61483985d4c2ff22a7bdca_c6df3f1ca1da44b2a575b66a31260a00
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_f8468509354542b6a2c363e63f7d684b
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,076:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_991c3c60e6624368ba37661012e2ad39_3808e5e1ef1842b1b9ca2db6e35e9aa0
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,077:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_917ebe20d3c541d89790b52ea4c5fa69
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:37:34,077:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8384_4f3b5c02a4b34527b7e3b2780bc6efaa_03968ac6bfcd4e98b7ade02d2b56bd0e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:38:00,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:38:00,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:38:00,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:38:00,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:38:00,831:INFO:PyCaret ClassificationExperiment
2023-09-05 17:38:00,831:INFO:Logging name: clf-default-name
2023-09-05 17:38:00,831:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-05 17:38:00,831:INFO:version 3.0.4
2023-09-05 17:38:00,831:INFO:Initializing setup()
2023-09-05 17:38:00,831:INFO:self.USI: 8236
2023-09-05 17:38:00,831:INFO:self._variable_keys: {'pipeline', 'fix_imbalance', '_available_plots', 'html_param', 'y_test', 'exp_id', 'y_train', 'USI', 'memory', 'fold_groups_param', 'idx', '_ml_usecase', 'X_test', 'exp_name_log', 'is_multiclass', 'data', 'gpu_n_jobs_param', 'X', 'fold_generator', 'y', 'seed', 'n_jobs_param', 'X_train', 'log_plots_param', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'target_param'}
2023-09-05 17:38:00,831:INFO:Checking environment
2023-09-05 17:38:00,831:INFO:python_version: 3.8.8
2023-09-05 17:38:00,831:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 17:38:00,831:INFO:machine: AMD64
2023-09-05 17:38:00,831:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 17:38:00,831:INFO:Memory: svmem(total=16822788096, available=9098788864, percent=45.9, used=7723999232, free=9098788864)
2023-09-05 17:38:00,831:INFO:Physical Core: 8
2023-09-05 17:38:00,831:INFO:Logical Core: 16
2023-09-05 17:38:00,831:INFO:Checking libraries
2023-09-05 17:38:00,831:INFO:System:
2023-09-05 17:38:00,831:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 17:38:00,831:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 17:38:00,831:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 17:38:00,831:INFO:PyCaret required dependencies:
2023-09-05 17:38:00,831:INFO:                 pip: 23.2.1
2023-09-05 17:38:00,831:INFO:          setuptools: 65.5.1
2023-09-05 17:38:00,831:INFO:             pycaret: 3.0.4
2023-09-05 17:38:00,831:INFO:             IPython: 8.12.2
2023-09-05 17:38:00,831:INFO:          ipywidgets: 8.0.7
2023-09-05 17:38:00,831:INFO:                tqdm: 4.66.1
2023-09-05 17:38:00,831:INFO:               numpy: 1.23.5
2023-09-05 17:38:00,831:INFO:              pandas: 1.5.3
2023-09-05 17:38:00,831:INFO:              jinja2: 3.1.2
2023-09-05 17:38:00,831:INFO:               scipy: 1.10.1
2023-09-05 17:38:00,831:INFO:              joblib: 1.3.2
2023-09-05 17:38:00,831:INFO:             sklearn: 1.2.2
2023-09-05 17:38:00,831:INFO:                pyod: 1.1.0
2023-09-05 17:38:00,831:INFO:            imblearn: 0.11.0
2023-09-05 17:38:00,831:INFO:   category_encoders: 2.6.2
2023-09-05 17:38:00,831:INFO:            lightgbm: 4.0.0
2023-09-05 17:38:00,831:INFO:               numba: 0.57.1
2023-09-05 17:38:00,831:INFO:            requests: 2.31.0
2023-09-05 17:38:00,831:INFO:          matplotlib: 3.7.2
2023-09-05 17:38:00,831:INFO:          scikitplot: 0.3.7
2023-09-05 17:38:00,831:INFO:         yellowbrick: 1.5
2023-09-05 17:38:00,831:INFO:              plotly: 5.15.0
2023-09-05 17:38:00,831:INFO:    plotly-resampler: Not installed
2023-09-05 17:38:00,831:INFO:             kaleido: 0.2.1
2023-09-05 17:38:00,831:INFO:           schemdraw: 0.15
2023-09-05 17:38:00,831:INFO:         statsmodels: 0.14.0
2023-09-05 17:38:00,831:INFO:              sktime: 0.22.0
2023-09-05 17:38:00,831:INFO:               tbats: 1.1.3
2023-09-05 17:38:00,831:INFO:            pmdarima: 2.0.3
2023-09-05 17:38:00,831:INFO:              psutil: 5.9.5
2023-09-05 17:38:00,831:INFO:          markupsafe: 2.1.3
2023-09-05 17:38:00,831:INFO:             pickle5: Not installed
2023-09-05 17:38:00,831:INFO:         cloudpickle: 2.2.1
2023-09-05 17:38:00,831:INFO:         deprecation: 2.1.0
2023-09-05 17:38:00,831:INFO:              xxhash: 3.3.0
2023-09-05 17:38:00,831:INFO:           wurlitzer: Not installed
2023-09-05 17:38:00,831:INFO:PyCaret optional dependencies:
2023-09-05 17:38:00,831:INFO:                shap: Not installed
2023-09-05 17:38:00,831:INFO:           interpret: Not installed
2023-09-05 17:38:00,831:INFO:                umap: Not installed
2023-09-05 17:38:00,831:INFO:    pandas_profiling: 4.5.1
2023-09-05 17:38:00,831:INFO:  explainerdashboard: Not installed
2023-09-05 17:38:00,831:INFO:             autoviz: Not installed
2023-09-05 17:38:00,831:INFO:           fairlearn: Not installed
2023-09-05 17:38:00,831:INFO:          deepchecks: Not installed
2023-09-05 17:38:00,831:INFO:             xgboost: 1.7.6
2023-09-05 17:38:00,831:INFO:            catboost: 1.2.1
2023-09-05 17:38:00,831:INFO:              kmodes: Not installed
2023-09-05 17:38:00,831:INFO:             mlxtend: Not installed
2023-09-05 17:38:00,831:INFO:       statsforecast: Not installed
2023-09-05 17:38:00,831:INFO:        tune_sklearn: Not installed
2023-09-05 17:38:00,831:INFO:                 ray: Not installed
2023-09-05 17:38:00,831:INFO:            hyperopt: Not installed
2023-09-05 17:38:00,831:INFO:              optuna: 3.3.0
2023-09-05 17:38:00,831:INFO:               skopt: 0.9.0
2023-09-05 17:38:00,831:INFO:              mlflow: Not installed
2023-09-05 17:38:00,831:INFO:              gradio: Not installed
2023-09-05 17:38:00,831:INFO:             fastapi: Not installed
2023-09-05 17:38:00,831:INFO:             uvicorn: Not installed
2023-09-05 17:38:00,831:INFO:              m2cgen: Not installed
2023-09-05 17:38:00,831:INFO:           evidently: Not installed
2023-09-05 17:38:00,831:INFO:               fugue: Not installed
2023-09-05 17:38:00,831:INFO:           streamlit: Not installed
2023-09-05 17:38:00,831:INFO:             prophet: Not installed
2023-09-05 17:38:00,831:INFO:None
2023-09-05 17:38:00,831:INFO:Set up data.
2023-09-05 17:38:00,847:INFO:Set up train/test split.
2023-09-05 17:38:00,847:INFO:Set up index.
2023-09-05 17:38:00,847:INFO:Set up folding strategy.
2023-09-05 17:38:00,847:INFO:Assigning column types.
2023-09-05 17:38:00,847:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 17:38:00,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:38:00,878:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 17:38:00,894:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:00,894:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:00,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:38:00,925:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 17:38:00,941:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:00,941:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:00,941:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 17:38:00,972:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 17:38:00,988:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,003:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,019:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 17:38:01,050:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,050:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,050:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-05 17:38:01,097:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,097:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,144:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,144:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,144:INFO:Preparing preprocessing pipeline...
2023-09-05 17:38:01,144:INFO:Set up simple imputation.
2023-09-05 17:38:01,159:INFO:Finished creating preprocessing pipeline.
2023-09-05 17:38:01,159:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-05 17:38:01,159:INFO:Creating final display dataframe.
2023-09-05 17:38:01,191:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              8236
2023-09-05 17:38:01,252:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,254:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,297:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,297:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,297:INFO:setup() successfully completed in 0.5s...............
2023-09-05 17:38:01,312:INFO:gpu_param set to False
2023-09-05 17:38:01,365:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,367:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,417:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,419:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,435:INFO:gpu_param set to False
2023-09-05 17:38:01,490:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,492:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,540:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:38:01,542:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:38:01,593:INFO:Initializing compare_models()
2023-09-05 17:38:01,593:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-05 17:38:01,593:INFO:Checking exceptions
2023-09-05 17:38:01,596:INFO:Preparing display monitor
2023-09-05 17:38:01,613:INFO:Initializing Logistic Regression
2023-09-05 17:38:01,613:INFO:Total runtime is 0.0 minutes
2023-09-05 17:38:01,615:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:01,615:INFO:Initializing create_model()
2023-09-05 17:38:01,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:01,615:INFO:Checking exceptions
2023-09-05 17:38:01,615:INFO:Importing libraries
2023-09-05 17:38:01,615:INFO:Copying training dataset
2023-09-05 17:38:01,617:INFO:Defining folds
2023-09-05 17:38:01,618:INFO:Declaring metric variables
2023-09-05 17:38:01,620:INFO:Importing untrained model
2023-09-05 17:38:01,622:INFO:Logistic Regression Imported successfully
2023-09-05 17:38:01,624:INFO:Starting cross validation
2023-09-05 17:38:01,624:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:03,255:INFO:Calculating mean and std
2023-09-05 17:38:03,255:INFO:Creating metrics dataframe
2023-09-05 17:38:03,299:INFO:Uploading results into container
2023-09-05 17:38:03,299:INFO:Uploading model into container now
2023-09-05 17:38:03,299:INFO:_master_model_container: 1
2023-09-05 17:38:03,299:INFO:_display_container: 2
2023-09-05 17:38:03,299:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-05 17:38:03,299:INFO:create_model() successfully completed......................................
2023-09-05 17:38:03,350:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:03,350:INFO:Creating metrics dataframe
2023-09-05 17:38:03,350:INFO:Initializing K Neighbors Classifier
2023-09-05 17:38:03,350:INFO:Total runtime is 0.028947110970815024 minutes
2023-09-05 17:38:03,364:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:03,364:INFO:Initializing create_model()
2023-09-05 17:38:03,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:03,364:INFO:Checking exceptions
2023-09-05 17:38:03,364:INFO:Importing libraries
2023-09-05 17:38:03,364:INFO:Copying training dataset
2023-09-05 17:38:03,366:INFO:Defining folds
2023-09-05 17:38:03,366:INFO:Declaring metric variables
2023-09-05 17:38:03,366:INFO:Importing untrained model
2023-09-05 17:38:03,366:INFO:K Neighbors Classifier Imported successfully
2023-09-05 17:38:03,366:INFO:Starting cross validation
2023-09-05 17:38:03,380:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:04,715:INFO:Calculating mean and std
2023-09-05 17:38:04,716:INFO:Creating metrics dataframe
2023-09-05 17:38:04,764:INFO:Uploading results into container
2023-09-05 17:38:04,765:INFO:Uploading model into container now
2023-09-05 17:38:04,765:INFO:_master_model_container: 2
2023-09-05 17:38:04,765:INFO:_display_container: 2
2023-09-05 17:38:04,765:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-05 17:38:04,765:INFO:create_model() successfully completed......................................
2023-09-05 17:38:04,799:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:04,799:INFO:Creating metrics dataframe
2023-09-05 17:38:04,816:INFO:Initializing Naive Bayes
2023-09-05 17:38:04,816:INFO:Total runtime is 0.05338282187779744 minutes
2023-09-05 17:38:04,816:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:04,816:INFO:Initializing create_model()
2023-09-05 17:38:04,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:04,816:INFO:Checking exceptions
2023-09-05 17:38:04,816:INFO:Importing libraries
2023-09-05 17:38:04,816:INFO:Copying training dataset
2023-09-05 17:38:04,816:INFO:Defining folds
2023-09-05 17:38:04,816:INFO:Declaring metric variables
2023-09-05 17:38:04,816:INFO:Importing untrained model
2023-09-05 17:38:04,816:INFO:Naive Bayes Imported successfully
2023-09-05 17:38:04,816:INFO:Starting cross validation
2023-09-05 17:38:04,830:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:06,100:INFO:Calculating mean and std
2023-09-05 17:38:06,100:INFO:Creating metrics dataframe
2023-09-05 17:38:06,146:INFO:Uploading results into container
2023-09-05 17:38:06,146:INFO:Uploading model into container now
2023-09-05 17:38:06,146:INFO:_master_model_container: 3
2023-09-05 17:38:06,146:INFO:_display_container: 2
2023-09-05 17:38:06,146:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-05 17:38:06,146:INFO:create_model() successfully completed......................................
2023-09-05 17:38:06,190:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:06,190:INFO:Creating metrics dataframe
2023-09-05 17:38:06,195:INFO:Initializing Decision Tree Classifier
2023-09-05 17:38:06,195:INFO:Total runtime is 0.07636542320251465 minutes
2023-09-05 17:38:06,198:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:06,198:INFO:Initializing create_model()
2023-09-05 17:38:06,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:06,198:INFO:Checking exceptions
2023-09-05 17:38:06,198:INFO:Importing libraries
2023-09-05 17:38:06,198:INFO:Copying training dataset
2023-09-05 17:38:06,200:INFO:Defining folds
2023-09-05 17:38:06,200:INFO:Declaring metric variables
2023-09-05 17:38:06,202:INFO:Importing untrained model
2023-09-05 17:38:06,204:INFO:Decision Tree Classifier Imported successfully
2023-09-05 17:38:06,209:INFO:Starting cross validation
2023-09-05 17:38:06,210:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:07,493:INFO:Calculating mean and std
2023-09-05 17:38:07,493:INFO:Creating metrics dataframe
2023-09-05 17:38:07,543:INFO:Uploading results into container
2023-09-05 17:38:07,543:INFO:Uploading model into container now
2023-09-05 17:38:07,543:INFO:_master_model_container: 4
2023-09-05 17:38:07,544:INFO:_display_container: 2
2023-09-05 17:38:07,544:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 17:38:07,544:INFO:create_model() successfully completed......................................
2023-09-05 17:38:07,589:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:07,589:INFO:Creating metrics dataframe
2023-09-05 17:38:07,595:INFO:Initializing SVM - Linear Kernel
2023-09-05 17:38:07,595:INFO:Total runtime is 0.09970670541127523 minutes
2023-09-05 17:38:07,598:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:07,598:INFO:Initializing create_model()
2023-09-05 17:38:07,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:07,598:INFO:Checking exceptions
2023-09-05 17:38:07,598:INFO:Importing libraries
2023-09-05 17:38:07,598:INFO:Copying training dataset
2023-09-05 17:38:07,599:INFO:Defining folds
2023-09-05 17:38:07,599:INFO:Declaring metric variables
2023-09-05 17:38:07,599:INFO:Importing untrained model
2023-09-05 17:38:07,599:INFO:SVM - Linear Kernel Imported successfully
2023-09-05 17:38:07,599:INFO:Starting cross validation
2023-09-05 17:38:07,599:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:08,721:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 17:38:08,773:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 17:38:08,841:INFO:Calculating mean and std
2023-09-05 17:38:08,841:INFO:Creating metrics dataframe
2023-09-05 17:38:08,880:INFO:Uploading results into container
2023-09-05 17:38:08,880:INFO:Uploading model into container now
2023-09-05 17:38:08,880:INFO:_master_model_container: 5
2023-09-05 17:38:08,880:INFO:_display_container: 2
2023-09-05 17:38:08,880:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-05 17:38:08,880:INFO:create_model() successfully completed......................................
2023-09-05 17:38:08,927:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:08,927:INFO:Creating metrics dataframe
2023-09-05 17:38:08,927:INFO:Initializing Ridge Classifier
2023-09-05 17:38:08,927:INFO:Total runtime is 0.12190349499384562 minutes
2023-09-05 17:38:08,927:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:08,927:INFO:Initializing create_model()
2023-09-05 17:38:08,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:08,927:INFO:Checking exceptions
2023-09-05 17:38:08,927:INFO:Importing libraries
2023-09-05 17:38:08,927:INFO:Copying training dataset
2023-09-05 17:38:08,945:INFO:Defining folds
2023-09-05 17:38:08,946:INFO:Declaring metric variables
2023-09-05 17:38:08,948:INFO:Importing untrained model
2023-09-05 17:38:08,950:INFO:Ridge Classifier Imported successfully
2023-09-05 17:38:08,951:INFO:Starting cross validation
2023-09-05 17:38:08,951:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:08,997:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 17:38:09,013:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 17:38:09,997:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 17:38:10,013:INFO:Calculating mean and std
2023-09-05 17:38:10,013:INFO:Creating metrics dataframe
2023-09-05 17:38:10,063:INFO:Uploading results into container
2023-09-05 17:38:10,063:INFO:Uploading model into container now
2023-09-05 17:38:10,063:INFO:_master_model_container: 6
2023-09-05 17:38:10,063:INFO:_display_container: 2
2023-09-05 17:38:10,063:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-05 17:38:10,063:INFO:create_model() successfully completed......................................
2023-09-05 17:38:10,094:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:10,094:INFO:Creating metrics dataframe
2023-09-05 17:38:10,110:INFO:Initializing Random Forest Classifier
2023-09-05 17:38:10,110:INFO:Total runtime is 0.1416104992230733 minutes
2023-09-05 17:38:10,110:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:10,110:INFO:Initializing create_model()
2023-09-05 17:38:10,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:10,110:INFO:Checking exceptions
2023-09-05 17:38:10,110:INFO:Importing libraries
2023-09-05 17:38:10,110:INFO:Copying training dataset
2023-09-05 17:38:10,120:INFO:Defining folds
2023-09-05 17:38:10,120:INFO:Declaring metric variables
2023-09-05 17:38:10,123:INFO:Importing untrained model
2023-09-05 17:38:10,125:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:10,131:INFO:Starting cross validation
2023-09-05 17:38:10,137:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:10,384:INFO:Calculating mean and std
2023-09-05 17:38:10,384:INFO:Creating metrics dataframe
2023-09-05 17:38:10,429:INFO:Uploading results into container
2023-09-05 17:38:10,429:INFO:Uploading model into container now
2023-09-05 17:38:10,429:INFO:_master_model_container: 7
2023-09-05 17:38:10,429:INFO:_display_container: 2
2023-09-05 17:38:10,429:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:10,429:INFO:create_model() successfully completed......................................
2023-09-05 17:38:10,476:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:10,476:INFO:Creating metrics dataframe
2023-09-05 17:38:10,476:INFO:Initializing Quadratic Discriminant Analysis
2023-09-05 17:38:10,476:INFO:Total runtime is 0.14772000710169472 minutes
2023-09-05 17:38:10,476:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:10,476:INFO:Initializing create_model()
2023-09-05 17:38:10,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:10,476:INFO:Checking exceptions
2023-09-05 17:38:10,476:INFO:Importing libraries
2023-09-05 17:38:10,476:INFO:Copying training dataset
2023-09-05 17:38:10,487:INFO:Defining folds
2023-09-05 17:38:10,487:INFO:Declaring metric variables
2023-09-05 17:38:10,490:INFO:Importing untrained model
2023-09-05 17:38:10,492:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-05 17:38:10,497:INFO:Starting cross validation
2023-09-05 17:38:10,498:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:10,630:INFO:Calculating mean and std
2023-09-05 17:38:10,632:INFO:Creating metrics dataframe
2023-09-05 17:38:10,682:INFO:Uploading results into container
2023-09-05 17:38:10,682:INFO:Uploading model into container now
2023-09-05 17:38:10,682:INFO:_master_model_container: 8
2023-09-05 17:38:10,682:INFO:_display_container: 2
2023-09-05 17:38:10,682:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-05 17:38:10,682:INFO:create_model() successfully completed......................................
2023-09-05 17:38:10,716:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:10,716:INFO:Creating metrics dataframe
2023-09-05 17:38:10,732:INFO:Initializing Ada Boost Classifier
2023-09-05 17:38:10,732:INFO:Total runtime is 0.1519843260447184 minutes
2023-09-05 17:38:10,732:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:10,732:INFO:Initializing create_model()
2023-09-05 17:38:10,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:10,732:INFO:Checking exceptions
2023-09-05 17:38:10,732:INFO:Importing libraries
2023-09-05 17:38:10,732:INFO:Copying training dataset
2023-09-05 17:38:10,732:INFO:Defining folds
2023-09-05 17:38:10,732:INFO:Declaring metric variables
2023-09-05 17:38:10,732:INFO:Importing untrained model
2023-09-05 17:38:10,732:INFO:Ada Boost Classifier Imported successfully
2023-09-05 17:38:10,752:INFO:Starting cross validation
2023-09-05 17:38:10,753:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:10,957:INFO:Calculating mean and std
2023-09-05 17:38:10,957:INFO:Creating metrics dataframe
2023-09-05 17:38:11,008:INFO:Uploading results into container
2023-09-05 17:38:11,008:INFO:Uploading model into container now
2023-09-05 17:38:11,008:INFO:_master_model_container: 9
2023-09-05 17:38:11,008:INFO:_display_container: 2
2023-09-05 17:38:11,009:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-05 17:38:11,009:INFO:create_model() successfully completed......................................
2023-09-05 17:38:11,046:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:11,046:INFO:Creating metrics dataframe
2023-09-05 17:38:11,046:INFO:Initializing Gradient Boosting Classifier
2023-09-05 17:38:11,046:INFO:Total runtime is 0.15721043348312375 minutes
2023-09-05 17:38:11,046:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:11,046:INFO:Initializing create_model()
2023-09-05 17:38:11,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:11,061:INFO:Checking exceptions
2023-09-05 17:38:11,061:INFO:Importing libraries
2023-09-05 17:38:11,061:INFO:Copying training dataset
2023-09-05 17:38:11,064:INFO:Defining folds
2023-09-05 17:38:11,065:INFO:Declaring metric variables
2023-09-05 17:38:11,068:INFO:Importing untrained model
2023-09-05 17:38:11,070:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 17:38:11,072:INFO:Starting cross validation
2023-09-05 17:38:11,072:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:11,300:INFO:Calculating mean and std
2023-09-05 17:38:11,300:INFO:Creating metrics dataframe
2023-09-05 17:38:11,347:INFO:Uploading results into container
2023-09-05 17:38:11,347:INFO:Uploading model into container now
2023-09-05 17:38:11,347:INFO:_master_model_container: 10
2023-09-05 17:38:11,347:INFO:_display_container: 2
2023-09-05 17:38:11,347:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 17:38:11,347:INFO:create_model() successfully completed......................................
2023-09-05 17:38:11,378:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:11,378:INFO:Creating metrics dataframe
2023-09-05 17:38:11,394:INFO:Initializing Linear Discriminant Analysis
2023-09-05 17:38:11,394:INFO:Total runtime is 0.16301532983779904 minutes
2023-09-05 17:38:11,394:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:11,394:INFO:Initializing create_model()
2023-09-05 17:38:11,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:11,394:INFO:Checking exceptions
2023-09-05 17:38:11,394:INFO:Importing libraries
2023-09-05 17:38:11,394:INFO:Copying training dataset
2023-09-05 17:38:11,400:INFO:Defining folds
2023-09-05 17:38:11,400:INFO:Declaring metric variables
2023-09-05 17:38:11,402:INFO:Importing untrained model
2023-09-05 17:38:11,404:INFO:Linear Discriminant Analysis Imported successfully
2023-09-05 17:38:11,406:INFO:Starting cross validation
2023-09-05 17:38:11,406:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:11,541:INFO:Calculating mean and std
2023-09-05 17:38:11,541:INFO:Creating metrics dataframe
2023-09-05 17:38:11,580:INFO:Uploading results into container
2023-09-05 17:38:11,580:INFO:Uploading model into container now
2023-09-05 17:38:11,580:INFO:_master_model_container: 11
2023-09-05 17:38:11,580:INFO:_display_container: 2
2023-09-05 17:38:11,580:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-05 17:38:11,580:INFO:create_model() successfully completed......................................
2023-09-05 17:38:11,630:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:11,630:INFO:Creating metrics dataframe
2023-09-05 17:38:11,630:INFO:Initializing Extra Trees Classifier
2023-09-05 17:38:11,630:INFO:Total runtime is 0.1669570485750834 minutes
2023-09-05 17:38:11,630:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:11,630:INFO:Initializing create_model()
2023-09-05 17:38:11,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:11,630:INFO:Checking exceptions
2023-09-05 17:38:11,630:INFO:Importing libraries
2023-09-05 17:38:11,630:INFO:Copying training dataset
2023-09-05 17:38:11,630:INFO:Defining folds
2023-09-05 17:38:11,630:INFO:Declaring metric variables
2023-09-05 17:38:11,646:INFO:Importing untrained model
2023-09-05 17:38:11,649:INFO:Extra Trees Classifier Imported successfully
2023-09-05 17:38:11,653:INFO:Starting cross validation
2023-09-05 17:38:11,654:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:11,978:INFO:Calculating mean and std
2023-09-05 17:38:11,978:INFO:Creating metrics dataframe
2023-09-05 17:38:12,030:INFO:Uploading results into container
2023-09-05 17:38:12,030:INFO:Uploading model into container now
2023-09-05 17:38:12,030:INFO:_master_model_container: 12
2023-09-05 17:38:12,030:INFO:_display_container: 2
2023-09-05 17:38:12,030:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:12,030:INFO:create_model() successfully completed......................................
2023-09-05 17:38:12,062:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:12,062:INFO:Creating metrics dataframe
2023-09-05 17:38:12,077:INFO:Initializing Extreme Gradient Boosting
2023-09-05 17:38:12,077:INFO:Total runtime is 0.17440265417098996 minutes
2023-09-05 17:38:12,077:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:12,077:INFO:Initializing create_model()
2023-09-05 17:38:12,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:12,077:INFO:Checking exceptions
2023-09-05 17:38:12,077:INFO:Importing libraries
2023-09-05 17:38:12,077:INFO:Copying training dataset
2023-09-05 17:38:12,087:INFO:Defining folds
2023-09-05 17:38:12,087:INFO:Declaring metric variables
2023-09-05 17:38:12,089:INFO:Importing untrained model
2023-09-05 17:38:12,092:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 17:38:12,098:INFO:Starting cross validation
2023-09-05 17:38:12,099:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:12,272:INFO:Calculating mean and std
2023-09-05 17:38:12,272:INFO:Creating metrics dataframe
2023-09-05 17:38:12,313:INFO:Uploading results into container
2023-09-05 17:38:12,313:INFO:Uploading model into container now
2023-09-05 17:38:12,313:INFO:_master_model_container: 13
2023-09-05 17:38:12,313:INFO:_display_container: 2
2023-09-05 17:38:12,313:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 17:38:12,313:INFO:create_model() successfully completed......................................
2023-09-05 17:38:12,360:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:12,360:INFO:Creating metrics dataframe
2023-09-05 17:38:12,360:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 17:38:12,360:INFO:Total runtime is 0.17910792827606198 minutes
2023-09-05 17:38:12,360:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:12,360:INFO:Initializing create_model()
2023-09-05 17:38:12,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:12,360:INFO:Checking exceptions
2023-09-05 17:38:12,360:INFO:Importing libraries
2023-09-05 17:38:12,360:INFO:Copying training dataset
2023-09-05 17:38:12,373:INFO:Defining folds
2023-09-05 17:38:12,374:INFO:Declaring metric variables
2023-09-05 17:38:12,376:INFO:Importing untrained model
2023-09-05 17:38:12,378:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 17:38:12,383:INFO:Starting cross validation
2023-09-05 17:38:12,384:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:12,631:INFO:Calculating mean and std
2023-09-05 17:38:12,632:INFO:Creating metrics dataframe
2023-09-05 17:38:12,696:INFO:Uploading results into container
2023-09-05 17:38:12,696:INFO:Uploading model into container now
2023-09-05 17:38:12,696:INFO:_master_model_container: 14
2023-09-05 17:38:12,696:INFO:_display_container: 2
2023-09-05 17:38:12,696:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 17:38:12,696:INFO:create_model() successfully completed......................................
2023-09-05 17:38:12,727:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:12,727:INFO:Creating metrics dataframe
2023-09-05 17:38:12,743:INFO:Initializing Dummy Classifier
2023-09-05 17:38:12,743:INFO:Total runtime is 0.1854942440986633 minutes
2023-09-05 17:38:12,743:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:12,743:INFO:Initializing create_model()
2023-09-05 17:38:12,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014968A231F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:12,743:INFO:Checking exceptions
2023-09-05 17:38:12,743:INFO:Importing libraries
2023-09-05 17:38:12,743:INFO:Copying training dataset
2023-09-05 17:38:12,751:INFO:Defining folds
2023-09-05 17:38:12,751:INFO:Declaring metric variables
2023-09-05 17:38:12,754:INFO:Importing untrained model
2023-09-05 17:38:12,756:INFO:Dummy Classifier Imported successfully
2023-09-05 17:38:12,760:INFO:Starting cross validation
2023-09-05 17:38:12,760:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:12,796:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 17:38:12,797:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 17:38:12,799:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 17:38:12,898:INFO:Calculating mean and std
2023-09-05 17:38:12,899:INFO:Creating metrics dataframe
2023-09-05 17:38:12,948:INFO:Uploading results into container
2023-09-05 17:38:12,948:INFO:Uploading model into container now
2023-09-05 17:38:12,949:INFO:_master_model_container: 15
2023-09-05 17:38:12,949:INFO:_display_container: 2
2023-09-05 17:38:12,949:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-05 17:38:12,949:INFO:create_model() successfully completed......................................
2023-09-05 17:38:12,983:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:12,983:INFO:Creating metrics dataframe
2023-09-05 17:38:13,009:INFO:Initializing create_model()
2023-09-05 17:38:13,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:13,009:INFO:Checking exceptions
2023-09-05 17:38:13,010:INFO:Importing libraries
2023-09-05 17:38:13,010:INFO:Copying training dataset
2023-09-05 17:38:13,012:INFO:Defining folds
2023-09-05 17:38:13,012:INFO:Declaring metric variables
2023-09-05 17:38:13,012:INFO:Importing untrained model
2023-09-05 17:38:13,012:INFO:Declaring custom model
2023-09-05 17:38:13,012:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 17:38:13,013:INFO:Cross validation set to False
2023-09-05 17:38:13,013:INFO:Fitting Model
2023-09-05 17:38:13,129:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 17:38:13,129:INFO:create_model() successfully completed......................................
2023-09-05 17:38:13,160:INFO:Initializing create_model()
2023-09-05 17:38:13,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:13,176:INFO:Checking exceptions
2023-09-05 17:38:13,177:INFO:Importing libraries
2023-09-05 17:38:13,177:INFO:Copying training dataset
2023-09-05 17:38:13,179:INFO:Defining folds
2023-09-05 17:38:13,179:INFO:Declaring metric variables
2023-09-05 17:38:13,179:INFO:Importing untrained model
2023-09-05 17:38:13,179:INFO:Declaring custom model
2023-09-05 17:38:13,180:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 17:38:13,180:INFO:Cross validation set to False
2023-09-05 17:38:13,180:INFO:Fitting Model
2023-09-05 17:38:13,194:INFO:[LightGBM] [Info] Number of positive: 273, number of negative: 439
2023-09-05 17:38:13,194:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.
2023-09-05 17:38:13,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-09-05 17:38:13,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-09-05 17:38:13,194:INFO:[LightGBM] [Info] Total Bins 274
2023-09-05 17:38:13,194:INFO:[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9
2023-09-05 17:38:13,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028
2023-09-05 17:38:13,195:INFO:[LightGBM] [Info] Start training from score -0.475028
2023-09-05 17:38:13,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:38:13,276:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 17:38:13,276:INFO:create_model() successfully completed......................................
2023-09-05 17:38:13,323:INFO:Initializing create_model()
2023-09-05 17:38:13,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:13,323:INFO:Checking exceptions
2023-09-05 17:38:13,323:INFO:Importing libraries
2023-09-05 17:38:13,323:INFO:Copying training dataset
2023-09-05 17:38:13,336:INFO:Defining folds
2023-09-05 17:38:13,336:INFO:Declaring metric variables
2023-09-05 17:38:13,336:INFO:Importing untrained model
2023-09-05 17:38:13,336:INFO:Declaring custom model
2023-09-05 17:38:13,337:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 17:38:13,337:INFO:Cross validation set to False
2023-09-05 17:38:13,337:INFO:Fitting Model
2023-09-05 17:38:13,430:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 17:38:13,430:INFO:create_model() successfully completed......................................
2023-09-05 17:38:13,501:INFO:_master_model_container: 15
2023-09-05 17:38:13,501:INFO:_display_container: 2
2023-09-05 17:38:13,501:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)]
2023-09-05 17:38:13,501:INFO:compare_models() successfully completed......................................
2023-09-05 17:38:13,534:INFO:Initializing create_model()
2023-09-05 17:38:13,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 17:38:13,534:INFO:Checking exceptions
2023-09-05 17:38:13,537:INFO:Importing libraries
2023-09-05 17:38:13,537:INFO:Copying training dataset
2023-09-05 17:38:13,548:INFO:Defining folds
2023-09-05 17:38:13,548:INFO:Declaring metric variables
2023-09-05 17:38:13,551:INFO:Importing untrained model
2023-09-05 17:38:13,553:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:13,557:INFO:Starting cross validation
2023-09-05 17:38:13,557:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:13,906:INFO:Calculating mean and std
2023-09-05 17:38:13,906:INFO:Creating metrics dataframe
2023-09-05 17:38:13,906:INFO:Finalizing model
2023-09-05 17:38:13,995:INFO:Uploading results into container
2023-09-05 17:38:13,995:INFO:Uploading model into container now
2023-09-05 17:38:14,010:INFO:_master_model_container: 16
2023-09-05 17:38:14,010:INFO:_display_container: 3
2023-09-05 17:38:14,010:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:14,010:INFO:create_model() successfully completed......................................
2023-09-05 17:38:14,066:INFO:Initializing tune_model()
2023-09-05 17:38:14,067:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [150, 200, 250], 'max_depth': [10, 20], 'min_samples_split': [1, 2, 3], 'min_samples_leaf': [1, 2, 3]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>)
2023-09-05 17:38:14,067:INFO:Checking exceptions
2023-09-05 17:38:14,077:INFO:Copying training dataset
2023-09-05 17:38:14,081:INFO:Checking base model
2023-09-05 17:38:14,081:INFO:Base model : Random Forest Classifier
2023-09-05 17:38:14,084:INFO:Declaring metric variables
2023-09-05 17:38:14,086:INFO:Defining Hyperparameters
2023-09-05 17:38:14,132:INFO:custom_grid: {'actual_estimator__n_estimators': [150, 200, 250], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2, 3], 'actual_estimator__min_samples_leaf': [1, 2, 3]}
2023-09-05 17:38:14,132:INFO:Tuning with n_jobs=-1
2023-09-05 17:38:14,132:INFO:Initializing RandomizedSearchCV
2023-09-05 17:38:15,597:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
12 fits failed out of a total of 30.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
12 fits failed with the following error:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\AI\pythonProject\venv\lib\site-packages\joblib\memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-05 17:38:15,597:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8033838         nan        nan 0.82725242 0.81741895 0.81881951
 0.81881951        nan 0.80899195        nan]
  warnings.warn(

2023-09-05 17:38:15,631:INFO:best_params: {'actual_estimator__n_estimators': 250, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-05 17:38:15,631:INFO:Hyperparameter search completed
2023-09-05 17:38:15,631:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:15,631:INFO:Initializing create_model()
2023-09-05 17:38:15,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001496AF22C10>, model_only=True, return_train_score=False, kwargs={'n_estimators': 250, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-05 17:38:15,631:INFO:Checking exceptions
2023-09-05 17:38:15,631:INFO:Importing libraries
2023-09-05 17:38:15,631:INFO:Copying training dataset
2023-09-05 17:38:15,646:INFO:Defining folds
2023-09-05 17:38:15,646:INFO:Declaring metric variables
2023-09-05 17:38:15,649:INFO:Importing untrained model
2023-09-05 17:38:15,649:INFO:Declaring custom model
2023-09-05 17:38:15,652:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:15,652:INFO:Starting cross validation
2023-09-05 17:38:15,652:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:16,053:INFO:Calculating mean and std
2023-09-05 17:38:16,053:INFO:Creating metrics dataframe
2023-09-05 17:38:16,053:INFO:Finalizing model
2023-09-05 17:38:16,149:INFO:Uploading results into container
2023-09-05 17:38:16,149:INFO:Uploading model into container now
2023-09-05 17:38:16,164:INFO:_master_model_container: 17
2023-09-05 17:38:16,164:INFO:_display_container: 4
2023-09-05 17:38:16,164:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:16,164:INFO:create_model() successfully completed......................................
2023-09-05 17:38:16,214:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:16,214:INFO:choose_better activated
2023-09-05 17:38:16,216:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:16,216:INFO:Initializing create_model()
2023-09-05 17:38:16,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:16,216:INFO:Checking exceptions
2023-09-05 17:38:16,216:INFO:Importing libraries
2023-09-05 17:38:16,216:INFO:Copying training dataset
2023-09-05 17:38:16,216:INFO:Defining folds
2023-09-05 17:38:16,216:INFO:Declaring metric variables
2023-09-05 17:38:16,216:INFO:Importing untrained model
2023-09-05 17:38:16,216:INFO:Declaring custom model
2023-09-05 17:38:16,216:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:16,216:INFO:Starting cross validation
2023-09-05 17:38:16,216:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:16,560:INFO:Calculating mean and std
2023-09-05 17:38:16,560:INFO:Creating metrics dataframe
2023-09-05 17:38:16,560:INFO:Finalizing model
2023-09-05 17:38:16,664:INFO:Uploading results into container
2023-09-05 17:38:16,665:INFO:Uploading model into container now
2023-09-05 17:38:16,665:INFO:_master_model_container: 18
2023-09-05 17:38:16,665:INFO:_display_container: 5
2023-09-05 17:38:16,666:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:16,666:INFO:create_model() successfully completed......................................
2023-09-05 17:38:16,716:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:16,716:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 17:38:16,716:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8273
2023-09-05 17:38:16,716:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 17:38:16,716:INFO:choose_better completed
2023-09-05 17:38:16,716:INFO:_master_model_container: 18
2023-09-05 17:38:16,716:INFO:_display_container: 4
2023-09-05 17:38:16,716:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:16,716:INFO:tune_model() successfully completed......................................
2023-09-05 17:38:16,822:INFO:Initializing tune_model()
2023-09-05 17:38:16,822:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>)
2023-09-05 17:38:16,822:INFO:Checking exceptions
2023-09-05 17:38:16,835:INFO:Copying training dataset
2023-09-05 17:38:16,836:INFO:Checking base model
2023-09-05 17:38:16,837:INFO:Base model : Random Forest Classifier
2023-09-05 17:38:16,840:INFO:Declaring metric variables
2023-09-05 17:38:16,840:INFO:Defining Hyperparameters
2023-09-05 17:38:16,894:INFO:Tuning with n_jobs=-1
2023-09-05 17:38:16,894:INFO:Initializing RandomizedSearchCV
2023-09-05 17:38:18,426:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-09-05 17:38:18,426:INFO:Hyperparameter search completed
2023-09-05 17:38:18,426:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:18,426:INFO:Initializing create_model()
2023-09-05 17:38:18,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001496CB06DC0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2023-09-05 17:38:18,426:INFO:Checking exceptions
2023-09-05 17:38:18,426:INFO:Importing libraries
2023-09-05 17:38:18,426:INFO:Copying training dataset
2023-09-05 17:38:18,432:INFO:Defining folds
2023-09-05 17:38:18,432:INFO:Declaring metric variables
2023-09-05 17:38:18,434:INFO:Importing untrained model
2023-09-05 17:38:18,434:INFO:Declaring custom model
2023-09-05 17:38:18,434:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:18,434:INFO:Starting cross validation
2023-09-05 17:38:18,434:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:18,746:INFO:Calculating mean and std
2023-09-05 17:38:18,746:INFO:Creating metrics dataframe
2023-09-05 17:38:18,746:INFO:Finalizing model
2023-09-05 17:38:18,831:INFO:Uploading results into container
2023-09-05 17:38:18,840:INFO:Uploading model into container now
2023-09-05 17:38:18,840:INFO:_master_model_container: 19
2023-09-05 17:38:18,840:INFO:_display_container: 5
2023-09-05 17:38:18,841:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:18,841:INFO:create_model() successfully completed......................................
2023-09-05 17:38:18,890:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:18,890:INFO:choose_better activated
2023-09-05 17:38:18,892:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:18,892:INFO:Initializing create_model()
2023-09-05 17:38:18,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:18,892:INFO:Checking exceptions
2023-09-05 17:38:18,893:INFO:Importing libraries
2023-09-05 17:38:18,893:INFO:Copying training dataset
2023-09-05 17:38:18,895:INFO:Defining folds
2023-09-05 17:38:18,895:INFO:Declaring metric variables
2023-09-05 17:38:18,895:INFO:Importing untrained model
2023-09-05 17:38:18,895:INFO:Declaring custom model
2023-09-05 17:38:18,896:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:18,896:INFO:Starting cross validation
2023-09-05 17:38:18,896:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:19,239:INFO:Calculating mean and std
2023-09-05 17:38:19,239:INFO:Creating metrics dataframe
2023-09-05 17:38:19,239:INFO:Finalizing model
2023-09-05 17:38:19,332:INFO:Uploading results into container
2023-09-05 17:38:19,332:INFO:Uploading model into container now
2023-09-05 17:38:19,332:INFO:_master_model_container: 20
2023-09-05 17:38:19,332:INFO:_display_container: 6
2023-09-05 17:38:19,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:19,332:INFO:create_model() successfully completed......................................
2023-09-05 17:38:19,364:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:19,364:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 17:38:19,364:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8244
2023-09-05 17:38:19,364:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 17:38:19,364:INFO:choose_better completed
2023-09-05 17:38:19,384:INFO:_master_model_container: 20
2023-09-05 17:38:19,384:INFO:_display_container: 5
2023-09-05 17:38:19,384:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:19,384:INFO:tune_model() successfully completed......................................
2023-09-05 17:38:19,474:INFO:Initializing tune_model()
2023-09-05 17:38:19,474:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>)
2023-09-05 17:38:19,474:INFO:Checking exceptions
2023-09-05 17:38:19,474:INFO:Soft dependency imported: optuna: 3.3.0
2023-09-05 17:38:19,637:INFO:Copying training dataset
2023-09-05 17:38:19,639:INFO:Checking base model
2023-09-05 17:38:19,639:INFO:Base model : Random Forest Classifier
2023-09-05 17:38:19,641:INFO:Declaring metric variables
2023-09-05 17:38:19,643:INFO:Defining Hyperparameters
2023-09-05 17:38:19,704:INFO:Tuning with n_jobs=-1
2023-09-05 17:38:19,705:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\samplers\_tpe\sampler.py:277: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-09-05 17:38:19,705:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\samplers\_tpe\sampler.py:296: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-09-05 17:38:19,705:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-09-05 17:38:19,705:INFO:Initializing optuna.integration.OptunaSearchCV
2023-09-05 17:38:19,707:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2441: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-09-05 17:38:33,872:INFO:best_params: {'actual_estimator__n_estimators': 217, 'actual_estimator__max_depth': 8, 'actual_estimator__min_impurity_decrease': 5.596327857818154e-09, 'actual_estimator__max_features': 0.997172072411133, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__bootstrap': True, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample'}
2023-09-05 17:38:33,873:INFO:Hyperparameter search completed
2023-09-05 17:38:33,873:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:33,874:INFO:Initializing create_model()
2023-09-05 17:38:33,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001496E67AFA0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 217, 'max_depth': 8, 'min_impurity_decrease': 5.596327857818154e-09, 'max_features': 0.997172072411133, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'})
2023-09-05 17:38:33,874:INFO:Checking exceptions
2023-09-05 17:38:33,874:INFO:Importing libraries
2023-09-05 17:38:33,874:INFO:Copying training dataset
2023-09-05 17:38:33,876:INFO:Defining folds
2023-09-05 17:38:33,876:INFO:Declaring metric variables
2023-09-05 17:38:33,878:INFO:Importing untrained model
2023-09-05 17:38:33,878:INFO:Declaring custom model
2023-09-05 17:38:33,881:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:33,885:INFO:Starting cross validation
2023-09-05 17:38:33,886:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:34,264:INFO:Calculating mean and std
2023-09-05 17:38:34,264:INFO:Creating metrics dataframe
2023-09-05 17:38:34,264:INFO:Finalizing model
2023-09-05 17:38:34,778:INFO:Uploading results into container
2023-09-05 17:38:34,785:INFO:Uploading model into container now
2023-09-05 17:38:34,785:INFO:_master_model_container: 21
2023-09-05 17:38:34,785:INFO:_display_container: 6
2023-09-05 17:38:34,785:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=8, max_features=0.997172072411133,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=5.596327857818154e-09,
                       min_samples_leaf=4, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=217,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 17:38:34,785:INFO:create_model() successfully completed......................................
2023-09-05 17:38:34,844:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:34,844:INFO:choose_better activated
2023-09-05 17:38:34,846:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:34,847:INFO:Initializing create_model()
2023-09-05 17:38:34,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:34,847:INFO:Checking exceptions
2023-09-05 17:38:34,847:INFO:Importing libraries
2023-09-05 17:38:34,847:INFO:Copying training dataset
2023-09-05 17:38:34,847:INFO:Defining folds
2023-09-05 17:38:34,847:INFO:Declaring metric variables
2023-09-05 17:38:34,847:INFO:Importing untrained model
2023-09-05 17:38:34,847:INFO:Declaring custom model
2023-09-05 17:38:34,847:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:34,847:INFO:Starting cross validation
2023-09-05 17:38:34,847:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:35,208:INFO:Calculating mean and std
2023-09-05 17:38:35,208:INFO:Creating metrics dataframe
2023-09-05 17:38:35,209:INFO:Finalizing model
2023-09-05 17:38:35,311:INFO:Uploading results into container
2023-09-05 17:38:35,311:INFO:Uploading model into container now
2023-09-05 17:38:35,311:INFO:_master_model_container: 22
2023-09-05 17:38:35,311:INFO:_display_container: 7
2023-09-05 17:38:35,311:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:35,311:INFO:create_model() successfully completed......................................
2023-09-05 17:38:35,358:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:35,358:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 17:38:35,358:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=8, max_features=0.997172072411133,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=5.596327857818154e-09,
                       min_samples_leaf=4, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=217,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.823
2023-09-05 17:38:35,358:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=8, max_features=0.997172072411133,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=5.596327857818154e-09,
                       min_samples_leaf=4, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=217,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) is best model
2023-09-05 17:38:35,358:INFO:choose_better completed
2023-09-05 17:38:35,368:INFO:_master_model_container: 22
2023-09-05 17:38:35,368:INFO:_display_container: 6
2023-09-05 17:38:35,369:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=8, max_features=0.997172072411133,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=5.596327857818154e-09,
                       min_samples_leaf=4, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=217,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 17:38:35,369:INFO:tune_model() successfully completed......................................
2023-09-05 17:38:35,439:INFO:Initializing tune_model()
2023-09-05 17:38:35,439:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>)
2023-09-05 17:38:35,439:INFO:Checking exceptions
2023-09-05 17:38:35,439:INFO:Soft dependency imported: skopt: 0.9.0
2023-09-05 17:38:35,474:INFO:Copying training dataset
2023-09-05 17:38:35,476:INFO:Checking base model
2023-09-05 17:38:35,476:INFO:Base model : Random Forest Classifier
2023-09-05 17:38:35,479:INFO:Declaring metric variables
2023-09-05 17:38:35,481:INFO:Defining Hyperparameters
2023-09-05 17:38:35,537:INFO:Tuning with n_jobs=-1
2023-09-05 17:38:35,540:INFO:Initializing skopt.BayesSearchCV
2023-09-05 17:38:39,197:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', True), ('actual_estimator__class_weight', 'balanced_subsample'), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 7), ('actual_estimator__max_features', 0.8224534830390922), ('actual_estimator__min_impurity_decrease', 3.902034183027504e-07), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 6), ('actual_estimator__n_estimators', 244)])
2023-09-05 17:38:39,197:INFO:Hyperparameter search completed
2023-09-05 17:38:39,197:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:39,212:INFO:Initializing create_model()
2023-09-05 17:38:39,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000149475F5250>, model_only=True, return_train_score=False, kwargs={'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_depth': 7, 'max_features': 0.8224534830390922, 'min_impurity_decrease': 3.902034183027504e-07, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 244})
2023-09-05 17:38:39,212:INFO:Checking exceptions
2023-09-05 17:38:39,212:INFO:Importing libraries
2023-09-05 17:38:39,212:INFO:Copying training dataset
2023-09-05 17:38:39,215:INFO:Defining folds
2023-09-05 17:38:39,215:INFO:Declaring metric variables
2023-09-05 17:38:39,217:INFO:Importing untrained model
2023-09-05 17:38:39,217:INFO:Declaring custom model
2023-09-05 17:38:39,217:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:39,217:INFO:Starting cross validation
2023-09-05 17:38:39,217:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:39,613:INFO:Calculating mean and std
2023-09-05 17:38:39,613:INFO:Creating metrics dataframe
2023-09-05 17:38:39,613:INFO:Finalizing model
2023-09-05 17:38:39,722:INFO:Uploading results into container
2023-09-05 17:38:39,732:INFO:Uploading model into container now
2023-09-05 17:38:39,732:INFO:_master_model_container: 23
2023-09-05 17:38:39,732:INFO:_display_container: 7
2023-09-05 17:38:39,732:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 17:38:39,732:INFO:create_model() successfully completed......................................
2023-09-05 17:38:39,788:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:39,789:INFO:choose_better activated
2023-09-05 17:38:39,791:INFO:SubProcess create_model() called ==================================
2023-09-05 17:38:39,791:INFO:Initializing create_model()
2023-09-05 17:38:39,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014967CCD7F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:38:39,791:INFO:Checking exceptions
2023-09-05 17:38:39,792:INFO:Importing libraries
2023-09-05 17:38:39,792:INFO:Copying training dataset
2023-09-05 17:38:39,794:INFO:Defining folds
2023-09-05 17:38:39,794:INFO:Declaring metric variables
2023-09-05 17:38:39,794:INFO:Importing untrained model
2023-09-05 17:38:39,794:INFO:Declaring custom model
2023-09-05 17:38:39,795:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:38:39,795:INFO:Starting cross validation
2023-09-05 17:38:39,795:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:38:40,146:INFO:Calculating mean and std
2023-09-05 17:38:40,146:INFO:Creating metrics dataframe
2023-09-05 17:38:40,147:INFO:Finalizing model
2023-09-05 17:38:40,234:INFO:Uploading results into container
2023-09-05 17:38:40,234:INFO:Uploading model into container now
2023-09-05 17:38:40,249:INFO:_master_model_container: 24
2023-09-05 17:38:40,249:INFO:_display_container: 8
2023-09-05 17:38:40,249:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:38:40,249:INFO:create_model() successfully completed......................................
2023-09-05 17:38:40,296:INFO:SubProcess create_model() end ==================================
2023-09-05 17:38:40,296:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-05 17:38:40,296:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8244
2023-09-05 17:38:40,296:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) is best model
2023-09-05 17:38:40,296:INFO:choose_better completed
2023-09-05 17:38:40,307:INFO:_master_model_container: 24
2023-09-05 17:38:40,307:INFO:_display_container: 7
2023-09-05 17:38:40,308:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 17:38:40,308:INFO:tune_model() successfully completed......................................
2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_4e373b5c7d33419baa219dd720bb5f93_7a783c608bdc4465a0e1816757212057
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_4bf2f3188a6a4964b3a4d0f06d74f687
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_38972ab6ede542d687441256432b36af_035629a52b1349cbbadb45889dcbdd24
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_04c740840501443da570e84f63d1962c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_8c20ad8e19de4f92aec4c475089edf00_9e8a3ab1bb7343219e5f3775dafa7bea
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_8aa3f48d0f244cbfa54701ed4facd57c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_0e5e18544f7246e8adc7d622da34dd3f_8aefdf15c7e8458995aaf3e9d312a31c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_68df5d4b3395480c8977b6fc33b20f8a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_7b48c595cb234194adcf04f66212f275_17092bdae3874eef98b0c568ccb6d05c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_5318fd2555144ed7b0105205ba8fd70b
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_f49f5a807cc14708ad0a6cabb14415fc_771cec07afe0410a95087fabeb160815
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_68140a91ed2040949f6de3e353837e4d
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_09a969c732c445aeb58395b42140af36_68e9ea80b42d41cb9c9ec7c469b7eeae
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_cc9ce8dbc1f843eb8907e975bb49760a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_8f0a9424a971465fa7b92332cd44a3b4_25d2faf3195a4a13904392618f056cc3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_2424a5b2b92b42f48f907b4db1f01487
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_7ac136de03434a1bbec770683920606c_2ea994827eec4a60afa6bb3c9285ab07
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_8da58bf5a3ef4f3896379eeea43e9821
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_6f6223d6208948b58a591a72858e4b8d_6d9de1d0eb8f49db9eb270160bb1cbd5
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_9b13e14210a149979eb8b4cae3bd9add
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_e562028df22d4f899cd6148b8c07b29b_11caba04299d468e9016c790f8a6169b
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_caf13f4229d94487a6c45ef649572e6d
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_2fe8d9e59cb64b64a36f3eac963c4342_759ce21d72624960a37f50a648a01477
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_5634d642bda945ab9f1dabf0bc11e71e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_302a3e31527f4979a1eacfb9097c63af_a54fe50addbe4fdcb0cada34f5ecf898
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_1f0243cef2de4b18a5dffd3f180b245c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 18:01:57,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_10436_b023de62aff0492e85e8d1edb067c5f0_a1d655f9c50c4dd694f09dc578be6035
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 09:55:34,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:55:34,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:55:34,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:55:34,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:55:34,710:INFO:PyCaret ClassificationExperiment
2023-09-06 09:55:34,710:INFO:Logging name: clf-default-name
2023-09-06 09:55:34,710:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-06 09:55:34,710:INFO:version 3.0.4
2023-09-06 09:55:34,710:INFO:Initializing setup()
2023-09-06 09:55:34,710:INFO:self.USI: 9aea
2023-09-06 09:55:34,710:INFO:self._variable_keys: {'y_train', 'fold_generator', '_available_plots', 'exp_name_log', 'gpu_n_jobs_param', 'log_plots_param', 'memory', 'is_multiclass', 'y_test', 'gpu_param', 'html_param', 'exp_id', 'X_test', 'fold_shuffle_param', 'X_train', 'logging_param', 'USI', 'n_jobs_param', 'seed', 'target_param', 'fix_imbalance', '_ml_usecase', 'idx', 'X', 'pipeline', 'y', 'fold_groups_param', 'data'}
2023-09-06 09:55:34,710:INFO:Checking environment
2023-09-06 09:55:34,710:INFO:python_version: 3.8.8
2023-09-06 09:55:34,710:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-06 09:55:34,710:INFO:machine: AMD64
2023-09-06 09:55:34,710:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-06 09:55:34,726:INFO:Memory: svmem(total=16822788096, available=8919175168, percent=47.0, used=7903612928, free=8919175168)
2023-09-06 09:55:34,726:INFO:Physical Core: 8
2023-09-06 09:55:34,726:INFO:Logical Core: 16
2023-09-06 09:55:34,726:INFO:Checking libraries
2023-09-06 09:55:34,726:INFO:System:
2023-09-06 09:55:34,726:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-06 09:55:34,726:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-06 09:55:34,726:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-06 09:55:34,726:INFO:PyCaret required dependencies:
2023-09-06 09:55:34,726:INFO:                 pip: 23.2.1
2023-09-06 09:55:34,726:INFO:          setuptools: 65.5.1
2023-09-06 09:55:34,726:INFO:             pycaret: 3.0.4
2023-09-06 09:55:34,726:INFO:             IPython: 8.12.2
2023-09-06 09:55:34,726:INFO:          ipywidgets: 8.0.7
2023-09-06 09:55:34,726:INFO:                tqdm: 4.66.1
2023-09-06 09:55:34,726:INFO:               numpy: 1.23.5
2023-09-06 09:55:34,726:INFO:              pandas: 1.5.3
2023-09-06 09:55:34,726:INFO:              jinja2: 3.1.2
2023-09-06 09:55:34,726:INFO:               scipy: 1.10.1
2023-09-06 09:55:34,726:INFO:              joblib: 1.3.2
2023-09-06 09:55:34,726:INFO:             sklearn: 1.2.2
2023-09-06 09:55:34,726:INFO:                pyod: 1.1.0
2023-09-06 09:55:34,726:INFO:            imblearn: 0.11.0
2023-09-06 09:55:34,726:INFO:   category_encoders: 2.6.2
2023-09-06 09:55:34,726:INFO:            lightgbm: 4.0.0
2023-09-06 09:55:34,726:INFO:               numba: 0.57.1
2023-09-06 09:55:34,726:INFO:            requests: 2.31.0
2023-09-06 09:55:34,726:INFO:          matplotlib: 3.7.2
2023-09-06 09:55:34,726:INFO:          scikitplot: 0.3.7
2023-09-06 09:55:34,726:INFO:         yellowbrick: 1.5
2023-09-06 09:55:34,726:INFO:              plotly: 5.15.0
2023-09-06 09:55:34,726:INFO:    plotly-resampler: Not installed
2023-09-06 09:55:34,726:INFO:             kaleido: 0.2.1
2023-09-06 09:55:34,726:INFO:           schemdraw: 0.15
2023-09-06 09:55:34,726:INFO:         statsmodels: 0.14.0
2023-09-06 09:55:34,726:INFO:              sktime: 0.22.0
2023-09-06 09:55:34,726:INFO:               tbats: 1.1.3
2023-09-06 09:55:34,726:INFO:            pmdarima: 2.0.3
2023-09-06 09:55:34,726:INFO:              psutil: 5.9.5
2023-09-06 09:55:34,726:INFO:          markupsafe: 2.1.3
2023-09-06 09:55:34,726:INFO:             pickle5: Not installed
2023-09-06 09:55:34,726:INFO:         cloudpickle: 2.2.1
2023-09-06 09:55:34,726:INFO:         deprecation: 2.1.0
2023-09-06 09:55:34,726:INFO:              xxhash: 3.3.0
2023-09-06 09:55:34,726:INFO:           wurlitzer: Not installed
2023-09-06 09:55:34,726:INFO:PyCaret optional dependencies:
2023-09-06 09:55:34,726:INFO:                shap: Not installed
2023-09-06 09:55:34,726:INFO:           interpret: Not installed
2023-09-06 09:55:34,726:INFO:                umap: Not installed
2023-09-06 09:55:34,726:INFO:    pandas_profiling: 4.5.1
2023-09-06 09:55:34,726:INFO:  explainerdashboard: Not installed
2023-09-06 09:55:34,726:INFO:             autoviz: Not installed
2023-09-06 09:55:34,726:INFO:           fairlearn: Not installed
2023-09-06 09:55:34,726:INFO:          deepchecks: Not installed
2023-09-06 09:55:34,726:INFO:             xgboost: 1.7.6
2023-09-06 09:55:34,726:INFO:            catboost: 1.2.1
2023-09-06 09:55:34,726:INFO:              kmodes: Not installed
2023-09-06 09:55:34,726:INFO:             mlxtend: Not installed
2023-09-06 09:55:34,726:INFO:       statsforecast: Not installed
2023-09-06 09:55:34,726:INFO:        tune_sklearn: Not installed
2023-09-06 09:55:34,726:INFO:                 ray: Not installed
2023-09-06 09:55:34,726:INFO:            hyperopt: Not installed
2023-09-06 09:55:34,726:INFO:              optuna: 3.3.0
2023-09-06 09:55:34,726:INFO:               skopt: 0.9.0
2023-09-06 09:55:34,726:INFO:              mlflow: Not installed
2023-09-06 09:55:34,726:INFO:              gradio: Not installed
2023-09-06 09:55:34,726:INFO:             fastapi: Not installed
2023-09-06 09:55:34,726:INFO:             uvicorn: Not installed
2023-09-06 09:55:34,726:INFO:              m2cgen: Not installed
2023-09-06 09:55:34,726:INFO:           evidently: Not installed
2023-09-06 09:55:34,726:INFO:               fugue: Not installed
2023-09-06 09:55:34,726:INFO:           streamlit: Not installed
2023-09-06 09:55:34,726:INFO:             prophet: Not installed
2023-09-06 09:55:34,726:INFO:None
2023-09-06 09:55:34,726:INFO:Set up data.
2023-09-06 09:55:34,726:INFO:Set up train/test split.
2023-09-06 09:55:34,742:INFO:Set up index.
2023-09-06 09:55:34,742:INFO:Set up folding strategy.
2023-09-06 09:55:34,742:INFO:Assigning column types.
2023-09-06 09:55:34,742:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-06 09:55:34,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-06 09:55:34,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:55:34,789:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:34,789:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:34,820:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-06 09:55:34,820:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:55:34,851:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:34,851:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:34,851:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-06 09:55:34,882:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:55:34,898:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:34,898:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:34,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:55:34,945:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:34,945:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:34,945:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-06 09:55:34,992:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:34,992:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:35,038:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:35,038:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:35,064:INFO:Preparing preprocessing pipeline...
2023-09-06 09:55:35,064:INFO:Set up simple imputation.
2023-09-06 09:55:35,064:INFO:Finished creating preprocessing pipeline.
2023-09-06 09:55:35,064:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-06 09:55:35,064:INFO:Creating final display dataframe.
2023-09-06 09:55:35,095:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9aea
2023-09-06 09:55:35,165:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:35,166:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:35,205:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:35,205:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:35,205:INFO:setup() successfully completed in 0.54s...............
2023-09-06 09:55:35,220:INFO:gpu_param set to False
2023-09-06 09:55:35,276:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:35,277:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:35,319:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:35,319:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:35,337:INFO:gpu_param set to False
2023-09-06 09:55:35,390:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:35,390:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:35,437:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:55:35,437:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:55:35,488:INFO:Initializing compare_models()
2023-09-06 09:55:35,488:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-06 09:55:35,488:INFO:Checking exceptions
2023-09-06 09:55:35,490:INFO:Preparing display monitor
2023-09-06 09:55:35,507:INFO:Initializing Logistic Regression
2023-09-06 09:55:35,507:INFO:Total runtime is 0.0 minutes
2023-09-06 09:55:35,509:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:35,509:INFO:Initializing create_model()
2023-09-06 09:55:35,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:35,509:INFO:Checking exceptions
2023-09-06 09:55:35,509:INFO:Importing libraries
2023-09-06 09:55:35,509:INFO:Copying training dataset
2023-09-06 09:55:35,511:INFO:Defining folds
2023-09-06 09:55:35,511:INFO:Declaring metric variables
2023-09-06 09:55:35,514:INFO:Importing untrained model
2023-09-06 09:55:35,514:INFO:Logistic Regression Imported successfully
2023-09-06 09:55:35,526:INFO:Starting cross validation
2023-09-06 09:55:35,527:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:37,175:INFO:Calculating mean and std
2023-09-06 09:55:37,175:INFO:Creating metrics dataframe
2023-09-06 09:55:37,219:INFO:Uploading results into container
2023-09-06 09:55:37,219:INFO:Uploading model into container now
2023-09-06 09:55:37,219:INFO:_master_model_container: 1
2023-09-06 09:55:37,219:INFO:_display_container: 2
2023-09-06 09:55:37,219:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-06 09:55:37,219:INFO:create_model() successfully completed......................................
2023-09-06 09:55:37,266:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:37,266:INFO:Creating metrics dataframe
2023-09-06 09:55:37,266:INFO:Initializing K Neighbors Classifier
2023-09-06 09:55:37,266:INFO:Total runtime is 0.029319838682810465 minutes
2023-09-06 09:55:37,266:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:37,266:INFO:Initializing create_model()
2023-09-06 09:55:37,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:37,266:INFO:Checking exceptions
2023-09-06 09:55:37,266:INFO:Importing libraries
2023-09-06 09:55:37,266:INFO:Copying training dataset
2023-09-06 09:55:37,283:INFO:Defining folds
2023-09-06 09:55:37,283:INFO:Declaring metric variables
2023-09-06 09:55:37,285:INFO:Importing untrained model
2023-09-06 09:55:37,287:INFO:K Neighbors Classifier Imported successfully
2023-09-06 09:55:37,289:INFO:Starting cross validation
2023-09-06 09:55:37,289:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:38,631:INFO:Calculating mean and std
2023-09-06 09:55:38,631:INFO:Creating metrics dataframe
2023-09-06 09:55:38,685:INFO:Uploading results into container
2023-09-06 09:55:38,685:INFO:Uploading model into container now
2023-09-06 09:55:38,685:INFO:_master_model_container: 2
2023-09-06 09:55:38,685:INFO:_display_container: 2
2023-09-06 09:55:38,701:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-06 09:55:38,701:INFO:create_model() successfully completed......................................
2023-09-06 09:55:38,732:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:38,732:INFO:Creating metrics dataframe
2023-09-06 09:55:38,748:INFO:Initializing Naive Bayes
2023-09-06 09:55:38,748:INFO:Total runtime is 0.05401754379272461 minutes
2023-09-06 09:55:38,755:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:38,756:INFO:Initializing create_model()
2023-09-06 09:55:38,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:38,756:INFO:Checking exceptions
2023-09-06 09:55:38,756:INFO:Importing libraries
2023-09-06 09:55:38,756:INFO:Copying training dataset
2023-09-06 09:55:38,759:INFO:Defining folds
2023-09-06 09:55:38,759:INFO:Declaring metric variables
2023-09-06 09:55:38,761:INFO:Importing untrained model
2023-09-06 09:55:38,762:INFO:Naive Bayes Imported successfully
2023-09-06 09:55:38,762:INFO:Starting cross validation
2023-09-06 09:55:38,762:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:40,030:INFO:Calculating mean and std
2023-09-06 09:55:40,030:INFO:Creating metrics dataframe
2023-09-06 09:55:40,089:INFO:Uploading results into container
2023-09-06 09:55:40,089:INFO:Uploading model into container now
2023-09-06 09:55:40,089:INFO:_master_model_container: 3
2023-09-06 09:55:40,089:INFO:_display_container: 2
2023-09-06 09:55:40,090:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-06 09:55:40,090:INFO:create_model() successfully completed......................................
2023-09-06 09:55:40,134:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:40,134:INFO:Creating metrics dataframe
2023-09-06 09:55:40,134:INFO:Initializing Decision Tree Classifier
2023-09-06 09:55:40,134:INFO:Total runtime is 0.07712414662043254 minutes
2023-09-06 09:55:40,134:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:40,134:INFO:Initializing create_model()
2023-09-06 09:55:40,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:40,134:INFO:Checking exceptions
2023-09-06 09:55:40,134:INFO:Importing libraries
2023-09-06 09:55:40,134:INFO:Copying training dataset
2023-09-06 09:55:40,145:INFO:Defining folds
2023-09-06 09:55:40,145:INFO:Declaring metric variables
2023-09-06 09:55:40,148:INFO:Importing untrained model
2023-09-06 09:55:40,150:INFO:Decision Tree Classifier Imported successfully
2023-09-06 09:55:40,156:INFO:Starting cross validation
2023-09-06 09:55:40,157:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:41,421:INFO:Calculating mean and std
2023-09-06 09:55:41,421:INFO:Creating metrics dataframe
2023-09-06 09:55:41,468:INFO:Uploading results into container
2023-09-06 09:55:41,468:INFO:Uploading model into container now
2023-09-06 09:55:41,468:INFO:_master_model_container: 4
2023-09-06 09:55:41,468:INFO:_display_container: 2
2023-09-06 09:55:41,468:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-06 09:55:41,468:INFO:create_model() successfully completed......................................
2023-09-06 09:55:41,527:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:41,527:INFO:Creating metrics dataframe
2023-09-06 09:55:41,533:INFO:Initializing SVM - Linear Kernel
2023-09-06 09:55:41,534:INFO:Total runtime is 0.10045642058054607 minutes
2023-09-06 09:55:41,536:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:41,536:INFO:Initializing create_model()
2023-09-06 09:55:41,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:41,536:INFO:Checking exceptions
2023-09-06 09:55:41,536:INFO:Importing libraries
2023-09-06 09:55:41,536:INFO:Copying training dataset
2023-09-06 09:55:41,536:INFO:Defining folds
2023-09-06 09:55:41,536:INFO:Declaring metric variables
2023-09-06 09:55:41,536:INFO:Importing untrained model
2023-09-06 09:55:41,536:INFO:SVM - Linear Kernel Imported successfully
2023-09-06 09:55:41,536:INFO:Starting cross validation
2023-09-06 09:55:41,536:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:42,692:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 09:55:42,692:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 09:55:42,692:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 09:55:42,817:INFO:Calculating mean and std
2023-09-06 09:55:42,817:INFO:Creating metrics dataframe
2023-09-06 09:55:42,868:INFO:Uploading results into container
2023-09-06 09:55:42,868:INFO:Uploading model into container now
2023-09-06 09:55:42,868:INFO:_master_model_container: 5
2023-09-06 09:55:42,868:INFO:_display_container: 2
2023-09-06 09:55:42,868:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-06 09:55:42,868:INFO:create_model() successfully completed......................................
2023-09-06 09:55:42,915:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:42,915:INFO:Creating metrics dataframe
2023-09-06 09:55:42,915:INFO:Initializing Ridge Classifier
2023-09-06 09:55:42,915:INFO:Total runtime is 0.1234666665395101 minutes
2023-09-06 09:55:42,915:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:42,915:INFO:Initializing create_model()
2023-09-06 09:55:42,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:42,915:INFO:Checking exceptions
2023-09-06 09:55:42,915:INFO:Importing libraries
2023-09-06 09:55:42,915:INFO:Copying training dataset
2023-09-06 09:55:42,931:INFO:Defining folds
2023-09-06 09:55:42,931:INFO:Declaring metric variables
2023-09-06 09:55:42,934:INFO:Importing untrained model
2023-09-06 09:55:42,936:INFO:Ridge Classifier Imported successfully
2023-09-06 09:55:42,936:INFO:Starting cross validation
2023-09-06 09:55:42,936:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:42,986:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:55:42,986:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:55:43,967:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:55:43,982:INFO:Calculating mean and std
2023-09-06 09:55:43,982:INFO:Creating metrics dataframe
2023-09-06 09:55:44,034:INFO:Uploading results into container
2023-09-06 09:55:44,034:INFO:Uploading model into container now
2023-09-06 09:55:44,034:INFO:_master_model_container: 6
2023-09-06 09:55:44,034:INFO:_display_container: 2
2023-09-06 09:55:44,034:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-06 09:55:44,034:INFO:create_model() successfully completed......................................
2023-09-06 09:55:44,081:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:44,081:INFO:Creating metrics dataframe
2023-09-06 09:55:44,081:INFO:Initializing Random Forest Classifier
2023-09-06 09:55:44,081:INFO:Total runtime is 0.14290442069371542 minutes
2023-09-06 09:55:44,081:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:44,081:INFO:Initializing create_model()
2023-09-06 09:55:44,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:44,081:INFO:Checking exceptions
2023-09-06 09:55:44,081:INFO:Importing libraries
2023-09-06 09:55:44,081:INFO:Copying training dataset
2023-09-06 09:55:44,098:INFO:Defining folds
2023-09-06 09:55:44,098:INFO:Declaring metric variables
2023-09-06 09:55:44,101:INFO:Importing untrained model
2023-09-06 09:55:44,103:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:55:44,104:INFO:Starting cross validation
2023-09-06 09:55:44,104:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:44,406:INFO:Calculating mean and std
2023-09-06 09:55:44,406:INFO:Creating metrics dataframe
2023-09-06 09:55:44,467:INFO:Uploading results into container
2023-09-06 09:55:44,467:INFO:Uploading model into container now
2023-09-06 09:55:44,467:INFO:_master_model_container: 7
2023-09-06 09:55:44,467:INFO:_display_container: 2
2023-09-06 09:55:44,467:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:44,467:INFO:create_model() successfully completed......................................
2023-09-06 09:55:44,515:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:44,515:INFO:Creating metrics dataframe
2023-09-06 09:55:44,524:INFO:Initializing Quadratic Discriminant Analysis
2023-09-06 09:55:44,524:INFO:Total runtime is 0.15027895371119182 minutes
2023-09-06 09:55:44,526:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:44,526:INFO:Initializing create_model()
2023-09-06 09:55:44,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:44,526:INFO:Checking exceptions
2023-09-06 09:55:44,526:INFO:Importing libraries
2023-09-06 09:55:44,526:INFO:Copying training dataset
2023-09-06 09:55:44,529:INFO:Defining folds
2023-09-06 09:55:44,530:INFO:Declaring metric variables
2023-09-06 09:55:44,532:INFO:Importing untrained model
2023-09-06 09:55:44,534:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-06 09:55:44,539:INFO:Starting cross validation
2023-09-06 09:55:44,540:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:44,695:INFO:Calculating mean and std
2023-09-06 09:55:44,695:INFO:Creating metrics dataframe
2023-09-06 09:55:44,752:INFO:Uploading results into container
2023-09-06 09:55:44,752:INFO:Uploading model into container now
2023-09-06 09:55:44,752:INFO:_master_model_container: 8
2023-09-06 09:55:44,752:INFO:_display_container: 2
2023-09-06 09:55:44,752:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-06 09:55:44,752:INFO:create_model() successfully completed......................................
2023-09-06 09:55:44,799:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:44,799:INFO:Creating metrics dataframe
2023-09-06 09:55:44,799:INFO:Initializing Ada Boost Classifier
2023-09-06 09:55:44,799:INFO:Total runtime is 0.1548641363779704 minutes
2023-09-06 09:55:44,799:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:44,799:INFO:Initializing create_model()
2023-09-06 09:55:44,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:44,799:INFO:Checking exceptions
2023-09-06 09:55:44,799:INFO:Importing libraries
2023-09-06 09:55:44,799:INFO:Copying training dataset
2023-09-06 09:55:44,812:INFO:Defining folds
2023-09-06 09:55:44,812:INFO:Declaring metric variables
2023-09-06 09:55:44,814:INFO:Importing untrained model
2023-09-06 09:55:44,817:INFO:Ada Boost Classifier Imported successfully
2023-09-06 09:55:44,821:INFO:Starting cross validation
2023-09-06 09:55:44,822:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:45,056:INFO:Calculating mean and std
2023-09-06 09:55:45,056:INFO:Creating metrics dataframe
2023-09-06 09:55:45,102:INFO:Uploading results into container
2023-09-06 09:55:45,102:INFO:Uploading model into container now
2023-09-06 09:55:45,102:INFO:_master_model_container: 9
2023-09-06 09:55:45,102:INFO:_display_container: 2
2023-09-06 09:55:45,102:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-06 09:55:45,102:INFO:create_model() successfully completed......................................
2023-09-06 09:55:45,149:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:45,149:INFO:Creating metrics dataframe
2023-09-06 09:55:45,165:INFO:Initializing Gradient Boosting Classifier
2023-09-06 09:55:45,165:INFO:Total runtime is 0.16096177895863853 minutes
2023-09-06 09:55:45,165:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:45,165:INFO:Initializing create_model()
2023-09-06 09:55:45,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:45,165:INFO:Checking exceptions
2023-09-06 09:55:45,165:INFO:Importing libraries
2023-09-06 09:55:45,165:INFO:Copying training dataset
2023-09-06 09:55:45,172:INFO:Defining folds
2023-09-06 09:55:45,172:INFO:Declaring metric variables
2023-09-06 09:55:45,175:INFO:Importing untrained model
2023-09-06 09:55:45,178:INFO:Gradient Boosting Classifier Imported successfully
2023-09-06 09:55:45,179:INFO:Starting cross validation
2023-09-06 09:55:45,185:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:45,423:INFO:Calculating mean and std
2023-09-06 09:55:45,423:INFO:Creating metrics dataframe
2023-09-06 09:55:45,484:INFO:Uploading results into container
2023-09-06 09:55:45,484:INFO:Uploading model into container now
2023-09-06 09:55:45,484:INFO:_master_model_container: 10
2023-09-06 09:55:45,484:INFO:_display_container: 2
2023-09-06 09:55:45,484:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-06 09:55:45,484:INFO:create_model() successfully completed......................................
2023-09-06 09:55:45,534:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:45,534:INFO:Creating metrics dataframe
2023-09-06 09:55:45,535:INFO:Initializing Linear Discriminant Analysis
2023-09-06 09:55:45,535:INFO:Total runtime is 0.16713581085205081 minutes
2023-09-06 09:55:45,535:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:45,535:INFO:Initializing create_model()
2023-09-06 09:55:45,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:45,535:INFO:Checking exceptions
2023-09-06 09:55:45,535:INFO:Importing libraries
2023-09-06 09:55:45,535:INFO:Copying training dataset
2023-09-06 09:55:45,535:INFO:Defining folds
2023-09-06 09:55:45,535:INFO:Declaring metric variables
2023-09-06 09:55:45,535:INFO:Importing untrained model
2023-09-06 09:55:45,535:INFO:Linear Discriminant Analysis Imported successfully
2023-09-06 09:55:45,555:INFO:Starting cross validation
2023-09-06 09:55:45,556:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:45,727:INFO:Calculating mean and std
2023-09-06 09:55:45,727:INFO:Creating metrics dataframe
2023-09-06 09:55:45,783:INFO:Uploading results into container
2023-09-06 09:55:45,783:INFO:Uploading model into container now
2023-09-06 09:55:45,783:INFO:_master_model_container: 11
2023-09-06 09:55:45,783:INFO:_display_container: 2
2023-09-06 09:55:45,783:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-06 09:55:45,783:INFO:create_model() successfully completed......................................
2023-09-06 09:55:45,825:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:45,825:INFO:Creating metrics dataframe
2023-09-06 09:55:45,841:INFO:Initializing Extra Trees Classifier
2023-09-06 09:55:45,841:INFO:Total runtime is 0.1722297231356303 minutes
2023-09-06 09:55:45,841:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:45,841:INFO:Initializing create_model()
2023-09-06 09:55:45,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:45,841:INFO:Checking exceptions
2023-09-06 09:55:45,841:INFO:Importing libraries
2023-09-06 09:55:45,841:INFO:Copying training dataset
2023-09-06 09:55:45,849:INFO:Defining folds
2023-09-06 09:55:45,849:INFO:Declaring metric variables
2023-09-06 09:55:45,852:INFO:Importing untrained model
2023-09-06 09:55:45,854:INFO:Extra Trees Classifier Imported successfully
2023-09-06 09:55:45,856:INFO:Starting cross validation
2023-09-06 09:55:45,856:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:46,198:INFO:Calculating mean and std
2023-09-06 09:55:46,198:INFO:Creating metrics dataframe
2023-09-06 09:55:46,252:INFO:Uploading results into container
2023-09-06 09:55:46,252:INFO:Uploading model into container now
2023-09-06 09:55:46,252:INFO:_master_model_container: 12
2023-09-06 09:55:46,252:INFO:_display_container: 2
2023-09-06 09:55:46,252:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:46,252:INFO:create_model() successfully completed......................................
2023-09-06 09:55:46,299:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:46,299:INFO:Creating metrics dataframe
2023-09-06 09:55:46,299:INFO:Initializing Extreme Gradient Boosting
2023-09-06 09:55:46,299:INFO:Total runtime is 0.17986062367757163 minutes
2023-09-06 09:55:46,314:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:46,314:INFO:Initializing create_model()
2023-09-06 09:55:46,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:46,314:INFO:Checking exceptions
2023-09-06 09:55:46,314:INFO:Importing libraries
2023-09-06 09:55:46,314:INFO:Copying training dataset
2023-09-06 09:55:46,318:INFO:Defining folds
2023-09-06 09:55:46,318:INFO:Declaring metric variables
2023-09-06 09:55:46,320:INFO:Importing untrained model
2023-09-06 09:55:46,322:INFO:Extreme Gradient Boosting Imported successfully
2023-09-06 09:55:46,324:INFO:Starting cross validation
2023-09-06 09:55:46,324:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:46,550:INFO:Calculating mean and std
2023-09-06 09:55:46,550:INFO:Creating metrics dataframe
2023-09-06 09:55:46,600:INFO:Uploading results into container
2023-09-06 09:55:46,600:INFO:Uploading model into container now
2023-09-06 09:55:46,600:INFO:_master_model_container: 13
2023-09-06 09:55:46,600:INFO:_display_container: 2
2023-09-06 09:55:46,600:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-06 09:55:46,600:INFO:create_model() successfully completed......................................
2023-09-06 09:55:46,647:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:46,647:INFO:Creating metrics dataframe
2023-09-06 09:55:46,647:INFO:Initializing Light Gradient Boosting Machine
2023-09-06 09:55:46,647:INFO:Total runtime is 0.1856719732284546 minutes
2023-09-06 09:55:46,663:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:46,663:INFO:Initializing create_model()
2023-09-06 09:55:46,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:46,663:INFO:Checking exceptions
2023-09-06 09:55:46,663:INFO:Importing libraries
2023-09-06 09:55:46,665:INFO:Copying training dataset
2023-09-06 09:55:46,667:INFO:Defining folds
2023-09-06 09:55:46,667:INFO:Declaring metric variables
2023-09-06 09:55:46,670:INFO:Importing untrained model
2023-09-06 09:55:46,672:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-06 09:55:46,673:INFO:Starting cross validation
2023-09-06 09:55:46,673:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:46,874:INFO:Calculating mean and std
2023-09-06 09:55:46,874:INFO:Creating metrics dataframe
2023-09-06 09:55:46,933:INFO:Uploading results into container
2023-09-06 09:55:46,933:INFO:Uploading model into container now
2023-09-06 09:55:46,933:INFO:_master_model_container: 14
2023-09-06 09:55:46,933:INFO:_display_container: 2
2023-09-06 09:55:46,933:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-06 09:55:46,933:INFO:create_model() successfully completed......................................
2023-09-06 09:55:46,980:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:46,980:INFO:Creating metrics dataframe
2023-09-06 09:55:46,980:INFO:Initializing Dummy Classifier
2023-09-06 09:55:46,980:INFO:Total runtime is 0.19121049245198568 minutes
2023-09-06 09:55:46,980:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:46,980:INFO:Initializing create_model()
2023-09-06 09:55:46,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF895250>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:46,980:INFO:Checking exceptions
2023-09-06 09:55:46,980:INFO:Importing libraries
2023-09-06 09:55:46,980:INFO:Copying training dataset
2023-09-06 09:55:46,997:INFO:Defining folds
2023-09-06 09:55:46,997:INFO:Declaring metric variables
2023-09-06 09:55:46,999:INFO:Importing untrained model
2023-09-06 09:55:47,001:INFO:Dummy Classifier Imported successfully
2023-09-06 09:55:47,004:INFO:Starting cross validation
2023-09-06 09:55:47,004:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:47,042:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 09:55:47,043:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 09:55:47,045:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 09:55:47,145:INFO:Calculating mean and std
2023-09-06 09:55:47,145:INFO:Creating metrics dataframe
2023-09-06 09:55:47,201:INFO:Uploading results into container
2023-09-06 09:55:47,201:INFO:Uploading model into container now
2023-09-06 09:55:47,201:INFO:_master_model_container: 15
2023-09-06 09:55:47,201:INFO:_display_container: 2
2023-09-06 09:55:47,201:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-06 09:55:47,201:INFO:create_model() successfully completed......................................
2023-09-06 09:55:47,248:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:47,248:INFO:Creating metrics dataframe
2023-09-06 09:55:47,263:INFO:Initializing create_model()
2023-09-06 09:55:47,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:47,263:INFO:Checking exceptions
2023-09-06 09:55:47,265:INFO:Importing libraries
2023-09-06 09:55:47,265:INFO:Copying training dataset
2023-09-06 09:55:47,267:INFO:Defining folds
2023-09-06 09:55:47,267:INFO:Declaring metric variables
2023-09-06 09:55:47,267:INFO:Importing untrained model
2023-09-06 09:55:47,267:INFO:Declaring custom model
2023-09-06 09:55:47,268:INFO:Gradient Boosting Classifier Imported successfully
2023-09-06 09:55:47,268:INFO:Cross validation set to False
2023-09-06 09:55:47,268:INFO:Fitting Model
2023-09-06 09:55:47,381:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-06 09:55:47,381:INFO:create_model() successfully completed......................................
2023-09-06 09:55:47,443:INFO:Initializing create_model()
2023-09-06 09:55:47,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:47,443:INFO:Checking exceptions
2023-09-06 09:55:47,445:INFO:Importing libraries
2023-09-06 09:55:47,445:INFO:Copying training dataset
2023-09-06 09:55:47,446:INFO:Defining folds
2023-09-06 09:55:47,446:INFO:Declaring metric variables
2023-09-06 09:55:47,446:INFO:Importing untrained model
2023-09-06 09:55:47,446:INFO:Declaring custom model
2023-09-06 09:55:47,446:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-06 09:55:47,446:INFO:Cross validation set to False
2023-09-06 09:55:47,446:INFO:Fitting Model
2023-09-06 09:55:47,471:INFO:[LightGBM] [Info] Number of positive: 273, number of negative: 439
2023-09-06 09:55:47,474:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.
2023-09-06 09:55:47,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-09-06 09:55:47,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-09-06 09:55:47,475:INFO:[LightGBM] [Info] Total Bins 274
2023-09-06 09:55:47,475:INFO:[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9
2023-09-06 09:55:47,475:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028
2023-09-06 09:55:47,476:INFO:[LightGBM] [Info] Start training from score -0.475028
2023-09-06 09:55:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:55:47,566:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-06 09:55:47,566:INFO:create_model() successfully completed......................................
2023-09-06 09:55:47,628:INFO:Initializing create_model()
2023-09-06 09:55:47,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:47,628:INFO:Checking exceptions
2023-09-06 09:55:47,628:INFO:Importing libraries
2023-09-06 09:55:47,628:INFO:Copying training dataset
2023-09-06 09:55:47,633:INFO:Defining folds
2023-09-06 09:55:47,633:INFO:Declaring metric variables
2023-09-06 09:55:47,634:INFO:Importing untrained model
2023-09-06 09:55:47,634:INFO:Declaring custom model
2023-09-06 09:55:47,634:INFO:Extreme Gradient Boosting Imported successfully
2023-09-06 09:55:47,635:INFO:Cross validation set to False
2023-09-06 09:55:47,635:INFO:Fitting Model
2023-09-06 09:55:47,730:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-06 09:55:47,730:INFO:create_model() successfully completed......................................
2023-09-06 09:55:47,806:INFO:_master_model_container: 15
2023-09-06 09:55:47,806:INFO:_display_container: 2
2023-09-06 09:55:47,806:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)]
2023-09-06 09:55:47,806:INFO:compare_models() successfully completed......................................
2023-09-06 09:55:47,839:INFO:Initializing create_model()
2023-09-06 09:55:47,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-06 09:55:47,839:INFO:Checking exceptions
2023-09-06 09:55:47,852:INFO:Importing libraries
2023-09-06 09:55:47,852:INFO:Copying training dataset
2023-09-06 09:55:47,855:INFO:Defining folds
2023-09-06 09:55:47,855:INFO:Declaring metric variables
2023-09-06 09:55:47,858:INFO:Importing untrained model
2023-09-06 09:55:47,858:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:55:47,858:INFO:Starting cross validation
2023-09-06 09:55:47,868:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:48,249:INFO:Calculating mean and std
2023-09-06 09:55:48,249:INFO:Creating metrics dataframe
2023-09-06 09:55:48,249:INFO:Finalizing model
2023-09-06 09:55:48,362:INFO:Uploading results into container
2023-09-06 09:55:48,365:INFO:Uploading model into container now
2023-09-06 09:55:48,368:INFO:_master_model_container: 16
2023-09-06 09:55:48,368:INFO:_display_container: 3
2023-09-06 09:55:48,368:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:48,368:INFO:create_model() successfully completed......................................
2023-09-06 09:55:48,427:INFO:Initializing tune_model()
2023-09-06 09:55:48,427:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [150, 200, 250], 'max_depth': [10, 20], 'min_samples_split': [1, 2, 3], 'min_samples_leaf': [1, 2, 3]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>)
2023-09-06 09:55:48,427:INFO:Checking exceptions
2023-09-06 09:55:48,437:INFO:Copying training dataset
2023-09-06 09:55:48,439:INFO:Checking base model
2023-09-06 09:55:48,439:INFO:Base model : Random Forest Classifier
2023-09-06 09:55:48,441:INFO:Declaring metric variables
2023-09-06 09:55:48,441:INFO:Defining Hyperparameters
2023-09-06 09:55:48,492:INFO:custom_grid: {'actual_estimator__n_estimators': [150, 200, 250], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2, 3], 'actual_estimator__min_samples_leaf': [1, 2, 3]}
2023-09-06 09:55:48,492:INFO:Tuning with n_jobs=-1
2023-09-06 09:55:48,492:INFO:Initializing RandomizedSearchCV
2023-09-06 09:55:50,153:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
12 fits failed out of a total of 30.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
12 fits failed with the following error:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\AI\pythonProject\venv\lib\site-packages\joblib\memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-06 09:55:50,153:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8033838         nan        nan 0.82725242 0.81741895 0.81881951
 0.81881951        nan 0.80899195        nan]
  warnings.warn(

2023-09-06 09:55:50,200:INFO:best_params: {'actual_estimator__n_estimators': 250, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-06 09:55:50,200:INFO:Hyperparameter search completed
2023-09-06 09:55:50,200:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:50,200:INFO:Initializing create_model()
2023-09-06 09:55:50,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271DB429F40>, model_only=True, return_train_score=False, kwargs={'n_estimators': 250, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-06 09:55:50,200:INFO:Checking exceptions
2023-09-06 09:55:50,200:INFO:Importing libraries
2023-09-06 09:55:50,200:INFO:Copying training dataset
2023-09-06 09:55:50,218:INFO:Defining folds
2023-09-06 09:55:50,218:INFO:Declaring metric variables
2023-09-06 09:55:50,220:INFO:Importing untrained model
2023-09-06 09:55:50,220:INFO:Declaring custom model
2023-09-06 09:55:50,222:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:55:50,227:INFO:Starting cross validation
2023-09-06 09:55:50,227:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:50,629:INFO:Calculating mean and std
2023-09-06 09:55:50,629:INFO:Creating metrics dataframe
2023-09-06 09:55:50,629:INFO:Finalizing model
2023-09-06 09:55:50,747:INFO:Uploading results into container
2023-09-06 09:55:50,747:INFO:Uploading model into container now
2023-09-06 09:55:50,759:INFO:_master_model_container: 17
2023-09-06 09:55:50,759:INFO:_display_container: 4
2023-09-06 09:55:50,759:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:50,759:INFO:create_model() successfully completed......................................
2023-09-06 09:55:50,802:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:50,802:INFO:choose_better activated
2023-09-06 09:55:50,804:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:50,804:INFO:Initializing create_model()
2023-09-06 09:55:50,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:50,804:INFO:Checking exceptions
2023-09-06 09:55:50,805:INFO:Importing libraries
2023-09-06 09:55:50,805:INFO:Copying training dataset
2023-09-06 09:55:50,808:INFO:Defining folds
2023-09-06 09:55:50,808:INFO:Declaring metric variables
2023-09-06 09:55:50,808:INFO:Importing untrained model
2023-09-06 09:55:50,808:INFO:Declaring custom model
2023-09-06 09:55:50,809:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:55:50,809:INFO:Starting cross validation
2023-09-06 09:55:50,809:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:51,163:INFO:Calculating mean and std
2023-09-06 09:55:51,163:INFO:Creating metrics dataframe
2023-09-06 09:55:51,163:INFO:Finalizing model
2023-09-06 09:55:51,266:INFO:Uploading results into container
2023-09-06 09:55:51,266:INFO:Uploading model into container now
2023-09-06 09:55:51,266:INFO:_master_model_container: 18
2023-09-06 09:55:51,266:INFO:_display_container: 5
2023-09-06 09:55:51,266:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:51,266:INFO:create_model() successfully completed......................................
2023-09-06 09:55:51,297:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:51,297:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-06 09:55:51,297:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8273
2023-09-06 09:55:51,297:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-06 09:55:51,297:INFO:choose_better completed
2023-09-06 09:55:51,315:INFO:_master_model_container: 18
2023-09-06 09:55:51,315:INFO:_display_container: 4
2023-09-06 09:55:51,315:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:51,315:INFO:tune_model() successfully completed......................................
2023-09-06 09:55:51,426:INFO:Initializing tune_model()
2023-09-06 09:55:51,426:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>)
2023-09-06 09:55:51,426:INFO:Checking exceptions
2023-09-06 09:55:51,439:INFO:Copying training dataset
2023-09-06 09:55:51,439:INFO:Checking base model
2023-09-06 09:55:51,439:INFO:Base model : Random Forest Classifier
2023-09-06 09:55:51,439:INFO:Declaring metric variables
2023-09-06 09:55:51,439:INFO:Defining Hyperparameters
2023-09-06 09:55:51,492:INFO:Tuning with n_jobs=-1
2023-09-06 09:55:51,492:INFO:Initializing RandomizedSearchCV
2023-09-06 09:55:53,258:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-09-06 09:55:53,258:INFO:Hyperparameter search completed
2023-09-06 09:55:53,258:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:53,258:INFO:Initializing create_model()
2023-09-06 09:55:53,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF6DEC70>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2023-09-06 09:55:53,258:INFO:Checking exceptions
2023-09-06 09:55:53,258:INFO:Importing libraries
2023-09-06 09:55:53,258:INFO:Copying training dataset
2023-09-06 09:55:53,274:INFO:Defining folds
2023-09-06 09:55:53,274:INFO:Declaring metric variables
2023-09-06 09:55:53,276:INFO:Importing untrained model
2023-09-06 09:55:53,276:INFO:Declaring custom model
2023-09-06 09:55:53,276:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:55:53,283:INFO:Starting cross validation
2023-09-06 09:55:53,283:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:53,612:INFO:Calculating mean and std
2023-09-06 09:55:53,612:INFO:Creating metrics dataframe
2023-09-06 09:55:53,612:INFO:Finalizing model
2023-09-06 09:55:53,713:INFO:Uploading results into container
2023-09-06 09:55:53,713:INFO:Uploading model into container now
2023-09-06 09:55:53,718:INFO:_master_model_container: 19
2023-09-06 09:55:53,718:INFO:_display_container: 5
2023-09-06 09:55:53,718:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:53,718:INFO:create_model() successfully completed......................................
2023-09-06 09:55:53,764:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:53,764:INFO:choose_better activated
2023-09-06 09:55:53,766:INFO:SubProcess create_model() called ==================================
2023-09-06 09:55:53,766:INFO:Initializing create_model()
2023-09-06 09:55:53,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:55:53,767:INFO:Checking exceptions
2023-09-06 09:55:53,767:INFO:Importing libraries
2023-09-06 09:55:53,767:INFO:Copying training dataset
2023-09-06 09:55:53,770:INFO:Defining folds
2023-09-06 09:55:53,770:INFO:Declaring metric variables
2023-09-06 09:55:53,770:INFO:Importing untrained model
2023-09-06 09:55:53,770:INFO:Declaring custom model
2023-09-06 09:55:53,770:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:55:53,770:INFO:Starting cross validation
2023-09-06 09:55:53,771:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:55:54,123:INFO:Calculating mean and std
2023-09-06 09:55:54,123:INFO:Creating metrics dataframe
2023-09-06 09:55:54,123:INFO:Finalizing model
2023-09-06 09:55:54,216:INFO:Uploading results into container
2023-09-06 09:55:54,216:INFO:Uploading model into container now
2023-09-06 09:55:54,216:INFO:_master_model_container: 20
2023-09-06 09:55:54,216:INFO:_display_container: 6
2023-09-06 09:55:54,216:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:54,216:INFO:create_model() successfully completed......................................
2023-09-06 09:55:54,263:INFO:SubProcess create_model() end ==================================
2023-09-06 09:55:54,263:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-06 09:55:54,263:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8244
2023-09-06 09:55:54,263:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-06 09:55:54,263:INFO:choose_better completed
2023-09-06 09:55:54,278:INFO:_master_model_container: 20
2023-09-06 09:55:54,278:INFO:_display_container: 5
2023-09-06 09:55:54,279:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:55:54,279:INFO:tune_model() successfully completed......................................
2023-09-06 09:55:54,385:INFO:Initializing tune_model()
2023-09-06 09:55:54,385:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>)
2023-09-06 09:55:54,386:INFO:Checking exceptions
2023-09-06 09:55:54,386:INFO:Soft dependency imported: optuna: 3.3.0
2023-09-06 09:55:54,680:INFO:Copying training dataset
2023-09-06 09:55:54,682:INFO:Checking base model
2023-09-06 09:55:54,682:INFO:Base model : Random Forest Classifier
2023-09-06 09:55:54,686:INFO:Declaring metric variables
2023-09-06 09:55:54,687:INFO:Defining Hyperparameters
2023-09-06 09:55:54,750:INFO:Tuning with n_jobs=-1
2023-09-06 09:55:54,750:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\samplers\_tpe\sampler.py:277: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-09-06 09:55:54,750:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\samplers\_tpe\sampler.py:296: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-09-06 09:55:54,750:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-09-06 09:55:54,750:INFO:Initializing optuna.integration.OptunaSearchCV
2023-09-06 09:55:54,750:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2441: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-09-06 09:56:06,702:INFO:best_params: {'actual_estimator__n_estimators': 129, 'actual_estimator__max_depth': 10, 'actual_estimator__min_impurity_decrease': 0.000524543590179047, 'actual_estimator__max_features': 0.7723885921845095, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__bootstrap': True, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}}
2023-09-06 09:56:06,702:INFO:Hyperparameter search completed
2023-09-06 09:56:06,702:INFO:SubProcess create_model() called ==================================
2023-09-06 09:56:06,715:INFO:Initializing create_model()
2023-09-06 09:56:06,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF6D5FA0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 129, 'max_depth': 10, 'min_impurity_decrease': 0.000524543590179047, 'max_features': 0.7723885921845095, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': True, 'criterion': 'gini', 'class_weight': {}})
2023-09-06 09:56:06,715:INFO:Checking exceptions
2023-09-06 09:56:06,715:INFO:Importing libraries
2023-09-06 09:56:06,715:INFO:Copying training dataset
2023-09-06 09:56:06,717:INFO:Defining folds
2023-09-06 09:56:06,717:INFO:Declaring metric variables
2023-09-06 09:56:06,720:INFO:Importing untrained model
2023-09-06 09:56:06,720:INFO:Declaring custom model
2023-09-06 09:56:06,723:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:56:06,723:INFO:Starting cross validation
2023-09-06 09:56:06,723:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:56:07,016:INFO:Calculating mean and std
2023-09-06 09:56:07,017:INFO:Creating metrics dataframe
2023-09-06 09:56:07,021:INFO:Finalizing model
2023-09-06 09:56:07,300:INFO:Uploading results into container
2023-09-06 09:56:07,300:INFO:Uploading model into container now
2023-09-06 09:56:07,312:INFO:_master_model_container: 21
2023-09-06 09:56:07,312:INFO:_display_container: 6
2023-09-06 09:56:07,312:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10,
                       max_features=0.7723885921845095, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.000524543590179047,
                       min_samples_leaf=3, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=129,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-06 09:56:07,312:INFO:create_model() successfully completed......................................
2023-09-06 09:56:07,368:INFO:SubProcess create_model() end ==================================
2023-09-06 09:56:07,368:INFO:choose_better activated
2023-09-06 09:56:07,370:INFO:SubProcess create_model() called ==================================
2023-09-06 09:56:07,370:INFO:Initializing create_model()
2023-09-06 09:56:07,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:56:07,370:INFO:Checking exceptions
2023-09-06 09:56:07,371:INFO:Importing libraries
2023-09-06 09:56:07,371:INFO:Copying training dataset
2023-09-06 09:56:07,373:INFO:Defining folds
2023-09-06 09:56:07,373:INFO:Declaring metric variables
2023-09-06 09:56:07,374:INFO:Importing untrained model
2023-09-06 09:56:07,374:INFO:Declaring custom model
2023-09-06 09:56:07,374:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:56:07,374:INFO:Starting cross validation
2023-09-06 09:56:07,375:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:56:07,758:INFO:Calculating mean and std
2023-09-06 09:56:07,758:INFO:Creating metrics dataframe
2023-09-06 09:56:07,758:INFO:Finalizing model
2023-09-06 09:56:07,868:INFO:Uploading results into container
2023-09-06 09:56:07,868:INFO:Uploading model into container now
2023-09-06 09:56:07,868:INFO:_master_model_container: 22
2023-09-06 09:56:07,868:INFO:_display_container: 7
2023-09-06 09:56:07,868:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:56:07,868:INFO:create_model() successfully completed......................................
2023-09-06 09:56:07,914:INFO:SubProcess create_model() end ==================================
2023-09-06 09:56:07,914:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-06 09:56:07,914:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10,
                       max_features=0.7723885921845095, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.000524543590179047,
                       min_samples_leaf=3, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=129,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.823
2023-09-06 09:56:07,914:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10,
                       max_features=0.7723885921845095, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.000524543590179047,
                       min_samples_leaf=3, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=129,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) is best model
2023-09-06 09:56:07,914:INFO:choose_better completed
2023-09-06 09:56:07,928:INFO:_master_model_container: 22
2023-09-06 09:56:07,928:INFO:_display_container: 6
2023-09-06 09:56:07,928:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10,
                       max_features=0.7723885921845095, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.000524543590179047,
                       min_samples_leaf=3, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=129,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-06 09:56:07,929:INFO:tune_model() successfully completed......................................
2023-09-06 09:56:07,989:INFO:Initializing tune_model()
2023-09-06 09:56:07,989:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>)
2023-09-06 09:56:07,989:INFO:Checking exceptions
2023-09-06 09:56:07,989:INFO:Soft dependency imported: skopt: 0.9.0
2023-09-06 09:56:08,034:INFO:Copying training dataset
2023-09-06 09:56:08,035:INFO:Checking base model
2023-09-06 09:56:08,035:INFO:Base model : Random Forest Classifier
2023-09-06 09:56:08,038:INFO:Declaring metric variables
2023-09-06 09:56:08,041:INFO:Defining Hyperparameters
2023-09-06 09:56:08,098:INFO:Tuning with n_jobs=-1
2023-09-06 09:56:08,098:INFO:Initializing skopt.BayesSearchCV
2023-09-06 09:56:12,095:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', True), ('actual_estimator__class_weight', 'balanced_subsample'), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 7), ('actual_estimator__max_features', 0.8224534830390922), ('actual_estimator__min_impurity_decrease', 3.902034183027504e-07), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 6), ('actual_estimator__n_estimators', 244)])
2023-09-06 09:56:12,095:INFO:Hyperparameter search completed
2023-09-06 09:56:12,095:INFO:SubProcess create_model() called ==================================
2023-09-06 09:56:12,095:INFO:Initializing create_model()
2023-09-06 09:56:12,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000271FF6DEFA0>, model_only=True, return_train_score=False, kwargs={'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_depth': 7, 'max_features': 0.8224534830390922, 'min_impurity_decrease': 3.902034183027504e-07, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 244})
2023-09-06 09:56:12,095:INFO:Checking exceptions
2023-09-06 09:56:12,095:INFO:Importing libraries
2023-09-06 09:56:12,095:INFO:Copying training dataset
2023-09-06 09:56:12,095:INFO:Defining folds
2023-09-06 09:56:12,095:INFO:Declaring metric variables
2023-09-06 09:56:12,106:INFO:Importing untrained model
2023-09-06 09:56:12,106:INFO:Declaring custom model
2023-09-06 09:56:12,108:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:56:12,115:INFO:Starting cross validation
2023-09-06 09:56:12,115:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:56:12,508:INFO:Calculating mean and std
2023-09-06 09:56:12,508:INFO:Creating metrics dataframe
2023-09-06 09:56:12,512:INFO:Finalizing model
2023-09-06 09:56:12,642:INFO:Uploading results into container
2023-09-06 09:56:12,642:INFO:Uploading model into container now
2023-09-06 09:56:12,647:INFO:_master_model_container: 23
2023-09-06 09:56:12,647:INFO:_display_container: 7
2023-09-06 09:56:12,647:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-06 09:56:12,647:INFO:create_model() successfully completed......................................
2023-09-06 09:56:12,704:INFO:SubProcess create_model() end ==================================
2023-09-06 09:56:12,704:INFO:choose_better activated
2023-09-06 09:56:12,707:INFO:SubProcess create_model() called ==================================
2023-09-06 09:56:12,707:INFO:Initializing create_model()
2023-09-06 09:56:12,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000271FB915880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:56:12,707:INFO:Checking exceptions
2023-09-06 09:56:12,708:INFO:Importing libraries
2023-09-06 09:56:12,708:INFO:Copying training dataset
2023-09-06 09:56:12,710:INFO:Defining folds
2023-09-06 09:56:12,710:INFO:Declaring metric variables
2023-09-06 09:56:12,710:INFO:Importing untrained model
2023-09-06 09:56:12,710:INFO:Declaring custom model
2023-09-06 09:56:12,711:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:56:12,711:INFO:Starting cross validation
2023-09-06 09:56:12,711:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:56:13,086:INFO:Calculating mean and std
2023-09-06 09:56:13,086:INFO:Creating metrics dataframe
2023-09-06 09:56:13,086:INFO:Finalizing model
2023-09-06 09:56:13,195:INFO:Uploading results into container
2023-09-06 09:56:13,195:INFO:Uploading model into container now
2023-09-06 09:56:13,195:INFO:_master_model_container: 24
2023-09-06 09:56:13,195:INFO:_display_container: 8
2023-09-06 09:56:13,195:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:56:13,195:INFO:create_model() successfully completed......................................
2023-09-06 09:56:13,242:INFO:SubProcess create_model() end ==================================
2023-09-06 09:56:13,242:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-06 09:56:13,242:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8244
2023-09-06 09:56:13,242:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) is best model
2023-09-06 09:56:13,242:INFO:choose_better completed
2023-09-06 09:56:13,258:INFO:_master_model_container: 24
2023-09-06 09:56:13,258:INFO:_display_container: 7
2023-09-06 09:56:13,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-06 09:56:13,258:INFO:tune_model() successfully completed......................................
2023-09-06 16:10:27,971:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:10:51,035:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:10:59,579:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:13:00,272:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:13:00,649:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:13:00,665:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:13:00,665:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:13:00,680:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:13:00,696:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 16:13:00,696:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_374ead2ecdce493cbefced5a549fdef2_b289f4c7ba4e434a84be1fd9780581c1
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_b72ea8b247884cb0887b124f82d5b2b5
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_8e0f44f2f78a4580acc91b70ad2b3ff4_834076b3f305495b832125c87b2abf28
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_de0ccfc49f0f463ab3585b15012591c6
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_f75163873f3e49cbb5e7b1b4423f22b0_595391b3f98d4039870a30ed2234ce70
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_b5eed8b6898146cda72dfa92d2c3a950
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_5bf87ff4bd3b48148d56cfe5d11767ff_22fb73cede90427db049324452db50d9
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_7a287ecf688c461dbcc8c17458273202
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_eae5636c0c654f3b8fbde031f1e96494_0215c97498db45f8bac84d19f2e91280
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_192de57f6b724c05923ee8da29c55486
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b0cb4d727c9f469b9d07677f03aac4ec_62e7e386b8ac40be84d32810c434cfef
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_540f8995a3394a20920d7bab7aa6b8e7
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_2ef1d9f9e3b5431e8738156d3366bd16_be10c9a21bd64bdba5a61401350b2bbd
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_7058846a84244b978a38b2096c2a9fc8
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_54c512381d9f450cba5555f3904b49a1_22acdd31e9a3471a924073ae50643508
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_14ca017c94cd4ef191d44f068979056c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_c00fa2bbe4b742bcae21c89f3f2f366b_ce4eaa2c4db147619290b56499ab9a7f
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_760d04c950fb4af0ae71421f45936429
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_abd3294cf0c443c3a8db9ec562122282_feda86dc489b4e0e89e4c93c31be7d51
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_63c386da24b343a39b3358cf2a931eb2
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_ee0ef0d5f27042fca770770ca9d2255f_e023a531c2b64a28b9f363eceaa451e2
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_0e0fe2de064a4e6bb686af992569c453
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b69a35b710af4a7c9baa977f8ae8b388_6708ea65939349bfa418e7fa00bcf9bd
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_12de5e86607643f2a8164b36f33b6415
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_3ec1a705947b418f8840b0e62ec9199e_5c745af22b9941649583fd7aaf58bfe3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_f6853d3e718c4a6693469bee03b184c4
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:04:42,192:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_9688_b1198951003743e1beb38bd03e1f340f_d8cbed6665ff439fa381d4f0130e80f2
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:06:26,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 17:06:26,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 17:06:26,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 17:06:26,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 17:06:27,137:INFO:PyCaret ClassificationExperiment
2023-09-06 17:06:27,137:INFO:Logging name: clf-default-name
2023-09-06 17:06:27,137:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-06 17:06:27,137:INFO:version 3.0.4
2023-09-06 17:06:27,137:INFO:Initializing setup()
2023-09-06 17:06:27,137:INFO:self.USI: d389
2023-09-06 17:06:27,137:INFO:self._variable_keys: {'fold_groups_param', 'fix_imbalance', 'fold_generator', 'X_test', '_available_plots', 'X', 'logging_param', 'USI', 'gpu_n_jobs_param', 'idx', 'gpu_param', 'fold_shuffle_param', 'y_train', 'is_multiclass', 'exp_name_log', 'memory', 'X_train', 'data', 'y_test', 'y', 'pipeline', 'html_param', '_ml_usecase', 'exp_id', 'log_plots_param', 'seed', 'target_param', 'n_jobs_param'}
2023-09-06 17:06:27,137:INFO:Checking environment
2023-09-06 17:06:27,137:INFO:python_version: 3.8.8
2023-09-06 17:06:27,137:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-06 17:06:27,137:INFO:machine: AMD64
2023-09-06 17:06:27,137:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-06 17:06:27,137:INFO:Memory: svmem(total=16822788096, available=8892239872, percent=47.1, used=7930548224, free=8892239872)
2023-09-06 17:06:27,137:INFO:Physical Core: 8
2023-09-06 17:06:27,137:INFO:Logical Core: 16
2023-09-06 17:06:27,137:INFO:Checking libraries
2023-09-06 17:06:27,148:INFO:System:
2023-09-06 17:06:27,148:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-06 17:06:27,148:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-06 17:06:27,148:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-06 17:06:27,148:INFO:PyCaret required dependencies:
2023-09-06 17:06:27,149:INFO:                 pip: 23.2.1
2023-09-06 17:06:27,149:INFO:          setuptools: 65.5.1
2023-09-06 17:06:27,149:INFO:             pycaret: 3.0.4
2023-09-06 17:06:27,149:INFO:             IPython: 8.12.2
2023-09-06 17:06:27,149:INFO:          ipywidgets: 8.0.7
2023-09-06 17:06:27,149:INFO:                tqdm: 4.66.1
2023-09-06 17:06:27,149:INFO:               numpy: 1.23.5
2023-09-06 17:06:27,149:INFO:              pandas: 1.5.3
2023-09-06 17:06:27,149:INFO:              jinja2: 3.1.2
2023-09-06 17:06:27,149:INFO:               scipy: 1.10.1
2023-09-06 17:06:27,149:INFO:              joblib: 1.3.2
2023-09-06 17:06:27,149:INFO:             sklearn: 1.2.2
2023-09-06 17:06:27,149:INFO:                pyod: 1.1.0
2023-09-06 17:06:27,149:INFO:            imblearn: 0.11.0
2023-09-06 17:06:27,149:INFO:   category_encoders: 2.6.2
2023-09-06 17:06:27,149:INFO:            lightgbm: 4.0.0
2023-09-06 17:06:27,149:INFO:               numba: 0.57.1
2023-09-06 17:06:27,149:INFO:            requests: 2.31.0
2023-09-06 17:06:27,149:INFO:          matplotlib: 3.7.2
2023-09-06 17:06:27,149:INFO:          scikitplot: 0.3.7
2023-09-06 17:06:27,149:INFO:         yellowbrick: 1.5
2023-09-06 17:06:27,149:INFO:              plotly: 5.15.0
2023-09-06 17:06:27,149:INFO:    plotly-resampler: Not installed
2023-09-06 17:06:27,149:INFO:             kaleido: 0.2.1
2023-09-06 17:06:27,149:INFO:           schemdraw: 0.15
2023-09-06 17:06:27,149:INFO:         statsmodels: 0.14.0
2023-09-06 17:06:27,149:INFO:              sktime: 0.22.0
2023-09-06 17:06:27,149:INFO:               tbats: 1.1.3
2023-09-06 17:06:27,149:INFO:            pmdarima: 2.0.3
2023-09-06 17:06:27,149:INFO:              psutil: 5.9.5
2023-09-06 17:06:27,149:INFO:          markupsafe: 2.1.3
2023-09-06 17:06:27,149:INFO:             pickle5: Not installed
2023-09-06 17:06:27,149:INFO:         cloudpickle: 2.2.1
2023-09-06 17:06:27,149:INFO:         deprecation: 2.1.0
2023-09-06 17:06:27,149:INFO:              xxhash: 3.3.0
2023-09-06 17:06:27,149:INFO:           wurlitzer: Not installed
2023-09-06 17:06:27,149:INFO:PyCaret optional dependencies:
2023-09-06 17:06:27,154:INFO:                shap: Not installed
2023-09-06 17:06:27,154:INFO:           interpret: Not installed
2023-09-06 17:06:27,154:INFO:                umap: Not installed
2023-09-06 17:06:27,154:INFO:    pandas_profiling: 4.5.1
2023-09-06 17:06:27,154:INFO:  explainerdashboard: Not installed
2023-09-06 17:06:27,154:INFO:             autoviz: Not installed
2023-09-06 17:06:27,155:INFO:           fairlearn: Not installed
2023-09-06 17:06:27,155:INFO:          deepchecks: Not installed
2023-09-06 17:06:27,155:INFO:             xgboost: 1.7.6
2023-09-06 17:06:27,155:INFO:            catboost: 1.2.1
2023-09-06 17:06:27,155:INFO:              kmodes: Not installed
2023-09-06 17:06:27,155:INFO:             mlxtend: Not installed
2023-09-06 17:06:27,155:INFO:       statsforecast: Not installed
2023-09-06 17:06:27,155:INFO:        tune_sklearn: Not installed
2023-09-06 17:06:27,155:INFO:                 ray: Not installed
2023-09-06 17:06:27,155:INFO:            hyperopt: Not installed
2023-09-06 17:06:27,155:INFO:              optuna: 3.3.0
2023-09-06 17:06:27,155:INFO:               skopt: 0.9.0
2023-09-06 17:06:27,155:INFO:              mlflow: Not installed
2023-09-06 17:06:27,155:INFO:              gradio: Not installed
2023-09-06 17:06:27,155:INFO:             fastapi: Not installed
2023-09-06 17:06:27,155:INFO:             uvicorn: Not installed
2023-09-06 17:06:27,155:INFO:              m2cgen: Not installed
2023-09-06 17:06:27,155:INFO:           evidently: Not installed
2023-09-06 17:06:27,155:INFO:               fugue: Not installed
2023-09-06 17:06:27,155:INFO:           streamlit: Not installed
2023-09-06 17:06:27,155:INFO:             prophet: Not installed
2023-09-06 17:06:27,155:INFO:None
2023-09-06 17:06:27,155:INFO:Set up data.
2023-09-06 17:06:27,158:INFO:Set up train/test split.
2023-09-06 17:06:27,160:INFO:Set up index.
2023-09-06 17:06:27,160:INFO:Set up folding strategy.
2023-09-06 17:06:27,160:INFO:Assigning column types.
2023-09-06 17:06:27,162:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-06 17:06:27,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-06 17:06:27,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 17:06:27,212:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,212:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-06 17:06:27,243:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 17:06:27,274:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,274:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,274:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-06 17:06:27,305:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 17:06:27,321:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,321:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 17:06:27,368:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,368:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,368:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-06 17:06:27,415:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,430:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,477:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,477:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,477:INFO:Preparing preprocessing pipeline...
2023-09-06 17:06:27,477:INFO:Set up simple imputation.
2023-09-06 17:06:27,477:INFO:Finished creating preprocessing pipeline.
2023-09-06 17:06:27,493:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-06 17:06:27,493:INFO:Creating final display dataframe.
2023-09-06 17:06:27,524:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d389
2023-09-06 17:06:27,579:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,580:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,614:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,614:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,630:INFO:setup() successfully completed in 0.53s...............
2023-09-06 17:06:27,646:INFO:gpu_param set to False
2023-09-06 17:06:27,699:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,702:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,747:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,747:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,764:INFO:gpu_param set to False
2023-09-06 17:06:27,815:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,817:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,869:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 17:06:27,871:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 17:06:27,915:INFO:Initializing compare_models()
2023-09-06 17:06:27,915:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-06 17:06:27,915:INFO:Checking exceptions
2023-09-06 17:06:27,918:INFO:Preparing display monitor
2023-09-06 17:06:27,938:INFO:Initializing Logistic Regression
2023-09-06 17:06:27,938:INFO:Total runtime is 0.0 minutes
2023-09-06 17:06:27,941:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:27,941:INFO:Initializing create_model()
2023-09-06 17:06:27,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:27,941:INFO:Checking exceptions
2023-09-06 17:06:27,941:INFO:Importing libraries
2023-09-06 17:06:27,941:INFO:Copying training dataset
2023-09-06 17:06:27,943:INFO:Defining folds
2023-09-06 17:06:27,943:INFO:Declaring metric variables
2023-09-06 17:06:27,945:INFO:Importing untrained model
2023-09-06 17:06:27,949:INFO:Logistic Regression Imported successfully
2023-09-06 17:06:27,954:INFO:Starting cross validation
2023-09-06 17:06:27,954:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:29,617:INFO:Calculating mean and std
2023-09-06 17:06:29,617:INFO:Creating metrics dataframe
2023-09-06 17:06:29,680:INFO:Uploading results into container
2023-09-06 17:06:29,680:INFO:Uploading model into container now
2023-09-06 17:06:29,680:INFO:_master_model_container: 1
2023-09-06 17:06:29,680:INFO:_display_container: 2
2023-09-06 17:06:29,696:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-06 17:06:29,696:INFO:create_model() successfully completed......................................
2023-09-06 17:06:29,727:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:29,727:INFO:Creating metrics dataframe
2023-09-06 17:06:29,743:INFO:Initializing K Neighbors Classifier
2023-09-06 17:06:29,743:INFO:Total runtime is 0.030074799060821535 minutes
2023-09-06 17:06:29,753:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:29,753:INFO:Initializing create_model()
2023-09-06 17:06:29,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:29,753:INFO:Checking exceptions
2023-09-06 17:06:29,753:INFO:Importing libraries
2023-09-06 17:06:29,753:INFO:Copying training dataset
2023-09-06 17:06:29,757:INFO:Defining folds
2023-09-06 17:06:29,757:INFO:Declaring metric variables
2023-09-06 17:06:29,759:INFO:Importing untrained model
2023-09-06 17:06:29,761:INFO:K Neighbors Classifier Imported successfully
2023-09-06 17:06:29,768:INFO:Starting cross validation
2023-09-06 17:06:29,769:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:31,145:INFO:Calculating mean and std
2023-09-06 17:06:31,145:INFO:Creating metrics dataframe
2023-09-06 17:06:31,214:INFO:Uploading results into container
2023-09-06 17:06:31,214:INFO:Uploading model into container now
2023-09-06 17:06:31,214:INFO:_master_model_container: 2
2023-09-06 17:06:31,214:INFO:_display_container: 2
2023-09-06 17:06:31,214:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-06 17:06:31,214:INFO:create_model() successfully completed......................................
2023-09-06 17:06:31,261:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:31,261:INFO:Creating metrics dataframe
2023-09-06 17:06:31,261:INFO:Initializing Naive Bayes
2023-09-06 17:06:31,261:INFO:Total runtime is 0.05537383556365967 minutes
2023-09-06 17:06:31,261:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:31,261:INFO:Initializing create_model()
2023-09-06 17:06:31,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:31,261:INFO:Checking exceptions
2023-09-06 17:06:31,261:INFO:Importing libraries
2023-09-06 17:06:31,261:INFO:Copying training dataset
2023-09-06 17:06:31,275:INFO:Defining folds
2023-09-06 17:06:31,275:INFO:Declaring metric variables
2023-09-06 17:06:31,278:INFO:Importing untrained model
2023-09-06 17:06:31,280:INFO:Naive Bayes Imported successfully
2023-09-06 17:06:31,285:INFO:Starting cross validation
2023-09-06 17:06:31,286:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:32,597:INFO:Calculating mean and std
2023-09-06 17:06:32,597:INFO:Creating metrics dataframe
2023-09-06 17:06:32,664:INFO:Uploading results into container
2023-09-06 17:06:32,664:INFO:Uploading model into container now
2023-09-06 17:06:32,664:INFO:_master_model_container: 3
2023-09-06 17:06:32,664:INFO:_display_container: 2
2023-09-06 17:06:32,664:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-06 17:06:32,664:INFO:create_model() successfully completed......................................
2023-09-06 17:06:32,711:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:32,711:INFO:Creating metrics dataframe
2023-09-06 17:06:32,711:INFO:Initializing Decision Tree Classifier
2023-09-06 17:06:32,711:INFO:Total runtime is 0.07953783671061199 minutes
2023-09-06 17:06:32,711:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:32,711:INFO:Initializing create_model()
2023-09-06 17:06:32,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:32,711:INFO:Checking exceptions
2023-09-06 17:06:32,711:INFO:Importing libraries
2023-09-06 17:06:32,711:INFO:Copying training dataset
2023-09-06 17:06:32,724:INFO:Defining folds
2023-09-06 17:06:32,725:INFO:Declaring metric variables
2023-09-06 17:06:32,727:INFO:Importing untrained model
2023-09-06 17:06:32,729:INFO:Decision Tree Classifier Imported successfully
2023-09-06 17:06:32,734:INFO:Starting cross validation
2023-09-06 17:06:32,735:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:34,050:INFO:Calculating mean and std
2023-09-06 17:06:34,050:INFO:Creating metrics dataframe
2023-09-06 17:06:34,114:INFO:Uploading results into container
2023-09-06 17:06:34,114:INFO:Uploading model into container now
2023-09-06 17:06:34,114:INFO:_master_model_container: 4
2023-09-06 17:06:34,114:INFO:_display_container: 2
2023-09-06 17:06:34,114:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-06 17:06:34,114:INFO:create_model() successfully completed......................................
2023-09-06 17:06:34,171:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:34,171:INFO:Creating metrics dataframe
2023-09-06 17:06:34,179:INFO:Initializing SVM - Linear Kernel
2023-09-06 17:06:34,179:INFO:Total runtime is 0.10400766531626385 minutes
2023-09-06 17:06:34,182:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:34,182:INFO:Initializing create_model()
2023-09-06 17:06:34,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:34,182:INFO:Checking exceptions
2023-09-06 17:06:34,182:INFO:Importing libraries
2023-09-06 17:06:34,182:INFO:Copying training dataset
2023-09-06 17:06:34,182:INFO:Defining folds
2023-09-06 17:06:34,182:INFO:Declaring metric variables
2023-09-06 17:06:34,182:INFO:Importing untrained model
2023-09-06 17:06:34,182:INFO:SVM - Linear Kernel Imported successfully
2023-09-06 17:06:34,182:INFO:Starting cross validation
2023-09-06 17:06:34,182:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:35,352:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 17:06:35,384:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 17:06:35,399:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 17:06:35,509:INFO:Calculating mean and std
2023-09-06 17:06:35,509:INFO:Creating metrics dataframe
2023-09-06 17:06:35,581:INFO:Uploading results into container
2023-09-06 17:06:35,581:INFO:Uploading model into container now
2023-09-06 17:06:35,581:INFO:_master_model_container: 5
2023-09-06 17:06:35,581:INFO:_display_container: 2
2023-09-06 17:06:35,581:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-06 17:06:35,581:INFO:create_model() successfully completed......................................
2023-09-06 17:06:35,627:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:35,627:INFO:Creating metrics dataframe
2023-09-06 17:06:35,627:INFO:Initializing Ridge Classifier
2023-09-06 17:06:35,627:INFO:Total runtime is 0.12814996242523194 minutes
2023-09-06 17:06:35,627:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:35,627:INFO:Initializing create_model()
2023-09-06 17:06:35,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:35,627:INFO:Checking exceptions
2023-09-06 17:06:35,627:INFO:Importing libraries
2023-09-06 17:06:35,627:INFO:Copying training dataset
2023-09-06 17:06:35,638:INFO:Defining folds
2023-09-06 17:06:35,639:INFO:Declaring metric variables
2023-09-06 17:06:35,641:INFO:Importing untrained model
2023-09-06 17:06:35,643:INFO:Ridge Classifier Imported successfully
2023-09-06 17:06:35,649:INFO:Starting cross validation
2023-09-06 17:06:35,650:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:35,680:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 17:06:35,682:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 17:06:36,706:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 17:06:36,722:INFO:Calculating mean and std
2023-09-06 17:06:36,722:INFO:Creating metrics dataframe
2023-09-06 17:06:36,796:INFO:Uploading results into container
2023-09-06 17:06:36,796:INFO:Uploading model into container now
2023-09-06 17:06:36,796:INFO:_master_model_container: 6
2023-09-06 17:06:36,796:INFO:_display_container: 2
2023-09-06 17:06:36,796:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-06 17:06:36,796:INFO:create_model() successfully completed......................................
2023-09-06 17:06:36,843:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:36,843:INFO:Creating metrics dataframe
2023-09-06 17:06:36,843:INFO:Initializing Random Forest Classifier
2023-09-06 17:06:36,843:INFO:Total runtime is 0.14840991497039796 minutes
2023-09-06 17:06:36,860:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:36,860:INFO:Initializing create_model()
2023-09-06 17:06:36,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:36,860:INFO:Checking exceptions
2023-09-06 17:06:36,860:INFO:Importing libraries
2023-09-06 17:06:36,860:INFO:Copying training dataset
2023-09-06 17:06:36,863:INFO:Defining folds
2023-09-06 17:06:36,863:INFO:Declaring metric variables
2023-09-06 17:06:36,865:INFO:Importing untrained model
2023-09-06 17:06:36,868:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:06:36,868:INFO:Starting cross validation
2023-09-06 17:06:36,868:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:37,197:INFO:Calculating mean and std
2023-09-06 17:06:37,197:INFO:Creating metrics dataframe
2023-09-06 17:06:37,264:INFO:Uploading results into container
2023-09-06 17:06:37,264:INFO:Uploading model into container now
2023-09-06 17:06:37,264:INFO:_master_model_container: 7
2023-09-06 17:06:37,264:INFO:_display_container: 2
2023-09-06 17:06:37,264:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:37,264:INFO:create_model() successfully completed......................................
2023-09-06 17:06:37,311:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:37,311:INFO:Creating metrics dataframe
2023-09-06 17:06:37,311:INFO:Initializing Quadratic Discriminant Analysis
2023-09-06 17:06:37,311:INFO:Total runtime is 0.15620466470718386 minutes
2023-09-06 17:06:37,311:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:37,311:INFO:Initializing create_model()
2023-09-06 17:06:37,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:37,311:INFO:Checking exceptions
2023-09-06 17:06:37,311:INFO:Importing libraries
2023-09-06 17:06:37,311:INFO:Copying training dataset
2023-09-06 17:06:37,328:INFO:Defining folds
2023-09-06 17:06:37,328:INFO:Declaring metric variables
2023-09-06 17:06:37,330:INFO:Importing untrained model
2023-09-06 17:06:37,333:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-06 17:06:37,335:INFO:Starting cross validation
2023-09-06 17:06:37,335:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:37,500:INFO:Calculating mean and std
2023-09-06 17:06:37,500:INFO:Creating metrics dataframe
2023-09-06 17:06:37,564:INFO:Uploading results into container
2023-09-06 17:06:37,564:INFO:Uploading model into container now
2023-09-06 17:06:37,564:INFO:_master_model_container: 8
2023-09-06 17:06:37,564:INFO:_display_container: 2
2023-09-06 17:06:37,564:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-06 17:06:37,564:INFO:create_model() successfully completed......................................
2023-09-06 17:06:37,611:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:37,611:INFO:Creating metrics dataframe
2023-09-06 17:06:37,626:INFO:Initializing Ada Boost Classifier
2023-09-06 17:06:37,626:INFO:Total runtime is 0.16146558125813804 minutes
2023-09-06 17:06:37,626:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:37,626:INFO:Initializing create_model()
2023-09-06 17:06:37,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:37,626:INFO:Checking exceptions
2023-09-06 17:06:37,626:INFO:Importing libraries
2023-09-06 17:06:37,626:INFO:Copying training dataset
2023-09-06 17:06:37,635:INFO:Defining folds
2023-09-06 17:06:37,635:INFO:Declaring metric variables
2023-09-06 17:06:37,637:INFO:Importing untrained model
2023-09-06 17:06:37,640:INFO:Ada Boost Classifier Imported successfully
2023-09-06 17:06:37,643:INFO:Starting cross validation
2023-09-06 17:06:37,643:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:37,895:INFO:Calculating mean and std
2023-09-06 17:06:37,895:INFO:Creating metrics dataframe
2023-09-06 17:06:37,964:INFO:Uploading results into container
2023-09-06 17:06:37,964:INFO:Uploading model into container now
2023-09-06 17:06:37,964:INFO:_master_model_container: 9
2023-09-06 17:06:37,964:INFO:_display_container: 2
2023-09-06 17:06:37,964:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-06 17:06:37,964:INFO:create_model() successfully completed......................................
2023-09-06 17:06:38,011:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:38,011:INFO:Creating metrics dataframe
2023-09-06 17:06:38,011:INFO:Initializing Gradient Boosting Classifier
2023-09-06 17:06:38,011:INFO:Total runtime is 0.1678702433904012 minutes
2023-09-06 17:06:38,026:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:38,026:INFO:Initializing create_model()
2023-09-06 17:06:38,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:38,026:INFO:Checking exceptions
2023-09-06 17:06:38,026:INFO:Importing libraries
2023-09-06 17:06:38,026:INFO:Copying training dataset
2023-09-06 17:06:38,029:INFO:Defining folds
2023-09-06 17:06:38,029:INFO:Declaring metric variables
2023-09-06 17:06:38,031:INFO:Importing untrained model
2023-09-06 17:06:38,034:INFO:Gradient Boosting Classifier Imported successfully
2023-09-06 17:06:38,036:INFO:Starting cross validation
2023-09-06 17:06:38,036:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:38,304:INFO:Calculating mean and std
2023-09-06 17:06:38,304:INFO:Creating metrics dataframe
2023-09-06 17:06:38,379:INFO:Uploading results into container
2023-09-06 17:06:38,379:INFO:Uploading model into container now
2023-09-06 17:06:38,379:INFO:_master_model_container: 10
2023-09-06 17:06:38,379:INFO:_display_container: 2
2023-09-06 17:06:38,379:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-06 17:06:38,379:INFO:create_model() successfully completed......................................
2023-09-06 17:06:38,411:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:38,411:INFO:Creating metrics dataframe
2023-09-06 17:06:38,426:INFO:Initializing Linear Discriminant Analysis
2023-09-06 17:06:38,426:INFO:Total runtime is 0.1747999668121338 minutes
2023-09-06 17:06:38,431:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:38,431:INFO:Initializing create_model()
2023-09-06 17:06:38,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:38,431:INFO:Checking exceptions
2023-09-06 17:06:38,431:INFO:Importing libraries
2023-09-06 17:06:38,431:INFO:Copying training dataset
2023-09-06 17:06:38,434:INFO:Defining folds
2023-09-06 17:06:38,434:INFO:Declaring metric variables
2023-09-06 17:06:38,437:INFO:Importing untrained model
2023-09-06 17:06:38,439:INFO:Linear Discriminant Analysis Imported successfully
2023-09-06 17:06:38,440:INFO:Starting cross validation
2023-09-06 17:06:38,440:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:38,615:INFO:Calculating mean and std
2023-09-06 17:06:38,616:INFO:Creating metrics dataframe
2023-09-06 17:06:38,680:INFO:Uploading results into container
2023-09-06 17:06:38,680:INFO:Uploading model into container now
2023-09-06 17:06:38,680:INFO:_master_model_container: 11
2023-09-06 17:06:38,680:INFO:_display_container: 2
2023-09-06 17:06:38,680:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-06 17:06:38,680:INFO:create_model() successfully completed......................................
2023-09-06 17:06:38,727:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:38,727:INFO:Creating metrics dataframe
2023-09-06 17:06:38,743:INFO:Initializing Extra Trees Classifier
2023-09-06 17:06:38,743:INFO:Total runtime is 0.180075204372406 minutes
2023-09-06 17:06:38,743:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:38,743:INFO:Initializing create_model()
2023-09-06 17:06:38,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:38,743:INFO:Checking exceptions
2023-09-06 17:06:38,743:INFO:Importing libraries
2023-09-06 17:06:38,743:INFO:Copying training dataset
2023-09-06 17:06:38,751:INFO:Defining folds
2023-09-06 17:06:38,751:INFO:Declaring metric variables
2023-09-06 17:06:38,753:INFO:Importing untrained model
2023-09-06 17:06:38,755:INFO:Extra Trees Classifier Imported successfully
2023-09-06 17:06:38,758:INFO:Starting cross validation
2023-09-06 17:06:38,758:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:39,064:INFO:Calculating mean and std
2023-09-06 17:06:39,064:INFO:Creating metrics dataframe
2023-09-06 17:06:39,134:INFO:Uploading results into container
2023-09-06 17:06:39,134:INFO:Uploading model into container now
2023-09-06 17:06:39,134:INFO:_master_model_container: 12
2023-09-06 17:06:39,134:INFO:_display_container: 2
2023-09-06 17:06:39,134:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:39,134:INFO:create_model() successfully completed......................................
2023-09-06 17:06:39,180:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:39,180:INFO:Creating metrics dataframe
2023-09-06 17:06:39,180:INFO:Initializing Extreme Gradient Boosting
2023-09-06 17:06:39,180:INFO:Total runtime is 0.1873691479365031 minutes
2023-09-06 17:06:39,180:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:39,180:INFO:Initializing create_model()
2023-09-06 17:06:39,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:39,180:INFO:Checking exceptions
2023-09-06 17:06:39,180:INFO:Importing libraries
2023-09-06 17:06:39,180:INFO:Copying training dataset
2023-09-06 17:06:39,195:INFO:Defining folds
2023-09-06 17:06:39,195:INFO:Declaring metric variables
2023-09-06 17:06:39,198:INFO:Importing untrained model
2023-09-06 17:06:39,200:INFO:Extreme Gradient Boosting Imported successfully
2023-09-06 17:06:39,205:INFO:Starting cross validation
2023-09-06 17:06:39,206:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:39,420:INFO:Calculating mean and std
2023-09-06 17:06:39,420:INFO:Creating metrics dataframe
2023-09-06 17:06:39,480:INFO:Uploading results into container
2023-09-06 17:06:39,480:INFO:Uploading model into container now
2023-09-06 17:06:39,480:INFO:_master_model_container: 13
2023-09-06 17:06:39,480:INFO:_display_container: 2
2023-09-06 17:06:39,480:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-06 17:06:39,480:INFO:create_model() successfully completed......................................
2023-09-06 17:06:39,527:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:39,527:INFO:Creating metrics dataframe
2023-09-06 17:06:39,543:INFO:Initializing Light Gradient Boosting Machine
2023-09-06 17:06:39,543:INFO:Total runtime is 0.1934101939201355 minutes
2023-09-06 17:06:39,543:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:39,543:INFO:Initializing create_model()
2023-09-06 17:06:39,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:39,543:INFO:Checking exceptions
2023-09-06 17:06:39,543:INFO:Importing libraries
2023-09-06 17:06:39,543:INFO:Copying training dataset
2023-09-06 17:06:39,550:INFO:Defining folds
2023-09-06 17:06:39,550:INFO:Declaring metric variables
2023-09-06 17:06:39,552:INFO:Importing untrained model
2023-09-06 17:06:39,554:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-06 17:06:39,558:INFO:Starting cross validation
2023-09-06 17:06:39,559:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:39,771:INFO:Calculating mean and std
2023-09-06 17:06:39,771:INFO:Creating metrics dataframe
2023-09-06 17:06:39,831:INFO:Uploading results into container
2023-09-06 17:06:39,846:INFO:Uploading model into container now
2023-09-06 17:06:39,846:INFO:_master_model_container: 14
2023-09-06 17:06:39,846:INFO:_display_container: 2
2023-09-06 17:06:39,846:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-06 17:06:39,846:INFO:create_model() successfully completed......................................
2023-09-06 17:06:39,878:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:39,878:INFO:Creating metrics dataframe
2023-09-06 17:06:39,893:INFO:Initializing Dummy Classifier
2023-09-06 17:06:39,893:INFO:Total runtime is 0.199249529838562 minutes
2023-09-06 17:06:39,893:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:39,893:INFO:Initializing create_model()
2023-09-06 17:06:39,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E5FC10>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:39,893:INFO:Checking exceptions
2023-09-06 17:06:39,893:INFO:Importing libraries
2023-09-06 17:06:39,893:INFO:Copying training dataset
2023-09-06 17:06:39,904:INFO:Defining folds
2023-09-06 17:06:39,904:INFO:Declaring metric variables
2023-09-06 17:06:39,906:INFO:Importing untrained model
2023-09-06 17:06:39,908:INFO:Dummy Classifier Imported successfully
2023-09-06 17:06:39,917:INFO:Starting cross validation
2023-09-06 17:06:39,918:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:39,967:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 17:06:39,976:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 17:06:39,978:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 17:06:40,091:INFO:Calculating mean and std
2023-09-06 17:06:40,091:INFO:Creating metrics dataframe
2023-09-06 17:06:40,165:INFO:Uploading results into container
2023-09-06 17:06:40,165:INFO:Uploading model into container now
2023-09-06 17:06:40,165:INFO:_master_model_container: 15
2023-09-06 17:06:40,165:INFO:_display_container: 2
2023-09-06 17:06:40,165:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-06 17:06:40,165:INFO:create_model() successfully completed......................................
2023-09-06 17:06:40,196:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:40,196:INFO:Creating metrics dataframe
2023-09-06 17:06:40,225:INFO:Initializing create_model()
2023-09-06 17:06:40,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:40,225:INFO:Checking exceptions
2023-09-06 17:06:40,226:INFO:Importing libraries
2023-09-06 17:06:40,226:INFO:Copying training dataset
2023-09-06 17:06:40,228:INFO:Defining folds
2023-09-06 17:06:40,228:INFO:Declaring metric variables
2023-09-06 17:06:40,228:INFO:Importing untrained model
2023-09-06 17:06:40,228:INFO:Declaring custom model
2023-09-06 17:06:40,229:INFO:Gradient Boosting Classifier Imported successfully
2023-09-06 17:06:40,229:INFO:Cross validation set to False
2023-09-06 17:06:40,229:INFO:Fitting Model
2023-09-06 17:06:40,360:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-06 17:06:40,360:INFO:create_model() successfully completed......................................
2023-09-06 17:06:40,407:INFO:Initializing create_model()
2023-09-06 17:06:40,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:40,407:INFO:Checking exceptions
2023-09-06 17:06:40,413:INFO:Importing libraries
2023-09-06 17:06:40,413:INFO:Copying training dataset
2023-09-06 17:06:40,415:INFO:Defining folds
2023-09-06 17:06:40,415:INFO:Declaring metric variables
2023-09-06 17:06:40,415:INFO:Importing untrained model
2023-09-06 17:06:40,415:INFO:Declaring custom model
2023-09-06 17:06:40,415:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-06 17:06:40,415:INFO:Cross validation set to False
2023-09-06 17:06:40,415:INFO:Fitting Model
2023-09-06 17:06:40,415:INFO:[LightGBM] [Info] Number of positive: 273, number of negative: 439
2023-09-06 17:06:40,415:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.
2023-09-06 17:06:40,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-09-06 17:06:40,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-09-06 17:06:40,415:INFO:[LightGBM] [Info] Total Bins 274
2023-09-06 17:06:40,415:INFO:[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9
2023-09-06 17:06:40,415:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028
2023-09-06 17:06:40,415:INFO:[LightGBM] [Info] Start training from score -0.475028
2023-09-06 17:06:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 17:06:40,521:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-06 17:06:40,521:INFO:create_model() successfully completed......................................
2023-09-06 17:06:40,583:INFO:Initializing create_model()
2023-09-06 17:06:40,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:40,583:INFO:Checking exceptions
2023-09-06 17:06:40,598:INFO:Importing libraries
2023-09-06 17:06:40,598:INFO:Copying training dataset
2023-09-06 17:06:40,600:INFO:Defining folds
2023-09-06 17:06:40,600:INFO:Declaring metric variables
2023-09-06 17:06:40,600:INFO:Importing untrained model
2023-09-06 17:06:40,600:INFO:Declaring custom model
2023-09-06 17:06:40,601:INFO:Extreme Gradient Boosting Imported successfully
2023-09-06 17:06:40,601:INFO:Cross validation set to False
2023-09-06 17:06:40,601:INFO:Fitting Model
2023-09-06 17:06:40,712:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-06 17:06:40,712:INFO:create_model() successfully completed......................................
2023-09-06 17:06:40,786:INFO:_master_model_container: 15
2023-09-06 17:06:40,786:INFO:_display_container: 2
2023-09-06 17:06:40,786:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)]
2023-09-06 17:06:40,786:INFO:compare_models() successfully completed......................................
2023-09-06 17:06:40,818:INFO:Initializing create_model()
2023-09-06 17:06:40,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-06 17:06:40,818:INFO:Checking exceptions
2023-09-06 17:06:40,835:INFO:Importing libraries
2023-09-06 17:06:40,835:INFO:Copying training dataset
2023-09-06 17:06:40,837:INFO:Defining folds
2023-09-06 17:06:40,837:INFO:Declaring metric variables
2023-09-06 17:06:40,839:INFO:Importing untrained model
2023-09-06 17:06:40,842:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:06:40,848:INFO:Starting cross validation
2023-09-06 17:06:40,849:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:41,228:INFO:Calculating mean and std
2023-09-06 17:06:41,228:INFO:Creating metrics dataframe
2023-09-06 17:06:41,228:INFO:Finalizing model
2023-09-06 17:06:41,352:INFO:Uploading results into container
2023-09-06 17:06:41,352:INFO:Uploading model into container now
2023-09-06 17:06:41,357:INFO:_master_model_container: 16
2023-09-06 17:06:41,357:INFO:_display_container: 3
2023-09-06 17:06:41,357:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:41,357:INFO:create_model() successfully completed......................................
2023-09-06 17:06:41,422:INFO:Initializing tune_model()
2023-09-06 17:06:41,422:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [150, 200, 250], 'max_depth': [10, 20], 'min_samples_split': [1, 2, 3], 'min_samples_leaf': [1, 2, 3]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>)
2023-09-06 17:06:41,422:INFO:Checking exceptions
2023-09-06 17:06:41,435:INFO:Copying training dataset
2023-09-06 17:06:41,436:INFO:Checking base model
2023-09-06 17:06:41,436:INFO:Base model : Random Forest Classifier
2023-09-06 17:06:41,439:INFO:Declaring metric variables
2023-09-06 17:06:41,440:INFO:Defining Hyperparameters
2023-09-06 17:06:41,493:INFO:custom_grid: {'actual_estimator__n_estimators': [150, 200, 250], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2, 3], 'actual_estimator__min_samples_leaf': [1, 2, 3]}
2023-09-06 17:06:41,493:INFO:Tuning with n_jobs=-1
2023-09-06 17:06:41,493:INFO:Initializing RandomizedSearchCV
2023-09-06 17:06:43,424:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
12 fits failed out of a total of 30.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
12 fits failed with the following error:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\AI\pythonProject\venv\lib\site-packages\joblib\memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-06 17:06:43,424:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8033838         nan        nan 0.82725242 0.81741895 0.81881951
 0.81881951        nan 0.80899195        nan]
  warnings.warn(

2023-09-06 17:06:43,486:INFO:best_params: {'actual_estimator__n_estimators': 250, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-06 17:06:43,486:INFO:Hyperparameter search completed
2023-09-06 17:06:43,486:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:43,486:INFO:Initializing create_model()
2023-09-06 17:06:43,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28CA6F70>, model_only=True, return_train_score=False, kwargs={'n_estimators': 250, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-06 17:06:43,486:INFO:Checking exceptions
2023-09-06 17:06:43,486:INFO:Importing libraries
2023-09-06 17:06:43,486:INFO:Copying training dataset
2023-09-06 17:06:43,499:INFO:Defining folds
2023-09-06 17:06:43,499:INFO:Declaring metric variables
2023-09-06 17:06:43,501:INFO:Importing untrained model
2023-09-06 17:06:43,501:INFO:Declaring custom model
2023-09-06 17:06:43,505:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:06:43,510:INFO:Starting cross validation
2023-09-06 17:06:43,510:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:43,955:INFO:Calculating mean and std
2023-09-06 17:06:43,955:INFO:Creating metrics dataframe
2023-09-06 17:06:43,955:INFO:Finalizing model
2023-09-06 17:06:44,087:INFO:Uploading results into container
2023-09-06 17:06:44,087:INFO:Uploading model into container now
2023-09-06 17:06:44,088:INFO:_master_model_container: 17
2023-09-06 17:06:44,088:INFO:_display_container: 4
2023-09-06 17:06:44,088:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:44,088:INFO:create_model() successfully completed......................................
2023-09-06 17:06:44,131:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:44,131:INFO:choose_better activated
2023-09-06 17:06:44,133:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:44,134:INFO:Initializing create_model()
2023-09-06 17:06:44,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:44,134:INFO:Checking exceptions
2023-09-06 17:06:44,136:INFO:Importing libraries
2023-09-06 17:06:44,136:INFO:Copying training dataset
2023-09-06 17:06:44,139:INFO:Defining folds
2023-09-06 17:06:44,139:INFO:Declaring metric variables
2023-09-06 17:06:44,139:INFO:Importing untrained model
2023-09-06 17:06:44,139:INFO:Declaring custom model
2023-09-06 17:06:44,140:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:06:44,140:INFO:Starting cross validation
2023-09-06 17:06:44,140:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:44,510:INFO:Calculating mean and std
2023-09-06 17:06:44,510:INFO:Creating metrics dataframe
2023-09-06 17:06:44,510:INFO:Finalizing model
2023-09-06 17:06:44,619:INFO:Uploading results into container
2023-09-06 17:06:44,619:INFO:Uploading model into container now
2023-09-06 17:06:44,619:INFO:_master_model_container: 18
2023-09-06 17:06:44,619:INFO:_display_container: 5
2023-09-06 17:06:44,619:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:44,619:INFO:create_model() successfully completed......................................
2023-09-06 17:06:44,676:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:44,676:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-06 17:06:44,676:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8273
2023-09-06 17:06:44,676:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-06 17:06:44,676:INFO:choose_better completed
2023-09-06 17:06:44,688:INFO:_master_model_container: 18
2023-09-06 17:06:44,688:INFO:_display_container: 4
2023-09-06 17:06:44,689:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=3, min_weight_fraction_leaf=0.0,
                       n_estimators=250, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:44,689:INFO:tune_model() successfully completed......................................
2023-09-06 17:06:44,838:INFO:Initializing tune_model()
2023-09-06 17:06:44,838:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>)
2023-09-06 17:06:44,838:INFO:Checking exceptions
2023-09-06 17:06:44,851:INFO:Copying training dataset
2023-09-06 17:06:44,852:INFO:Checking base model
2023-09-06 17:06:44,852:INFO:Base model : Random Forest Classifier
2023-09-06 17:06:44,856:INFO:Declaring metric variables
2023-09-06 17:06:44,857:INFO:Defining Hyperparameters
2023-09-06 17:06:44,911:INFO:Tuning with n_jobs=-1
2023-09-06 17:06:44,911:INFO:Initializing RandomizedSearchCV
2023-09-06 17:06:46,940:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-09-06 17:06:46,940:INFO:Hyperparameter search completed
2023-09-06 17:06:46,940:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:46,940:INFO:Initializing create_model()
2023-09-06 17:06:46,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C01CF14F0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2023-09-06 17:06:46,940:INFO:Checking exceptions
2023-09-06 17:06:46,940:INFO:Importing libraries
2023-09-06 17:06:46,940:INFO:Copying training dataset
2023-09-06 17:06:46,954:INFO:Defining folds
2023-09-06 17:06:46,954:INFO:Declaring metric variables
2023-09-06 17:06:46,955:INFO:Importing untrained model
2023-09-06 17:06:46,955:INFO:Declaring custom model
2023-09-06 17:06:46,955:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:06:46,955:INFO:Starting cross validation
2023-09-06 17:06:46,955:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:47,298:INFO:Calculating mean and std
2023-09-06 17:06:47,298:INFO:Creating metrics dataframe
2023-09-06 17:06:47,298:INFO:Finalizing model
2023-09-06 17:06:47,419:INFO:Uploading results into container
2023-09-06 17:06:47,419:INFO:Uploading model into container now
2023-09-06 17:06:47,420:INFO:_master_model_container: 19
2023-09-06 17:06:47,420:INFO:_display_container: 5
2023-09-06 17:06:47,420:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:47,420:INFO:create_model() successfully completed......................................
2023-09-06 17:06:47,470:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:47,470:INFO:choose_better activated
2023-09-06 17:06:47,472:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:47,472:INFO:Initializing create_model()
2023-09-06 17:06:47,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:06:47,472:INFO:Checking exceptions
2023-09-06 17:06:47,473:INFO:Importing libraries
2023-09-06 17:06:47,473:INFO:Copying training dataset
2023-09-06 17:06:47,476:INFO:Defining folds
2023-09-06 17:06:47,476:INFO:Declaring metric variables
2023-09-06 17:06:47,476:INFO:Importing untrained model
2023-09-06 17:06:47,476:INFO:Declaring custom model
2023-09-06 17:06:47,476:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:06:47,476:INFO:Starting cross validation
2023-09-06 17:06:47,477:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:06:47,843:INFO:Calculating mean and std
2023-09-06 17:06:47,843:INFO:Creating metrics dataframe
2023-09-06 17:06:47,843:INFO:Finalizing model
2023-09-06 17:06:47,952:INFO:Uploading results into container
2023-09-06 17:06:47,952:INFO:Uploading model into container now
2023-09-06 17:06:47,952:INFO:_master_model_container: 20
2023-09-06 17:06:47,952:INFO:_display_container: 6
2023-09-06 17:06:47,952:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:47,952:INFO:create_model() successfully completed......................................
2023-09-06 17:06:47,999:INFO:SubProcess create_model() end ==================================
2023-09-06 17:06:47,999:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-06 17:06:47,999:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8244
2023-09-06 17:06:47,999:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-06 17:06:47,999:INFO:choose_better completed
2023-09-06 17:06:48,015:INFO:_master_model_container: 20
2023-09-06 17:06:48,015:INFO:_display_container: 5
2023-09-06 17:06:48,016:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:06:48,016:INFO:tune_model() successfully completed......................................
2023-09-06 17:06:48,132:INFO:Initializing tune_model()
2023-09-06 17:06:48,133:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>)
2023-09-06 17:06:48,133:INFO:Checking exceptions
2023-09-06 17:06:48,133:INFO:Soft dependency imported: optuna: 3.3.0
2023-09-06 17:06:48,305:INFO:Copying training dataset
2023-09-06 17:06:48,307:INFO:Checking base model
2023-09-06 17:06:48,307:INFO:Base model : Random Forest Classifier
2023-09-06 17:06:48,308:INFO:Declaring metric variables
2023-09-06 17:06:48,308:INFO:Defining Hyperparameters
2023-09-06 17:06:48,367:INFO:Tuning with n_jobs=-1
2023-09-06 17:06:48,368:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\samplers\_tpe\sampler.py:277: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-09-06 17:06:48,368:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\samplers\_tpe\sampler.py:296: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-09-06 17:06:48,368:WARNING:C:\AI\pythonProject\venv\lib\site-packages\optuna\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-09-06 17:06:48,368:INFO:Initializing optuna.integration.OptunaSearchCV
2023-09-06 17:06:48,370:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2441: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-09-06 17:06:59,944:INFO:best_params: {'actual_estimator__n_estimators': 222, 'actual_estimator__max_depth': 7, 'actual_estimator__min_impurity_decrease': 6.510221262613744e-05, 'actual_estimator__max_features': 0.6652952360738025, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__bootstrap': False, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced'}
2023-09-06 17:06:59,944:INFO:Hyperparameter search completed
2023-09-06 17:06:59,944:INFO:SubProcess create_model() called ==================================
2023-09-06 17:06:59,944:INFO:Initializing create_model()
2023-09-06 17:06:59,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28DDCBB0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 222, 'max_depth': 7, 'min_impurity_decrease': 6.510221262613744e-05, 'max_features': 0.6652952360738025, 'min_samples_split': 2, 'min_samples_leaf': 5, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'})
2023-09-06 17:06:59,944:INFO:Checking exceptions
2023-09-06 17:06:59,944:INFO:Importing libraries
2023-09-06 17:06:59,944:INFO:Copying training dataset
2023-09-06 17:06:59,944:INFO:Defining folds
2023-09-06 17:06:59,944:INFO:Declaring metric variables
2023-09-06 17:06:59,958:INFO:Importing untrained model
2023-09-06 17:06:59,959:INFO:Declaring custom model
2023-09-06 17:06:59,961:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:06:59,967:INFO:Starting cross validation
2023-09-06 17:06:59,967:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:07:00,409:INFO:Calculating mean and std
2023-09-06 17:07:00,409:INFO:Creating metrics dataframe
2023-09-06 17:07:00,409:INFO:Finalizing model
2023-09-06 17:07:00,818:INFO:Uploading results into container
2023-09-06 17:07:00,818:INFO:Uploading model into container now
2023-09-06 17:07:00,818:INFO:_master_model_container: 21
2023-09-06 17:07:00,818:INFO:_display_container: 6
2023-09-06 17:07:00,818:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=7,
                       max_features=0.6652952360738025, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=6.510221262613744e-05,
                       min_samples_leaf=5, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=222,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-06 17:07:00,818:INFO:create_model() successfully completed......................................
2023-09-06 17:07:00,867:INFO:SubProcess create_model() end ==================================
2023-09-06 17:07:00,867:INFO:choose_better activated
2023-09-06 17:07:00,882:INFO:SubProcess create_model() called ==================================
2023-09-06 17:07:00,882:INFO:Initializing create_model()
2023-09-06 17:07:00,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:07:00,882:INFO:Checking exceptions
2023-09-06 17:07:00,884:INFO:Importing libraries
2023-09-06 17:07:00,884:INFO:Copying training dataset
2023-09-06 17:07:00,884:INFO:Defining folds
2023-09-06 17:07:00,884:INFO:Declaring metric variables
2023-09-06 17:07:00,884:INFO:Importing untrained model
2023-09-06 17:07:00,884:INFO:Declaring custom model
2023-09-06 17:07:00,884:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:07:00,884:INFO:Starting cross validation
2023-09-06 17:07:00,884:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:07:01,306:INFO:Calculating mean and std
2023-09-06 17:07:01,306:INFO:Creating metrics dataframe
2023-09-06 17:07:01,306:INFO:Finalizing model
2023-09-06 17:07:01,436:INFO:Uploading results into container
2023-09-06 17:07:01,437:INFO:Uploading model into container now
2023-09-06 17:07:01,437:INFO:_master_model_container: 22
2023-09-06 17:07:01,437:INFO:_display_container: 7
2023-09-06 17:07:01,437:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:07:01,437:INFO:create_model() successfully completed......................................
2023-09-06 17:07:01,493:INFO:SubProcess create_model() end ==================================
2023-09-06 17:07:01,493:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-06 17:07:01,498:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=7,
                       max_features=0.6652952360738025, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=6.510221262613744e-05,
                       min_samples_leaf=5, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=222,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8146
2023-09-06 17:07:01,498:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-06 17:07:01,498:INFO:choose_better completed
2023-09-06 17:07:01,498:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-06 17:07:01,500:INFO:_master_model_container: 22
2023-09-06 17:07:01,500:INFO:_display_container: 6
2023-09-06 17:07:01,500:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:07:01,500:INFO:tune_model() successfully completed......................................
2023-09-06 17:07:01,568:INFO:Initializing tune_model()
2023-09-06 17:07:01,568:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>)
2023-09-06 17:07:01,568:INFO:Checking exceptions
2023-09-06 17:07:01,568:INFO:Soft dependency imported: skopt: 0.9.0
2023-09-06 17:07:01,601:INFO:Copying training dataset
2023-09-06 17:07:01,603:INFO:Checking base model
2023-09-06 17:07:01,603:INFO:Base model : Random Forest Classifier
2023-09-06 17:07:01,605:INFO:Declaring metric variables
2023-09-06 17:07:01,607:INFO:Defining Hyperparameters
2023-09-06 17:07:01,666:INFO:Tuning with n_jobs=-1
2023-09-06 17:07:01,666:INFO:Initializing skopt.BayesSearchCV
2023-09-06 17:07:05,878:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', True), ('actual_estimator__class_weight', 'balanced_subsample'), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 7), ('actual_estimator__max_features', 0.8224534830390922), ('actual_estimator__min_impurity_decrease', 3.902034183027504e-07), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 6), ('actual_estimator__n_estimators', 244)])
2023-09-06 17:07:05,878:INFO:Hyperparameter search completed
2023-09-06 17:07:05,879:INFO:SubProcess create_model() called ==================================
2023-09-06 17:07:05,879:INFO:Initializing create_model()
2023-09-06 17:07:05,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C28E96DF0>, model_only=True, return_train_score=False, kwargs={'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_depth': 7, 'max_features': 0.8224534830390922, 'min_impurity_decrease': 3.902034183027504e-07, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 244})
2023-09-06 17:07:05,880:INFO:Checking exceptions
2023-09-06 17:07:05,880:INFO:Importing libraries
2023-09-06 17:07:05,880:INFO:Copying training dataset
2023-09-06 17:07:05,883:INFO:Defining folds
2023-09-06 17:07:05,883:INFO:Declaring metric variables
2023-09-06 17:07:05,885:INFO:Importing untrained model
2023-09-06 17:07:05,885:INFO:Declaring custom model
2023-09-06 17:07:05,885:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:07:05,885:INFO:Starting cross validation
2023-09-06 17:07:05,885:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:07:06,320:INFO:Calculating mean and std
2023-09-06 17:07:06,320:INFO:Creating metrics dataframe
2023-09-06 17:07:06,320:INFO:Finalizing model
2023-09-06 17:07:06,445:INFO:Uploading results into container
2023-09-06 17:07:06,460:INFO:Uploading model into container now
2023-09-06 17:07:06,460:INFO:_master_model_container: 23
2023-09-06 17:07:06,460:INFO:_display_container: 7
2023-09-06 17:07:06,461:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-06 17:07:06,461:INFO:create_model() successfully completed......................................
2023-09-06 17:07:06,516:INFO:SubProcess create_model() end ==================================
2023-09-06 17:07:06,516:INFO:choose_better activated
2023-09-06 17:07:06,516:INFO:SubProcess create_model() called ==================================
2023-09-06 17:07:06,516:INFO:Initializing create_model()
2023-09-06 17:07:06,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024C22AF5D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 17:07:06,516:INFO:Checking exceptions
2023-09-06 17:07:06,516:INFO:Importing libraries
2023-09-06 17:07:06,516:INFO:Copying training dataset
2023-09-06 17:07:06,516:INFO:Defining folds
2023-09-06 17:07:06,516:INFO:Declaring metric variables
2023-09-06 17:07:06,516:INFO:Importing untrained model
2023-09-06 17:07:06,516:INFO:Declaring custom model
2023-09-06 17:07:06,516:INFO:Random Forest Classifier Imported successfully
2023-09-06 17:07:06,524:INFO:Starting cross validation
2023-09-06 17:07:06,524:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 17:07:06,916:INFO:Calculating mean and std
2023-09-06 17:07:06,916:INFO:Creating metrics dataframe
2023-09-06 17:07:06,916:INFO:Finalizing model
2023-09-06 17:07:07,050:INFO:Uploading results into container
2023-09-06 17:07:07,051:INFO:Uploading model into container now
2023-09-06 17:07:07,051:INFO:_master_model_container: 24
2023-09-06 17:07:07,051:INFO:_display_container: 8
2023-09-06 17:07:07,051:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 17:07:07,051:INFO:create_model() successfully completed......................................
2023-09-06 17:07:07,101:INFO:SubProcess create_model() end ==================================
2023-09-06 17:07:07,101:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=200, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8188
2023-09-06 17:07:07,101:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8244
2023-09-06 17:07:07,101:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) is best model
2023-09-06 17:07:07,101:INFO:choose_better completed
2023-09-06 17:07:07,116:INFO:_master_model_container: 24
2023-09-06 17:07:07,116:INFO:_display_container: 7
2023-09-06 17:07:07,116:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features=0.8224534830390922,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=3.902034183027504e-07,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, n_estimators=244,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-06 17:07:07,116:INFO:tune_model() successfully completed......................................
2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_143161f3175144609e39cfa1cc2483f4
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_f860fb452dc3400ca1ef78672a3d3d71_25c01dd533af494eac07981d8e3aa794
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_1f072fccd6ac445eb7d138a156bf0d1d
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_f42e213317d04ce48d175f2ec04b137f_d5ac42e917054532a1db1d06fb43d661
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_edaffe2f22834320ac44a1bd72f9b290
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_ce0f8ec614fb4ed599ed9b733817d6d4_627a7a205e45498e8bed18e97d1ed101
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_e72bf178114146c8ba40c4f8c4e9463e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_b5da3926ed2542bdb62b68fd0f1e1ada_19b47674020a45abaab815825626afbb
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_8f4f35ccb38a4e9d90274066c28e1385
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_2a2acee5ff2247479ce13673dda9908c_59c54c4733ab42718789810b7a1003c4
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,896:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_501782b843fb4a72adc828231deaa31b
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_48ec92ba685a4ff6857b9e8ae2044f77_e0eff75da6e9459eb35bc19f718040fa
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_9ff7a3e1d2204222b058b985cf3672e4
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_ccb7a8e2addd48a3b6636c32f3dd60d4_f931f4111f6446288695cc9945fd4cb0
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_9a28984a4f824e999eaae6ed854bc0f6
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_7c85ab2984fb4142bd079df1b521f4ff_1c794a90ae0a4d819a85b32ff532b564
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_2b45e8b1716741da8b0b2e6af7135484
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_84ec870c30a14049a30e7afeb5ec7a79_c5cb4af7fe5845ad81494e2525805899
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_0b8250d8015e4a72b8962da8bd3451fc
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_6ffa4665ac0041ee922c1f061d0fda8e_92d27eccbfe749a9abf7988893c517aa
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_a5fda35615124931b1e56736e094eb3f
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_4f3524c1dd724e3b8abd3957826a11f1_fff9b6339e6d45caa5e9d3f6f35bd65d
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_9089239e5963461ebb67c738838b3a11
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_bbb8b3a09c7a4b3f8ccbe24edbf2f592_0dc3fea236284812b21ee36b1ab9d523
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_6a7c7543a29f49b58b72eff7e723f622
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_e312fab485934767a109187a3ca968ce_66115f26703543248120bd030e832768
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_5a6460283c9c4e3485d8ae8c1f304683
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_5a3dee6372534dd48aec790d666cde08_f9890a37515646c4b26ef50aec743537
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_8a7a4d050e8c47baa5ad6e70f871aabc
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_e285f9ce53854146accb345f0ce56e93_de530c55d0c64c48a5dd085235713222
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_f94ba6742a2149668039cfb1a3aa1280
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_ab68d71ef3cd49acb7e5eb3df9931392_43b1ca9dea504d7c8bf6d1065a7534ee
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_773827c2200a402390f995e7766e9ba0
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_6a8c52cb74ec4793848b5c5cd19084e7_0b7685d00a894238b07fb0574d6cf110
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_b359385c60324458b44d7f6a75f4a73e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_23151e3f6a7048c0a1bd62c6e800e2e1_92a4492152f745c4b2755384fd9aa250
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_5f43851ab061410e9344917d53aab31f
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_787ebe9b788247b8a4088e5f215380ae_686fa6ba64e942d6a430c8f7667342e5
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_9e1a36240b034cb2beb4bfb1d1f30383
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_3acf549f254845e7a68600a798820c20_64fecbe68ecc479b85f0901bdf380401
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_33f9d28885584024987d271b97da0586
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_79a25034b60948cf9c6fa0c252ee1e7b_0df1d8e846f04dc9914cd977de5fc1fa
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_26100d63f1dd4fa1827d59c80d6e5642
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_60bf90d229994e6e91c86fe871ca51c5_9d748ff3f42643efb04719bd1f6b590e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_a76ac63d15fb4174bebf2e6f4e2e135a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_7e321f5842a2496782a3f65f273beef7_6daa9858c275447c9ad88f73756798a6
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_70a4eb682fcb41fa9c72c95ede985a8c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_35789ed83c634f5b9edbc7c3df1dbdec_6d6da82141784a62bd2ff5be8899d8d7
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_dcfa1abbadfd4f7c95ce88c63f361d10
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_e0be8d4d6d5444cd9429671b1091ddf8_923c9f984a3c44939743c3e8ba756512
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_8bd172951eaf4d27a730b8683ecf8ca9
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_34e9115491644848b5692eb52ba73ecd_9cc6430c82f746c79422dcc6ed1e6f89
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_0691143a1e5246ed82e97f097fb230f3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-06 17:07:28,912:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_8132_c1becf8d254f40db8a0781bf2058bb4e_6544227ac5274ce581df94de7cf531cf
  warnings.warn("Failed to delete temporary folder: {}"

